# 手部行为检测方案与功能说明

本指南统一了“手部行为识别”（包括洗手和消毒）的实施方案、功能说明和配置方法，为该模块提供单一、权威的参考。

## 1. 功能概述

本项目通过计算机视觉技术，实时检测工作场景中的“洗手”和“手部消毒”两种关键行为。其技术核心是 **姿态估计 + 运动分析 + 混合判断引擎**。

- **姿态估计 (Pose Estimation)**: 首先，系统通过姿态检测器精确捕捉人的手部关键点。
- **运动分析 (Motion Analysis)**: 其次，分析这些关键点在时间序列上的运动特征（如速度、轨迹、相对距离）。
- **混合判断引擎 (Hybrid Judgment Engine)**: 最后，将运动特征输入一个由“规则引擎”和可选的“机器学习分类器”组成的混合引擎，得出最终行为判断。

这种设计兼顾了规则法的快速部署和机器学习的精度优势。

## 2. 技术实现详解

### 2.1 步骤一：姿态检测

这是所有行为分析的基础。系统会根据当前硬件环境，自动选择最高效的姿态检测后端：

- **在GPU/MPS设备上**: 优先使用 **YOLOv8-Pose** (`yolov8n-pose.pt`)。它性能高，能充分利用硬件加速，是生产环境的首选。
- **在CPU设备上**: 自动回退到 **MediaPipe**。它对CPU优化良好，保证了在无GPU环境下的可用性。

这个过程是全自动的，由系统的“硬件自适应”机制管理。详情请参考《性能优化与自适应指南》。

### 2.2 步骤二：运动分析与特征提取

获取到手部关键点序列后，`src/core/motion_analyzer.py` 模块会计算一系列用于行为判断的量化特征，例如：
- 双手间的平均距离。
- 手部在水平和垂直方向上的移动标准差。
- 手部运动的频率。
- 关键点是否在预设的“洗手区域”或“消毒区域”内。

### 2.3 步骤三：混合判断引擎

系统采用一个灵活的混合引擎来输出最终结果。

1.  **规则引擎 (Rule Engine)**
    这是系统的基础判断逻辑。它将上一步提取的运动特征与 `config/unified_params.yaml` 中 `detection_rules` 部分定义的阈值进行比较。例如，“双手水平移动标准差大于 `horizontal_move_std` 且持续时间超过 `min_duration`” 才可能被判定为洗手。规则引擎会输出一个基于规则的置信度分数。

2.  **机器学习分类器 (Optional ML Classifier)**
    为了提升精度，系统可以额外启用一个轻量级的机器学习模型（当前为XGBoost）。
    - **启用方式**: 在 `unified_params.yaml` 中设置 `behavior_recognition.use_ml_classifier: true`。
    - **工作方式**: 启用后，运动特征会同时被送入此分类器，输出一个基于模型的置信度分数。

3.  **结果融合 (Result Fusion)**
    如果ML分类器被启用，系统会根据 `ml_fusion_alpha` 参数将“规则分数”和“模型分数”进行加权平均，得到最终的行为置信度。这使得系统可以在依赖规则的同时，利用机器学习模型进行智能校正。

## 3. 如何配置

手部行为检测的主要参数均在 `config/unified_params.yaml` 的 `behavior_recognition` 和 `detection_rules` 部分。

| 参数 | 区域 | 描述 |
|---|---|---|
| `use_advanced_detection` | `behavior_recognition` | **总开关**。设为`true`以启用基于姿态的检测流程。 |
| `handwashing_min_duration` | `behavior_recognition` | 规则引擎：一次有效洗手所需的最短持续时间（秒）。 |
| `sanitizing_min_duration` | `behavior_recognition` | 规则引擎：一次有效消毒所需的最短持续时间（秒）。 |
| `horizontal_move_std` | `detection_rules` | 规则引擎：判断手部是否在搓动的水平移动标准差阈值。 |
| `use_ml_classifier` | `behavior_recognition` | **ML增强开关**。设为`true`以启用XGBoost分类器。 |
| `ml_model_path` | `behavior_recognition` | 指定XGBoost模型的路径 (如 `models/handwash_xgb.joblib`)。 |
| `ml_fusion_alpha` | `behavior_recognition` | 结果融合权重。`0.5`表示规则和模型各占一半权重。 |
| `confidence_threshold` | `behavior_recognition` | 最终置信度阈值。只有高于此值的行为才会被系统上报。 |

## 4. 未来规划：端到端时序模型

当前的“姿态+特征+混合引擎”方案是一个兼顾了开发速度和效果的务实选择。未来的演进方向是训练一个端到端的时序动作识别模型（如基于Transformer或LSTM的架构）。

- **数据来源**: 系统内置的`DataCollector`模块正在后台持续收集合格的视频片段，为训练端到端模型准备数据集。
- **目标**: 新模型将直接以视频或关键点序列作为输入，输出行为类别。这将有望进一步提升检测的准确率和鲁棒性，减少对复杂规则和特征工程的依赖。
