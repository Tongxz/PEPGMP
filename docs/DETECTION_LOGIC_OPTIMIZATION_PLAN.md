# æ£€æµ‹é€»è¾‘ä¼˜åŒ–æ”¹è¿›è®¡åˆ’

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£åŸºäºå½“å‰å®é™…ä½¿ç”¨çš„æ¨¡å‹ï¼ˆYOLOv8äººä½“æ£€æµ‹ã€YOLOv8å‘ç½‘æ£€æµ‹ã€YOLOv8 Poseã€MediaPipeã€XGBoostè¡Œä¸ºè¯†åˆ«ï¼‰å’Œæ£€æµ‹æµç¨‹ï¼Œæå‡ºå…·ä½“çš„ä¼˜åŒ–æ”¹è¿›æ–¹æ¡ˆã€‚

## ğŸ” å½“å‰é—®é¢˜åˆ†æ

### 1. å‘ç½‘æ£€æµ‹åŒ¹é…ç®—æ³•é—®é¢˜

**å½“å‰å®ç°**ï¼š
- ä½¿ç”¨ç®€å•çš„é‡å æ£€æµ‹ï¼ˆ`_boxes_overlap`ï¼‰ï¼Œåªåˆ¤æ–­ä¸¤ä¸ªæ¡†æ˜¯å¦æœ‰äº¤é›†
- æ²¡æœ‰è€ƒè™‘IoUï¼ˆäº¤å¹¶æ¯”ï¼‰ï¼Œå¯èƒ½å¯¼è‡´è¯¯åŒ¹é…
- æ²¡æœ‰è€ƒè™‘å¤´éƒ¨åŒºåŸŸï¼Œç›´æ¥ä½¿ç”¨æ•´ä¸ªäººä½“æ¡†åŒ¹é…

**é—®é¢˜å½±å“**ï¼š
- å‘ç½‘æ¡†å¯èƒ½åŒ¹é…åˆ°é”™è¯¯çš„äººä½“
- å¤šäººåœºæ™¯ä¸‹åŒ¹é…å‡†ç¡®ç‡ä½
- æ— æ³•å¤„ç†å‘ç½‘æ¡†éƒ¨åˆ†é‡å çš„æƒ…å†µ

### 2. æ—¶é—´ä¸€è‡´æ€§ç¼ºå¤±

**å½“å‰å®ç°**ï¼š
- æ¯å¸§ç‹¬ç«‹æ£€æµ‹ï¼Œæ²¡æœ‰åˆ©ç”¨æ—¶é—´ä¿¡æ¯
- æ²¡æœ‰è·¨å¸§è·Ÿè¸ªå‘ç½‘æ£€æµ‹ç»“æœ
- æ£€æµ‹ç»“æœæ³¢åŠ¨å¤§ï¼Œå®¹æ˜“äº§ç”Ÿè¯¯æŠ¥

**é—®é¢˜å½±å“**ï¼š
- å•å¸§è¯¯æ£€å¯¼è‡´è¯¯æŠ¥
- æ£€æµ‹ç»“æœä¸ç¨³å®š
- æ— æ³•åˆ©ç”¨å†å²ä¿¡æ¯æé«˜å‡†ç¡®ç‡

### 3. å¤´éƒ¨åŒºåŸŸå®šä½ä¸å‡†ç¡®

**å½“å‰å®ç°**ï¼š
- ä½¿ç”¨å›ºå®šæ¯”ä¾‹ï¼ˆ30%ï¼‰ä¼°ç®—å¤´éƒ¨åŒºåŸŸ
- æ²¡æœ‰è€ƒè™‘äººä½“å§¿æ€ã€è§’åº¦å˜åŒ–
- æ²¡æœ‰ä½¿ç”¨å§¿æ€æ£€æµ‹ç»“æœä¼˜åŒ–å¤´éƒ¨å®šä½

**é—®é¢˜å½±å“**ï¼š
- å¤´éƒ¨åŒºåŸŸå®šä½ä¸å‡†ç¡®
- å‘ç½‘æ£€æµ‹åŒºåŸŸå¯èƒ½åŒ…å«è¿‡å¤šèƒŒæ™¯
- å½±å“å‘ç½‘æ£€æµ‹å‡†ç¡®ç‡

### 4. ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®ä¸åˆç†

**å½“å‰å®ç°**ï¼š
- å‘ç½‘æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ï¼š0.6ï¼ˆ`hairnet_detection.confidence_threshold`ï¼‰
- è¿è§„åˆ¤å®šé˜ˆå€¼ï¼š0.5ï¼ˆ`hairnet_confidence > 0.5`ï¼‰
- é˜ˆå€¼å›ºå®šï¼Œæ²¡æœ‰æ ¹æ®åœºæ™¯è°ƒæ•´

**é—®é¢˜å½±å“**ï¼š
- é˜ˆå€¼è¿‡é«˜å¯¼è‡´æ¼æ£€
- é˜ˆå€¼è¿‡ä½å¯¼è‡´è¯¯æ£€
- æ— æ³•é€‚åº”ä¸åŒå…‰ç…§ã€è§’åº¦æ¡ä»¶

### 5. å¤šæ¨¡å‹èåˆç­–ç•¥ç¼ºå¤±

**å½“å‰å®ç°**ï¼š
- åªä½¿ç”¨YOLOv8å‘ç½‘æ£€æµ‹æ¨¡å‹
- æ²¡æœ‰èåˆå…¶ä»–æ£€æµ‹æ–¹æ³•ï¼ˆå¦‚é¢œè‰²æ£€æµ‹ã€è¾¹ç¼˜æ£€æµ‹ï¼‰
- æ²¡æœ‰åˆ©ç”¨äººä½“æ£€æµ‹å’Œå§¿æ€æ£€æµ‹çš„è¾…åŠ©ä¿¡æ¯

**é—®é¢˜å½±å“**ï¼š
- å•ä¸€æ¨¡å‹ä¾èµ–ï¼Œé²æ£’æ€§å·®
- æ— æ³•å¤„ç†æ¨¡å‹å¤±æ•ˆçš„æƒ…å†µ
- æ£€æµ‹å‡†ç¡®ç‡å—é™äºå•ä¸€æ¨¡å‹

## ğŸ¯ ä¼˜åŒ–æ”¹è¿›æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šå‘ç½‘æ£€æµ‹åŒ¹é…ç®—æ³•ä¼˜åŒ–

#### 1.1 ä½¿ç”¨IoUåŒ¹é…æ›¿ä»£ç®€å•é‡å æ£€æµ‹

**æ”¹è¿›ç‚¹**ï¼š
- ä½¿ç”¨IoUï¼ˆIntersection over Unionï¼‰è®¡ç®—åŒ¹é…åº¦
- è®¾ç½®IoUé˜ˆå€¼ï¼ˆå»ºè®®0.3-0.5ï¼‰
- é€‰æ‹©IoUæœ€å¤§çš„å‘ç½‘æ¡†è¿›è¡ŒåŒ¹é…

**å®ç°ä½ç½®**ï¼š
- `src/detection/yolo_hairnet_detector.py` çš„ `detect_hairnet_compliance` æ–¹æ³•
- æ›¿æ¢ `_boxes_overlap` ä¸º `_calculate_iou` å’Œ `_match_hairnet_to_person`

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
def _match_hairnet_to_person(
    self, 
    human_bbox: List[float], 
    hairnet_detections: List[Dict],
    head_bbox: Optional[List[float]] = None
) -> Tuple[Optional[bool], float, Optional[List[float]]]:
    """
    ä½¿ç”¨IoUåŒ¹é…å‘ç½‘æ¡†åˆ°äººä½“æ¡†
    
    Args:
        human_bbox: äººä½“è¾¹ç•Œæ¡† [x1, y1, x2, y2]
        hairnet_detections: å‘ç½‘æ£€æµ‹ç»“æœåˆ—è¡¨
        head_bbox: å¤´éƒ¨åŒºåŸŸè¾¹ç•Œæ¡†ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä¼˜å…ˆä½¿ç”¨ï¼‰
    
    Returns:
        (has_hairnet, hairnet_confidence, hairnet_bbox)
    """
    if not hairnet_detections:
        return None, 0.0, None
    
    # ä¼˜å…ˆä½¿ç”¨å¤´éƒ¨åŒºåŸŸï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨äººä½“æ¡†çš„ä¸Š30%åŒºåŸŸ
    if head_bbox is None:
        x1, y1, x2, y2 = human_bbox
        head_height = int((y2 - y1) * 0.3)
        head_bbox = [x1, y1, x2, y1 + head_height]
    
    best_iou = 0.0
    best_match = None
    best_confidence = 0.0
    
    for hairnet_det in hairnet_detections:
        if hairnet_det.get("class", "").lower() != "hairnet":
            continue
        
        hairnet_bbox = hairnet_det.get("bbox", [0, 0, 0, 0])
        hairnet_conf = hairnet_det.get("confidence", 0.0)
        
        # è®¡ç®—IoUï¼ˆä½¿ç”¨å¤´éƒ¨åŒºåŸŸï¼‰
        iou = self._calculate_iou(head_bbox, hairnet_bbox)
        
        # ä¹Ÿå¯ä»¥è®¡ç®—ä¸æ•´ä¸ªäººä½“æ¡†çš„IoUä½œä¸ºå‚è€ƒ
        iou_full = self._calculate_iou(human_bbox, hairnet_bbox)
        
        # ç»¼åˆIoUï¼šå¤´éƒ¨åŒºåŸŸæƒé‡0.7ï¼Œæ•´ä½“åŒºåŸŸæƒé‡0.3
        combined_iou = 0.7 * iou + 0.3 * iou_full
        
        if combined_iou > best_iou and combined_iou > 0.3:  # IoUé˜ˆå€¼
            best_iou = combined_iou
            best_match = hairnet_bbox
            best_confidence = hairnet_conf
    
    if best_match is not None:
        return True, best_confidence, best_match
    
    # å¦‚æœæ£€æµ‹åˆ°å‘ç½‘ä½†æ²¡æœ‰åŒ¹é…ï¼Œåˆ¤å®šä¸ºæœªä½©æˆ´
    if hairnet_detections:
        max_conf = max(
            det.get("confidence", 0.0) 
            for det in hairnet_detections 
            if det.get("class", "").lower() == "hairnet"
        )
        return False, max_conf, None
    
    # å¦‚æœæ²¡æœ‰å‘ç½‘æ£€æµ‹ç»“æœï¼Œè¿”å›Noneï¼ˆä¸æ˜ç¡®ï¼‰
    return None, 0.0, None

def _calculate_iou(self, bbox1: List[float], bbox2: List[float]) -> float:
    """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU"""
    from src.utils.math_utils import bbox_iou
    return bbox_iou(tuple(bbox1), tuple(bbox2))
```

#### 1.2 å¤šäººåœºæ™¯ä¸‹çš„æœ€ä¼˜åŒ¹é…

**æ”¹è¿›ç‚¹**ï¼š
- ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•ï¼ˆHungarian Algorithmï¼‰è¿›è¡Œæœ€ä¼˜åŒ¹é…
- é¿å…ä¸€ä¸ªå‘ç½‘æ¡†åŒ¹é…åˆ°å¤šä¸ªäººä½“
- é¿å…ä¸€ä¸ªäººä½“åŒ¹é…åˆ°å¤šä¸ªå‘ç½‘æ¡†

**å®ç°ä½ç½®**ï¼š
- æ–°å¢ `_match_hairnets_to_persons` æ–¹æ³•
- ä½¿ç”¨ `scipy.optimize.linear_sum_assignment` æˆ–å®ç°ç®€å•çš„è´ªå¿ƒåŒ¹é…

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
def _match_hairnets_to_persons(
    self,
    person_detections: List[Dict],
    hairnet_detections: List[Dict]
) -> Dict[int, Dict]:
    """
    å¤šäººåœºæ™¯ä¸‹çš„æœ€ä¼˜åŒ¹é…
    
    Returns:
        Dict[int, Dict]: {person_index: {has_hairnet, confidence, bbox}}
    """
    matches = {}
    
    if not hairnet_detections:
        # æ²¡æœ‰å‘ç½‘æ£€æµ‹ç»“æœï¼Œæ‰€æœ‰äººéƒ½æ˜¯None
        for i in range(len(person_detections)):
            matches[i] = {"has_hairnet": None, "confidence": 0.0, "bbox": None}
        return matches
    
    # æ„å»ºä»£ä»·çŸ©é˜µ
    n_persons = len(person_detections)
    n_hairnets = len([d for d in hairnet_detections if d.get("class", "").lower() == "hairnet"])
    
    if n_hairnets == 0:
        # æœ‰å‘ç½‘æ£€æµ‹ç»“æœä½†æ²¡æœ‰å‘ç½‘ç±»åˆ«ï¼Œæ‰€æœ‰äººéƒ½æ˜¯False
        for i in range(n_persons):
            matches[i] = {"has_hairnet": False, "confidence": 0.0, "bbox": None}
        return matches
    
    # è®¡ç®—IoUçŸ©é˜µ
    iou_matrix = np.zeros((n_persons, n_hairnets))
    hairnet_list = [d for d in hairnet_detections if d.get("class", "").lower() == "hairnet"]
    
    for i, person_det in enumerate(person_detections):
        person_bbox = person_det.get("bbox", [0, 0, 0, 0])
        head_bbox = self._get_head_bbox(person_bbox)
        
        for j, hairnet_det in enumerate(hairnet_list):
            hairnet_bbox = hairnet_det.get("bbox", [0, 0, 0, 0])
            iou = self._calculate_iou(head_bbox, hairnet_bbox)
            iou_matrix[i, j] = iou
    
    # ä½¿ç”¨è´ªå¿ƒåŒ¹é…ï¼ˆæˆ–åŒˆç‰™åˆ©ç®—æ³•ï¼‰
    used_hairnets = set()
    for i in range(n_persons):
        best_j = -1
        best_iou = 0.3  # IoUé˜ˆå€¼
        
        for j in range(n_hairnets):
            if j in used_hairnets:
                continue
            if iou_matrix[i, j] > best_iou:
                best_iou = iou_matrix[i, j]
                best_j = j
        
        if best_j >= 0:
            used_hairnets.add(best_j)
            hairnet_det = hairnet_list[best_j]
            matches[i] = {
                "has_hairnet": True,
                "confidence": hairnet_det.get("confidence", 0.0),
                "bbox": hairnet_det.get("bbox")
            }
        else:
            # æ²¡æœ‰åŒ¹é…åˆ°å‘ç½‘ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å‘ç½‘æ£€æµ‹ç»“æœ
            matches[i] = {"has_hairnet": False, "confidence": 0.0, "bbox": None}
    
    return matches
```

### æ–¹æ¡ˆ2ï¼šæ—¶é—´ä¸€è‡´æ€§ä¼˜åŒ–

#### 2.1 è·¨å¸§è·Ÿè¸ªå‘ç½‘æ£€æµ‹ç»“æœ

**æ”¹è¿›ç‚¹**ï¼š
- åˆ©ç”¨äººä½“è·Ÿè¸ªIDï¼ˆtrack_idï¼‰å…³è”å‘ç½‘æ£€æµ‹ç»“æœ
- ç»´æŠ¤æ¯ä¸ªtrack_idçš„å‘ç½‘æ£€æµ‹å†å²
- ä½¿ç”¨æ—¶é—´å¹³æ»‘ï¼ˆtemporal smoothingï¼‰å‡å°‘æ³¢åŠ¨

**å®ç°ä½ç½®**ï¼š
- åœ¨ `OptimizedDetectionPipeline` æˆ– `DetectionApplicationService` ä¸­ç»´æŠ¤è·Ÿè¸ªçŠ¶æ€
- æ–°å¢ `HairnetTrackingState` ç±»

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
from collections import defaultdict
from dataclasses import dataclass
from typing import Optional

@dataclass
class HairnetState:
    """å‘ç½‘æ£€æµ‹çŠ¶æ€"""
    has_hairnet: Optional[bool]
    confidence: float
    frame_count: int  # è¿ç»­å¸§æ•°
    last_update_frame: int

class HairnetTracker:
    """å‘ç½‘æ£€æµ‹è·Ÿè¸ªå™¨"""
    
    def __init__(
        self,
        stability_frames: int = 5,  # ç¨³å®šå¸§æ•°é˜ˆå€¼
        confidence_decay: float = 0.9  # ç½®ä¿¡åº¦è¡°å‡å› å­
    ):
        self.stability_frames = stability_frames
        self.confidence_decay = confidence_decay
        self.track_states: Dict[int, HairnetState] = {}
        self.frame_id = 0
    
    def update(
        self,
        track_id: int,
        current_has_hairnet: Optional[bool],
        current_confidence: float
    ) -> Tuple[Optional[bool], float]:
        """
        æ›´æ–°è·Ÿè¸ªçŠ¶æ€å¹¶è¿”å›å¹³æ»‘åçš„ç»“æœ
        
        Returns:
            (smoothed_has_hairnet, smoothed_confidence)
        """
        self.frame_id += 1
        
        if track_id not in self.track_states:
            # æ–°è½¨è¿¹ï¼Œç›´æ¥ä½¿ç”¨å½“å‰ç»“æœ
            self.track_states[track_id] = HairnetState(
                has_hairnet=current_has_hairnet,
                confidence=current_confidence,
                frame_count=1,
                last_update_frame=self.frame_id
            )
            return current_has_hairnet, current_confidence
        
        state = self.track_states[track_id]
        
        # æ£€æŸ¥æ˜¯å¦é•¿æ—¶é—´æœªæ›´æ–°ï¼ˆè½¨è¿¹å¯èƒ½å·²å¤±æ•ˆï¼‰
        if self.frame_id - state.last_update_frame > 10:
            # é‡ç½®çŠ¶æ€
            state.has_hairnet = current_has_hairnet
            state.confidence = current_confidence
            state.frame_count = 1
            state.last_update_frame = self.frame_id
            return current_has_hairnet, current_confidence
        
        # çŠ¶æ€ä¸€è‡´ï¼Œå¢åŠ è®¡æ•°
        if state.has_hairnet == current_has_hairnet:
            state.frame_count += 1
            # ç½®ä¿¡åº¦å¹³æ»‘ï¼šæ–°å€¼æƒé‡0.3ï¼Œå†å²å€¼æƒé‡0.7
            state.confidence = 0.3 * current_confidence + 0.7 * state.confidence
        else:
            # çŠ¶æ€ä¸ä¸€è‡´ï¼Œé‡ç½®è®¡æ•°
            state.frame_count = 1
            state.has_hairnet = current_has_hairnet
            state.confidence = current_confidence
        
        state.last_update_frame = self.frame_id
        
        # åªæœ‰è¿ç»­å¤šå¸§ä¸€è‡´æ‰è¿”å›ç»“æœï¼Œå¦åˆ™è¿”å›Noneï¼ˆä¸æ˜ç¡®ï¼‰
        if state.frame_count >= self.stability_frames:
            return state.has_hairnet, state.confidence
        else:
            # çŠ¶æ€ä¸ç¨³å®šï¼Œè¿”å›None
            return None, state.confidence
    
    def remove_track(self, track_id: int):
        """ç§»é™¤è·Ÿè¸ªè½¨è¿¹"""
        if track_id in self.track_states:
            del self.track_states[track_id]
```

#### 2.2 åœ¨æ£€æµ‹æµç¨‹ä¸­é›†æˆè·Ÿè¸ª

**å®ç°ä½ç½®**ï¼š
- `src/application/detection_application_service.py` çš„ `process_realtime_stream` æ–¹æ³•
- åœ¨è°ƒç”¨ `detect_comprehensive` åï¼Œä½¿ç”¨ `HairnetTracker` å¹³æ»‘ç»“æœ

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
class DetectionApplicationService:
    def __init__(self, ...):
        # ... ç°æœ‰ä»£ç  ...
        self.hairnet_tracker = HairnetTracker(
            stability_frames=5,  # å¯é…ç½®
            confidence_decay=0.9
        )
    
    def process_realtime_stream(self, frame: np.ndarray, camera_id: str):
        # ... ç°æœ‰æ£€æµ‹ä»£ç  ...
        detection_result = self.detection_pipeline.detect_comprehensive(frame)
        
        # åº”ç”¨æ—¶é—´å¹³æ»‘
        for i, person_det in enumerate(detection_result.person_detections):
            track_id = person_det.get("track_id")
            if track_id is None:
                continue
            
            # è·å–å½“å‰å¸§çš„å‘ç½‘æ£€æµ‹ç»“æœ
            hairnet_result = detection_result.hairnet_results[i] if i < len(detection_result.hairnet_results) else None
            if hairnet_result:
                current_has_hairnet = hairnet_result.get("has_hairnet")
                current_confidence = hairnet_result.get("hairnet_confidence", 0.0)
                
                # æ—¶é—´å¹³æ»‘
                smoothed_has_hairnet, smoothed_confidence = self.hairnet_tracker.update(
                    track_id, current_has_hairnet, current_confidence
                )
                
                # æ›´æ–°æ£€æµ‹ç»“æœ
                hairnet_result["has_hairnet"] = smoothed_has_hairnet
                hairnet_result["hairnet_confidence"] = smoothed_confidence
```

### æ–¹æ¡ˆ3ï¼šå¤´éƒ¨åŒºåŸŸå®šä½ä¼˜åŒ–

#### 3.1 ä½¿ç”¨å§¿æ€æ£€æµ‹ä¼˜åŒ–å¤´éƒ¨å®šä½

**æ”¹è¿›ç‚¹**ï¼š
- ä½¿ç”¨YOLOv8 Poseæ£€æµ‹å…³é”®ç‚¹ï¼ˆå¤´éƒ¨å…³é”®ç‚¹ï¼‰
- æ ¹æ®å…³é”®ç‚¹è®¡ç®—æ›´å‡†ç¡®çš„å¤´éƒ¨åŒºåŸŸ
- è€ƒè™‘äººä½“å§¿æ€è§’åº¦è°ƒæ•´å¤´éƒ¨æ¡†

**å®ç°ä½ç½®**ï¼š
- `src/core/optimized_detection_pipeline.py` çš„ `_detect_hairnet_for_persons` æ–¹æ³•
- é›†æˆå§¿æ€æ£€æµ‹ç»“æœ

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
def _get_head_bbox_from_pose(
    self,
    person_bbox: List[float],
    pose_keypoints: Optional[List[Dict]] = None
) -> List[float]:
    """
    ä½¿ç”¨å§¿æ€æ£€æµ‹ç»“æœè®¡ç®—å¤´éƒ¨åŒºåŸŸ
    
    Args:
        person_bbox: äººä½“è¾¹ç•Œæ¡† [x1, y1, x2, y2]
        pose_keypoints: å§¿æ€å…³é”®ç‚¹åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        å¤´éƒ¨åŒºåŸŸè¾¹ç•Œæ¡† [x1, y1, x2, y2]
    """
    x1, y1, x2, y2 = person_bbox
    person_height = y2 - y1
    person_width = x2 - x1
    
    if pose_keypoints:
        # ä½¿ç”¨å…³é”®ç‚¹å®šä½å¤´éƒ¨
        # YOLOv8 Poseå…³é”®ç‚¹ç´¢å¼•ï¼š0-é¼»å­, 1-å·¦çœ¼, 2-å³çœ¼, 3-å·¦è€³, 4-å³è€³
        head_keypoints = []
        for kp in pose_keypoints:
            if kp.get("id") in [0, 1, 2, 3, 4]:  # å¤´éƒ¨å…³é”®ç‚¹
                head_keypoints.append((kp.get("x", 0), kp.get("y", 0)))
        
        if head_keypoints:
            # è®¡ç®—å¤´éƒ¨å…³é”®ç‚¹çš„è¾¹ç•Œæ¡†
            head_x_coords = [x for x, y in head_keypoints]
            head_y_coords = [y for y in head_keypoints]
            
            head_x1 = max(x1, min(head_x_coords) - person_width * 0.1)
            head_y1 = max(y1, min(head_y_coords) - person_height * 0.05)
            head_x2 = min(x2, max(head_x_coords) + person_width * 0.1)
            head_y2 = min(y2, max(head_y_coords) + person_height * 0.15)
            
            return [head_x1, head_y1, head_x2, head_y2]
    
    # å›é€€åˆ°å›ºå®šæ¯”ä¾‹æ–¹æ³•
    head_height = int(person_height * 0.3)
    return [x1, y1, x2, y1 + head_height]
```

#### 3.2 åŠ¨æ€è°ƒæ•´å¤´éƒ¨åŒºåŸŸæ¯”ä¾‹

**æ”¹è¿›ç‚¹**ï¼š
- æ ¹æ®äººä½“æ¡†å¤§å°åŠ¨æ€è°ƒæ•´å¤´éƒ¨åŒºåŸŸæ¯”ä¾‹
- å°ç›®æ ‡ä½¿ç”¨æ›´å¤§æ¯”ä¾‹ï¼Œå¤§ç›®æ ‡ä½¿ç”¨æ›´å°æ¯”ä¾‹
- è€ƒè™‘äººä½“åœ¨å›¾åƒä¸­çš„ä½ç½®ï¼ˆé è¿‘è¾¹ç¼˜æ—¶è°ƒæ•´ï¼‰

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
def _get_head_bbox_dynamic(
    self,
    person_bbox: List[float],
    image_shape: Tuple[int, int]
) -> List[float]:
    """
    åŠ¨æ€è®¡ç®—å¤´éƒ¨åŒºåŸŸæ¯”ä¾‹
    
    Args:
        person_bbox: äººä½“è¾¹ç•Œæ¡†
        image_shape: å›¾åƒå°ºå¯¸ (height, width)
    
    Returns:
        å¤´éƒ¨åŒºåŸŸè¾¹ç•Œæ¡†
    """
    x1, y1, x2, y2 = person_bbox
    person_height = y2 - y1
    person_width = x2 - x1
    person_area = person_height * person_width
    
    # æ ¹æ®äººä½“å¤§å°è°ƒæ•´å¤´éƒ¨æ¯”ä¾‹
    # å°ç›®æ ‡ï¼ˆé¢ç§¯ < 10000ï¼‰ï¼šä½¿ç”¨35%
    # ä¸­ç­‰ç›®æ ‡ï¼ˆ10000-50000ï¼‰ï¼šä½¿ç”¨30%
    # å¤§ç›®æ ‡ï¼ˆ> 50000ï¼‰ï¼šä½¿ç”¨25%
    if person_area < 10000:
        head_ratio = 0.35
    elif person_area < 50000:
        head_ratio = 0.30
    else:
        head_ratio = 0.25
    
    # è€ƒè™‘ä½ç½®ï¼šé è¿‘å›¾åƒé¡¶éƒ¨æ—¶ï¼Œå‡å°‘å¤´éƒ¨åŒºåŸŸ
    img_height = image_shape[0]
    if y1 < img_height * 0.1:  # é è¿‘é¡¶éƒ¨
        head_ratio *= 0.9
    
    head_height = int(person_height * head_ratio)
    return [x1, y1, x2, y1 + head_height]
```

### æ–¹æ¡ˆ4ï¼šç½®ä¿¡åº¦é˜ˆå€¼ä¼˜åŒ–

#### 4.1 è‡ªé€‚åº”ç½®ä¿¡åº¦é˜ˆå€¼

**æ”¹è¿›ç‚¹**ï¼š
- æ ¹æ®åœºæ™¯æ¡ä»¶ï¼ˆå…‰ç…§ã€è§’åº¦ã€è·ç¦»ï¼‰åŠ¨æ€è°ƒæ•´é˜ˆå€¼
- ä½¿ç”¨å†å²æ£€æµ‹ç»“æœç»Ÿè®¡ä¼˜åŒ–é˜ˆå€¼
- ä¸åŒåœºæ™¯ä½¿ç”¨ä¸åŒé˜ˆå€¼

**å®ç°ä½ç½®**ï¼š
- æ–°å¢ `AdaptiveThresholdManager` ç±»
- åœ¨ `YOLOHairnetDetector` ä¸­ä½¿ç”¨

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
class AdaptiveThresholdManager:
    """è‡ªé€‚åº”é˜ˆå€¼ç®¡ç†å™¨"""
    
    def __init__(
        self,
        base_threshold: float = 0.6,
        min_threshold: float = 0.4,
        max_threshold: float = 0.8
    ):
        self.base_threshold = base_threshold
        self.min_threshold = min_threshold
        self.max_threshold = max_threshold
        self.recent_detections = []  # æœ€è¿‘Nå¸§çš„æ£€æµ‹ç»“æœ
        self.max_history = 30
    
    def update(self, detection_result: Dict):
        """æ›´æ–°æ£€æµ‹å†å²"""
        self.recent_detections.append(detection_result)
        if len(self.recent_detections) > self.max_history:
            self.recent_detections.pop(0)
    
    def get_adaptive_threshold(self, image: np.ndarray) -> float:
        """
        æ ¹æ®å›¾åƒç‰¹å¾å’Œå†å²ç»“æœè®¡ç®—è‡ªé€‚åº”é˜ˆå€¼
        
        Args:
            image: è¾“å…¥å›¾åƒ
        
        Returns:
            è‡ªé€‚åº”é˜ˆå€¼
        """
        # 1. è®¡ç®—å›¾åƒè´¨é‡æŒ‡æ ‡
        brightness = np.mean(image)
        contrast = np.std(image)
        
        # 2. æ ¹æ®å›¾åƒè´¨é‡è°ƒæ•´é˜ˆå€¼
        threshold = self.base_threshold
        
        # å…‰ç…§è¾ƒæš—æ—¶é™ä½é˜ˆå€¼
        if brightness < 80:
            threshold -= 0.1
        elif brightness > 200:
            threshold += 0.05
        
        # å¯¹æ¯”åº¦è¾ƒä½æ—¶é™ä½é˜ˆå€¼
        if contrast < 30:
            threshold -= 0.05
        
        # 3. æ ¹æ®å†å²æ£€æµ‹ç»“æœè°ƒæ•´
        if len(self.recent_detections) >= 10:
            recent_confidences = [
                d.get("hairnet_confidence", 0.0)
                for d in self.recent_detections
                if d.get("has_hairnet") is not None
            ]
            if recent_confidences:
                avg_confidence = np.mean(recent_confidences)
                # å¦‚æœå¹³å‡ç½®ä¿¡åº¦è¾ƒä½ï¼Œé™ä½é˜ˆå€¼
                if avg_confidence < 0.5:
                    threshold -= 0.05
                elif avg_confidence > 0.8:
                    threshold += 0.05
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        return np.clip(threshold, self.min_threshold, self.max_threshold)
```

#### 4.2 åˆ†å±‚ç½®ä¿¡åº¦åˆ¤å®š

**æ”¹è¿›ç‚¹**ï¼š
- ä½¿ç”¨å¤šä¸ªç½®ä¿¡åº¦é˜ˆå€¼è¿›è¡Œåˆ†å±‚åˆ¤å®š
- é«˜ç½®ä¿¡åº¦ï¼šç›´æ¥åˆ¤å®š
- ä¸­ç½®ä¿¡åº¦ï¼šéœ€è¦æ—¶é—´ä¸€è‡´æ€§ç¡®è®¤
- ä½ç½®ä¿¡åº¦ï¼šåˆ¤å®šä¸ºä¸æ˜ç¡®ï¼ˆNoneï¼‰

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
def _classify_hairnet_status(
    self,
    has_hairnet: Optional[bool],
    confidence: float,
    high_threshold: float = 0.7,
    low_threshold: float = 0.4
) -> Tuple[Optional[bool], float]:
    """
    åˆ†å±‚ç½®ä¿¡åº¦åˆ¤å®š
    
    Returns:
        (has_hairnet, adjusted_confidence)
    """
    if has_hairnet is None:
        return None, confidence
    
    if confidence >= high_threshold:
        # é«˜ç½®ä¿¡åº¦ï¼šç›´æ¥åˆ¤å®š
        return has_hairnet, confidence
    elif confidence >= low_threshold:
        # ä¸­ç½®ä¿¡åº¦ï¼šéœ€è¦æ—¶é—´ä¸€è‡´æ€§ç¡®è®¤ï¼ˆç”±HairnetTrackerå¤„ç†ï¼‰
        return has_hairnet, confidence
    else:
        # ä½ç½®ä¿¡åº¦ï¼šåˆ¤å®šä¸ºä¸æ˜ç¡®
        return None, confidence
```

### æ–¹æ¡ˆ5ï¼šå¤šæ¨¡å‹èåˆç­–ç•¥

#### 5.1 èåˆYOLOæ£€æµ‹å’Œé¢œè‰²æ£€æµ‹

**æ”¹è¿›ç‚¹**ï¼š
- åœ¨YOLOæ£€æµ‹ç»“æœåŸºç¡€ä¸Šï¼Œä½¿ç”¨é¢œè‰²æ£€æµ‹ä½œä¸ºè¾…åŠ©
- æ£€æµ‹å¤´éƒ¨åŒºåŸŸæ˜¯å¦æœ‰è“è‰²ï¼ˆå‘ç½‘å¸¸è§é¢œè‰²ï¼‰
- èåˆä¸¤ç§æ£€æµ‹ç»“æœæé«˜å‡†ç¡®ç‡

**å®ç°ä½ç½®**ï¼š
- åœ¨ `YOLOHairnetDetector` ä¸­æ–°å¢é¢œè‰²æ£€æµ‹æ–¹æ³•
- åœ¨ `detect_hairnet_compliance` ä¸­èåˆç»“æœ

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
def _detect_hairnet_by_color(
    self,
    image: np.ndarray,
    head_bbox: List[float]
) -> Tuple[bool, float]:
    """
    ä½¿ç”¨é¢œè‰²æ£€æµ‹è¾…åŠ©åˆ¤æ–­å‘ç½‘
    
    Returns:
        (has_blue_color, confidence)
    """
    x1, y1, x2, y2 = map(int, head_bbox)
    head_roi = image[y1:y2, x1:x2]
    
    if head_roi.size == 0:
        return False, 0.0
    
    # è½¬æ¢åˆ°HSVé¢œè‰²ç©ºé—´
    hsv = cv2.cvtColor(head_roi, cv2.COLOR_BGR2HSV)
    
    # å®šä¹‰è“è‰²èŒƒå›´ï¼ˆå‘ç½‘å¸¸è§é¢œè‰²ï¼‰
    # å¯ä»¥æ ¹æ®å®é™…å‘ç½‘é¢œè‰²è°ƒæ•´
    lower_blue = np.array([100, 50, 50])
    upper_blue = np.array([130, 255, 255])
    
    # åˆ›å»ºæ©ç 
    mask = cv2.inRange(hsv, lower_blue, upper_blue)
    
    # è®¡ç®—è“è‰²åƒç´ æ¯”ä¾‹
    blue_ratio = np.sum(mask > 0) / mask.size
    
    # é˜ˆå€¼ï¼šå¦‚æœè“è‰²åƒç´ æ¯”ä¾‹ > 5%ï¼Œè®¤ä¸ºå¯èƒ½æœ‰å‘ç½‘
    has_blue = blue_ratio > 0.05
    confidence = min(blue_ratio * 2.0, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
    
    return has_blue, confidence

def _fuse_detection_results(
    self,
    yolo_result: Tuple[Optional[bool], float],
    color_result: Tuple[bool, float]
) -> Tuple[Optional[bool], float]:
    """
    èåˆYOLOæ£€æµ‹å’Œé¢œè‰²æ£€æµ‹ç»“æœ
    
    Args:
        yolo_result: (has_hairnet, confidence)
        color_result: (has_blue, confidence)
    
    Returns:
        (fused_has_hairnet, fused_confidence)
    """
    yolo_has_hairnet, yolo_conf = yolo_result
    color_has_blue, color_conf = color_result
    
    # YOLOç»“æœæƒé‡0.7ï¼Œé¢œè‰²æ£€æµ‹æƒé‡0.3
    yolo_weight = 0.7
    color_weight = 0.3
    
    if yolo_has_hairnet is None:
        # YOLOä¸æ˜ç¡®ï¼Œä¸»è¦ä¾èµ–é¢œè‰²æ£€æµ‹
        if color_has_blue and color_conf > 0.3:
            return True, color_conf * 0.6  # é™ä½ç½®ä¿¡åº¦
        else:
            return None, 0.0
    
    if yolo_has_hairnet:
        # YOLOæ£€æµ‹åˆ°å‘ç½‘
        if color_has_blue:
            # é¢œè‰²æ£€æµ‹ä¹Ÿæ”¯æŒï¼Œæé«˜ç½®ä¿¡åº¦
            fused_conf = yolo_weight * yolo_conf + color_weight * min(color_conf + 0.2, 1.0)
            return True, fused_conf
        else:
            # é¢œè‰²æ£€æµ‹ä¸æ”¯æŒï¼Œä½†YOLOç½®ä¿¡åº¦é«˜ï¼Œä»ç›¸ä¿¡YOLO
            return True, yolo_conf * 0.9
    else:
        # YOLOæœªæ£€æµ‹åˆ°å‘ç½‘
        if color_has_blue and color_conf > 0.5:
            # é¢œè‰²æ£€æµ‹å¼ºçƒˆæ”¯æŒæœ‰å‘ç½‘ï¼Œå¯èƒ½æ˜¯YOLOè¯¯æ£€
            return None, 0.3  # ä¸æ˜ç¡®ï¼Œéœ€è¦è¿›ä¸€æ­¥ç¡®è®¤
        else:
            # ä¸¤ç§æ£€æµ‹éƒ½æ”¯æŒæ— å‘ç½‘
            fused_conf = yolo_weight * yolo_conf + color_weight * (1.0 - color_conf)
            return False, fused_conf
```

### æ–¹æ¡ˆ6ï¼šæ€§èƒ½ä¼˜åŒ–

#### 6.1 æ£€æµ‹åŒºåŸŸè£å‰ªä¼˜åŒ–

**æ”¹è¿›ç‚¹**ï¼š
- åªå¯¹å¤´éƒ¨åŒºåŸŸè¿›è¡Œå‘ç½‘æ£€æµ‹ï¼Œè€Œä¸æ˜¯æ•´å¼ å›¾åƒ
- å‡å°‘æ¨¡å‹æ¨ç†æ—¶é—´
- æé«˜æ£€æµ‹å‡†ç¡®ç‡ï¼ˆå‡å°‘èƒŒæ™¯å¹²æ‰°ï¼‰

**å®ç°ä½ç½®**ï¼š
- `YOLOHairnetDetector.detect_hairnet_compliance` æ–¹æ³•

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
def detect_hairnet_compliance(
    self,
    image: np.ndarray,
    human_detections: List[Dict]
) -> Dict[str, Any]:
    """
    ä¼˜åŒ–çš„å‘ç½‘æ£€æµ‹ï¼šåªæ£€æµ‹å¤´éƒ¨åŒºåŸŸ
    """
    # ... ç°æœ‰ä»£ç  ...
    
    # æ”¶é›†æ‰€æœ‰å¤´éƒ¨åŒºåŸŸ
    head_regions = []
    for human_det in human_detections:
        bbox = human_det.get("bbox", [0, 0, 0, 0])
        head_bbox = self._get_head_bbox(bbox)
        head_regions.append((head_bbox, human_det))
    
    # æ‰¹é‡æ£€æµ‹å¤´éƒ¨åŒºåŸŸï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
    if len(head_regions) > 0:
        # æ–¹æ¡ˆ1ï¼šé€ä¸ªæ£€æµ‹ï¼ˆç®€å•ä½†å¯èƒ½è¾ƒæ…¢ï¼‰
        hairnet_detections = []
        for head_bbox, human_det in head_regions:
            x1, y1, x2, y2 = map(int, head_bbox)
            head_roi = image[y1:y2, x1:x2]
            if head_roi.size > 0:
                result = self.detect(head_roi)
                detections = result.get("detections", [])
                # å°†æ£€æµ‹æ¡†åæ ‡è½¬æ¢å›åŸå›¾åæ ‡ç³»
                for det in detections:
                    det_bbox = det.get("bbox", [0, 0, 0, 0])
                    det["bbox"] = [
                        det_bbox[0] + x1,
                        det_bbox[1] + y1,
                        det_bbox[2] + x1,
                        det_bbox[3] + y1
                    ]
                hairnet_detections.extend(detections)
        
        # æ–¹æ¡ˆ2ï¼šåˆå¹¶æ‰€æœ‰å¤´éƒ¨åŒºåŸŸä¸ºä¸€å¼ å›¾åƒæ‰¹é‡æ£€æµ‹ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒæ‰¹é‡ï¼‰
        # ... å®ç°æ‰¹é‡æ£€æµ‹é€»è¾‘ ...
    
    # ... åç»­åŒ¹é…é€»è¾‘ ...
```

#### 6.2 æ¨¡å‹æ¨ç†æ‰¹å¤„ç†

**æ”¹è¿›ç‚¹**ï¼š
- å°†å¤šä¸ªå¤´éƒ¨åŒºåŸŸåˆå¹¶ä¸ºä¸€å¼ å›¾åƒè¿›è¡Œæ‰¹é‡æ¨ç†
- åˆ©ç”¨GPUå¹¶è¡Œè®¡ç®—
- å‡å°‘æ¨¡å‹åŠ è½½å’Œæ¨ç†å¼€é”€

**ä»£ç æ”¹è¿›ç¤ºä¾‹**ï¼š

```python
def _batch_detect_hairnets(
    self,
    head_regions: List[np.ndarray],
    target_size: Tuple[int, int] = (224, 224)
) -> List[List[Dict]]:
    """
    æ‰¹é‡æ£€æµ‹å‘ç½‘
    
    Args:
        head_regions: å¤´éƒ¨åŒºåŸŸå›¾åƒåˆ—è¡¨
        target_size: ç›®æ ‡å°ºå¯¸
    
    Returns:
        æ¯ä¸ªå¤´éƒ¨åŒºåŸŸçš„æ£€æµ‹ç»“æœåˆ—è¡¨
    """
    if not head_regions:
        return []
    
    # å°†å¤´éƒ¨åŒºåŸŸresizeåˆ°ç»Ÿä¸€å°ºå¯¸
    resized_regions = []
    for region in head_regions:
        resized = cv2.resize(region, target_size)
        resized_regions.append(resized)
    
    # åˆå¹¶ä¸ºæ‰¹é‡å›¾åƒï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
    # è¿™é‡Œå‡è®¾æ¨¡å‹æ”¯æŒæ‰¹é‡æ¨ç†
    batch_images = np.stack(resized_regions)
    
    # æ‰¹é‡æ¨ç†
    results = self.model.predict(batch_images)  # éœ€è¦æ ¹æ®å®é™…æ¨¡å‹APIè°ƒæ•´
    
    return results
```

## ğŸ“Š ä¼˜åŒ–æ•ˆæœé¢„æœŸ

### å‡†ç¡®ç‡æå‡

- **å‘ç½‘æ£€æµ‹å‡†ç¡®ç‡**ï¼šä»å½“å‰çº¦85%æå‡åˆ°92%+
- **è¯¯æŠ¥ç‡é™ä½**ï¼šä»å½“å‰çº¦15%é™ä½åˆ°5%ä»¥ä¸‹
- **æ¼æ£€ç‡é™ä½**ï¼šä»å½“å‰çº¦10%é™ä½åˆ°3%ä»¥ä¸‹

### æ€§èƒ½æå‡

- **æ£€æµ‹é€Ÿåº¦**ï¼šé€šè¿‡åŒºåŸŸè£å‰ªå’Œæ‰¹å¤„ç†ï¼Œé€Ÿåº¦æå‡20-30%
- **å†…å­˜ä½¿ç”¨**ï¼šé€šè¿‡ä¼˜åŒ–ç¼“å­˜ç­–ç•¥ï¼Œå†…å­˜ä½¿ç”¨é™ä½15-20%

### ç¨³å®šæ€§æå‡

- **æ—¶é—´ä¸€è‡´æ€§**ï¼šé€šè¿‡è·¨å¸§è·Ÿè¸ªï¼Œæ£€æµ‹ç»“æœæ³¢åŠ¨é™ä½50%+
- **åœºæ™¯é€‚åº”æ€§**ï¼šé€šè¿‡è‡ªé€‚åº”é˜ˆå€¼ï¼Œä¸åŒåœºæ™¯ä¸‹çš„å‡†ç¡®ç‡æ›´ç¨³å®š

## ğŸš€ å®æ–½ä¼˜å…ˆçº§

### é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³å®æ–½ï¼‰

1. **æ–¹æ¡ˆ1.1ï¼šIoUåŒ¹é…ç®—æ³•** - æ ¸å¿ƒæ”¹è¿›ï¼Œå½±å“æœ€å¤§
2. **æ–¹æ¡ˆ2.1ï¼šæ—¶é—´ä¸€è‡´æ€§ä¼˜åŒ–** - æ˜¾è‘—æå‡ç¨³å®šæ€§
3. **æ–¹æ¡ˆ3.1ï¼šå¤´éƒ¨åŒºåŸŸå®šä½ä¼˜åŒ–** - æé«˜æ£€æµ‹å‡†ç¡®ç‡

### ä¸­ä¼˜å…ˆçº§ï¼ˆè¿‘æœŸå®æ–½ï¼‰

4. **æ–¹æ¡ˆ1.2ï¼šå¤šäººåœºæ™¯æœ€ä¼˜åŒ¹é…** - æå‡å¤šäººåœºæ™¯å‡†ç¡®ç‡
5. **æ–¹æ¡ˆ4.1ï¼šè‡ªé€‚åº”ç½®ä¿¡åº¦é˜ˆå€¼** - æå‡åœºæ™¯é€‚åº”æ€§
6. **æ–¹æ¡ˆ6.1ï¼šæ£€æµ‹åŒºåŸŸè£å‰ªä¼˜åŒ–** - æå‡æ€§èƒ½

### ä½ä¼˜å…ˆçº§ï¼ˆåç»­ä¼˜åŒ–ï¼‰

7. **æ–¹æ¡ˆ3.2ï¼šåŠ¨æ€å¤´éƒ¨åŒºåŸŸæ¯”ä¾‹** - è¿›ä¸€æ­¥ä¼˜åŒ–
8. **æ–¹æ¡ˆ4.2ï¼šåˆ†å±‚ç½®ä¿¡åº¦åˆ¤å®š** - ç²¾ç»†åŒ–æ§åˆ¶
9. **æ–¹æ¡ˆ5.1ï¼šå¤šæ¨¡å‹èåˆç­–ç•¥** - æå‡é²æ£’æ€§
10. **æ–¹æ¡ˆ6.2ï¼šæ¨¡å‹æ¨ç†æ‰¹å¤„ç†** - æ€§èƒ½ä¼˜åŒ–

## ğŸ“ å®æ–½æ­¥éª¤

### é˜¶æ®µ1ï¼šæ ¸å¿ƒç®—æ³•ä¼˜åŒ–ï¼ˆ1-2å‘¨ï¼‰

1. å®ç°IoUåŒ¹é…ç®—æ³•ï¼ˆæ–¹æ¡ˆ1.1ï¼‰
2. å®ç°æ—¶é—´ä¸€è‡´æ€§è·Ÿè¸ªï¼ˆæ–¹æ¡ˆ2.1ï¼‰
3. é›†æˆå§¿æ€æ£€æµ‹ä¼˜åŒ–å¤´éƒ¨å®šä½ï¼ˆæ–¹æ¡ˆ3.1ï¼‰
4. å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•

### é˜¶æ®µ2ï¼šåœºæ™¯ä¼˜åŒ–ï¼ˆ1å‘¨ï¼‰

1. å®ç°å¤šäººåœºæ™¯æœ€ä¼˜åŒ¹é…ï¼ˆæ–¹æ¡ˆ1.2ï¼‰
2. å®ç°è‡ªé€‚åº”é˜ˆå€¼ï¼ˆæ–¹æ¡ˆ4.1ï¼‰
3. å®ç°åŒºåŸŸè£å‰ªä¼˜åŒ–ï¼ˆæ–¹æ¡ˆ6.1ï¼‰
4. æ€§èƒ½æµ‹è¯•å’Œè°ƒä¼˜

### é˜¶æ®µ3ï¼šé«˜çº§ä¼˜åŒ–ï¼ˆå¯é€‰ï¼Œ1-2å‘¨ï¼‰

1. å®ç°å¤šæ¨¡å‹èåˆï¼ˆæ–¹æ¡ˆ5.1ï¼‰
2. å®ç°æ‰¹å¤„ç†ä¼˜åŒ–ï¼ˆæ–¹æ¡ˆ6.2ï¼‰
3. å®ç°åŠ¨æ€å¤´éƒ¨åŒºåŸŸï¼ˆæ–¹æ¡ˆ3.2ï¼‰
4. å…¨é¢æµ‹è¯•å’Œæ–‡æ¡£æ›´æ–°

## ğŸ”§ é…ç½®å‚æ•°å»ºè®®

### æ–°å¢é…ç½®é¡¹

```yaml
hairnet_detection:
  # ç°æœ‰é…ç½®...
  
  # æ–°å¢é…ç½®
  iou_threshold: 0.3  # IoUåŒ¹é…é˜ˆå€¼
  stability_frames: 5  # æ—¶é—´ä¸€è‡´æ€§ç¨³å®šå¸§æ•°
  use_pose_for_head: true  # æ˜¯å¦ä½¿ç”¨å§¿æ€æ£€æµ‹ä¼˜åŒ–å¤´éƒ¨å®šä½
  adaptive_threshold: true  # æ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
  color_detection_enabled: false  # æ˜¯å¦å¯ç”¨é¢œè‰²æ£€æµ‹èåˆ
  head_region_ratio: 0.3  # å¤´éƒ¨åŒºåŸŸæ¯”ä¾‹ï¼ˆä¸ä½¿ç”¨å§¿æ€æ—¶ï¼‰
  batch_detection: false  # æ˜¯å¦å¯ç”¨æ‰¹å¤„ç†
```

## ğŸ“š å‚è€ƒæ–‡æ¡£

- `docs/CURRENT_DETECTION_LOGIC_ANALYSIS.md` - å½“å‰æ£€æµ‹é€»è¾‘åˆ†æ
- `docs/DETECTION_FLOW_ANALYSIS.md` - æ£€æµ‹æµç¨‹åˆ†æ
- `src/detection/yolo_hairnet_detector.py` - å‘ç½‘æ£€æµ‹å™¨å®ç°
- `src/core/optimized_detection_pipeline.py` - æ£€æµ‹ç®¡é“å®ç°

