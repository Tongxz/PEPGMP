# 人体行为检测系统技术方案 (v2.0)

## 1. 项目概述

### 1.1 项目背景
本项目旨在开发一个基于计算机视觉的人体行为检测系统，通过摄像头实时识别进入区域内的人员是否佩戴发网、洗手、手部消毒等关键行为。系统设计为在内网环境离线运行，并具备高度的性能和硬件自适应能力。

### 1.2 核心功能
- **多目标检测与追踪**：实时检测和追踪进入监控区域的多个人员。
- **合规性检测**：
  - **发网佩戴检测**：识别人员是否正确佩戴发网。
  - **行为识别**：通过姿态估计和运动分析，识别洗手、消毒等行为。
- **区域管理与流程合规**：支持自定义检测区域，并根据人员在不同区域的停留时长和顺序判断流程合规性。
- **性能自适应**：根据硬件环境（GPU/CPU/MPS）和预设档位（Profiles）自动调整模型和参数。
- **实时预警与数据采集**：对违规行为进行实时告警和抓拍，并为模型迭代自动收集数据。

### 1.3 技术特点
- **模型驱动**：核心检测功能（人体、发网、姿态）均基于YOLOv8模型，确保了高精度和高性能。
- **配置优先**：通过统一的YAML配置文件 (`unified_params.yaml`) 管理所有参数，实现灵活调整。
- **硬件自适应**：支持NVIDIA(CUDA)、Apple Silicon(MPS)和CPU，并能自动选择最优设备。
- **性能卓越**：内置批处理、混合精度（AMP）、智能缓存等多种优化策略。
- **部署友好**：支持Docker容器化部署，简化了环境依赖和安装过程。

## 2. 技术架构

### 2.1 整体架构
系统采用分层架构，各层职责清晰，易于扩展和维护。

```
┌──────────────────────────────────┐
│           前端展示层 (Vue.js)            │
├──────────────────────────────────┤
│           API服务层 (FastAPI)            │
├──────────────────────────────────┤
│ 核心业务层 (流程/规则/区域/追踪)         │
├──────────────────────────────────┤
│ AI模型推理层 (YOLOv8/MediaPipe)          │
├──────────────────────────────────┤
│   配置与自适应层 (Profiles/设备选择)     │
├──────────────────────────────────┤
│         硬件抽象层 (CUDA/MPS/CPU)        │
└──────────────────────────────────┘
```

### 2.2 核心技术栈
- **主要框架**: **PyTorch**
- **目标/姿态检测**: **Ultralytics YOLOv8** (主力), MediaPipe (备用)
- **Web服务**: **FastAPI** + Uvicorn + WebSocket
- **图像处理**: OpenCV-Python
- **配置管理**: YAML + Pydantic (隐式)
- **部署**: Docker

## 3. 核心模块设计

### 3.1 配置与自适应层
这是本系统的一大特色，确保了“一套代码，处处运行”。

- **硬件设备自适应** (`src/config/model_config.py`):
  - 程序启动时自动检测硬件，并按 `mps` → `cuda` → `cpu` 的优先级选择最佳计算设备。
  - 支持通过环境变量 `HBD_DEVICE` 强制指定设备。

- **性能档位 (Profiles)** (`config/unified_params.yaml`):
  - 系统预设了 `fast`, `balanced`, `accurate` 三个档位。
  - 每个档位对应不同的模型（如`yolov8n.pt` vs `yolov8m.pt`）、图像尺寸（`imgsz`）和置信度阈值等参数。
  - 系统通过 `--profile` 命令行参数加载不同配置，实现性能与精度的快速切换。

### 3.2 AI模型推理层

- **人体检测 (`HumanDetector`)**:
  - **技术**: 基于YOLOv8。根据不同`profile`加载`yolov8n/s/m.pt`等不同大小的模型。

- **发网检测 (`YOLOHairnetDetector`)**:
  - **技术**: 基于一个经过专门训练的YOLOv8模型，可直接检测图像中的`hairnet`, `head`, `person`。
  - **优势**: 端到端检测，无需级联，速度快、精度高。

- **姿态与手部检测 (`PoseDetector`)**:
  - **主力技术**: **YOLOv8-Pose** (`yolov8n-pose.pt`)，在GPU/MPS设备上性能优越。
  - **备用技术**: **MediaPipe**，在纯CPU环境下作为高效的备选方案。
  - **自动选择**: 系统会根据当前计算设备自动选择合适的后端 (`pose_detection.backend: auto`)。

### 3.3 核心业务层

- **行为识别 (`BehaviorRecognizer`)**:
  - 结合姿态关键点和运动轨迹，通过**规则引擎**（`detection_rules`）判断洗手、消毒等行为。规则包括手的移动频率、相对距离、持续时间等。
  - （可选）支持加载一个基于XGBoost的轻量级分类模型进行辅助判断。

- **流程合规引擎 (`ProcessEngine`)**:
  - 通过追踪每个人的ID，并结合其在不同预设区域（`regions.json`）的进入/离开时间和顺序，判断其行为是否符合流程规范。
  - **示例规则**: “进入洗手区必须停留超过N秒”、“必须先经过洗手区才能进入烘干区”。

## 4. 性能优化策略

系统内置了多项性能优化措施，大部分可通过 `config/unified_params.yaml` 文件开关。

- **批处理 (Batch Processing)**: 将多帧图像打包成一个批次进行推理，极大提升GPU利用率。
- **自动混合精度 (AMP)**: 在CUDA设备上自动使用FP16进行计算，减少显存占用并提升速度。
- **智能缓存**: 对输入的相似帧进行缓存，避免重复计算。
- **级联检测 (Cascade)**: （可选）使用轻量模型进行普筛，仅对低置信度或关键区域的目标启用重量级模型复核，平衡速度与精度。

## 5. 总结

本系统是一套现代化的、高性能的视觉检测方案。其架构设计充分考虑了实际部署中的多样化硬件和性能需求，通过**配置驱动**和**硬件自适应**两大核心机制，实现了高灵活性、高效率和高可维护性的统一。
