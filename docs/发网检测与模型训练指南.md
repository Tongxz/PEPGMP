# 发网检测与模型训练指南

本指南是关于“发网检测”功能的唯一权威参考，整合了模型的使用、训练、测试和YOLOv8集成细节。

## 1. 功能概述

系统的发网检测功能已**完全迁移并依赖于一个定制训练的YOLOv8模型**。该模型能够直接在图像中检测出`hairnet`(发网)、`head`(头部)和`person`(人员)三个类别，实现了端到端的检测，无需复杂的级联处理。

所有传统的或备用的检测器已从系统中移除，以确保检测结果的一致性和高可靠性。

### YOLOv8检测器的优势
1.  **流程简单**：一步到位完成检测，无需先找人再找头。
2.  **高准确率**：YOLOv8模型在目标检测任务上表现优异。
3.  **性能卓越**：模型经过优化，推理速度快，适合实时应用。
4.  **配置灵活**：支持通过配置文件和命令行轻松调整各项参数。

## 2. 如何使用

### 2.1 核心配置

发网检测器的所有核心参数都通过 `config/unified_params.yaml` 文件进行管理。**请注意**，该文件中 `hairnet_detection` 部分可能包含一些历史遗留参数，对于当前的YOLOv8检测器，只有以下参数是有效的：

```yaml
hairnet_detection:
  model_path: models/hairnet_detection/hairnet_detection.pt # 模型权重路径
  confidence_threshold: 0.6  # 检测置信度阈值
  iou_threshold: 0.5         # NMS的IoU阈值
  device: auto               # 计算设备 (auto, cpu, cuda, mps)
```

### 2.2 在代码中集成

推荐通过工厂模式 `HairnetDetectionFactory` 来创建检测器，这样可以自动加载上述配置文件中的参数。

```python
import cv2
from src.core.hairnet_detection_factory import HairnetDetectionFactory

# 1. 通过工厂创建YOLOv8检测器
detector = HairnetDetectionFactory.create_detector(detector_type='yolo')

# 2. 读取图像并进行检测
image = cv2.imread('path/to/your/image.jpg')
result = detector.detect(image)

# 3. 处理和显示结果
detections = result.get('detections', [])
visualization = result.get('visualization') # 获取带标注的可视化图像

print(f"检测到 {len(detections)} 个目标。")
for det in detections:
    print(f"- 类别: {det.get('class_name')}, 置信度: {det.get('confidence'):.2f}")

if visualization is not None:
    cv2.imshow('Hairnet Detection Result', visualization)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
```

## 3. 如何训练新模型

您可以基于项目的数据集继续优化，或使用自己的数据从头训练模型。整个流程分为：**准备数据 → 开始训练 → 测试验证 → 部署新模型**。

### 3.1 准备数据集

项目使用标准的YOLOv8数据集格式。

1.  **目录结构**：确保您的数据集遵循以下结构：
    ```
    datasets/hairnet/
    ├── train/ (images/ & labels/)
    ├── valid/ (images/ & labels/)
    ├── test/ (images/ & labels/)
    └── data.yaml
    ```
2.  **`data.yaml` 文件**: 该文件是YOLOv8训练的入口，指向训练和验证数据，并定义类别。
    ```yaml
    train: ../datasets/hairnet/train/images
    val: ../datasets/hairnet/valid/images
    nc: 3
    names: ['hairnet', 'head', 'person']
    ```

### 3.2 开始训练

我们提供了便捷的shell脚本来启动训练。

-   **快速开始**:
    ```bash
    # 使用默认参数开始训练
    ./start_training.sh
    ```
-   **自定义训练**:
    ```bash
    # 示例：使用yolov8s权重，在GPU上训练200轮，批次大小为8
    ./start_training.sh --epochs 200 --batch-size 8 --weights models/yolo/yolov8s.pt --device cuda:0
    ```

### 3.3 测试与验证

训练完成后，使用测试脚本来评估模型性能。

```bash
# 使用最新训练好的模型测试单个图片并显示结果
./start_testing.sh --source path/to/image.jpg --view-img
```

### 3.4 部署新模型

1.  训练脚本的输出（包括最佳权重 `best.pt`）通常保存在 `runs/train/<experiment_name>/weights/` 目录下。
2.  将 `best.pt` 文件复制到您期望的模型存放位置，例如 `models/hairnet_detection/`。
3.  更新 `config/unified_params.yaml` 文件中 `hairnet_detection.model_path` 的路径，指向您的新模型文件。
4.  重新启动系统，即可加载并使用您的新模型。

## 4. 故障排除

-   **`FileNotFoundError: ... .pt`**:
    *   **问题**: 找不到模型文件。
    *   **解决**: 检查 `config/unified_params.yaml` 中的 `model_path` 路径是否正确，并确认文件是否存在。

-   **检测结果不准确**:
    *   **问题**: 漏检或误检严重。
    *   **解决**: 尝试调整 `confidence_threshold`。如果效果依然不佳，说明模型泛化能力不足，需要用更多样化的数据进行重新训练。

-   **训练时CUDA内存不足**:
    *   **问题**: `CUDA out of memory`。
    *   **解决**: 在训练时减小批次大小 (`--batch-size`) 或图像尺寸 (`--img-size`)。
