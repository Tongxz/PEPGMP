# GPUç¯å¢ƒä¸‹æ¨¡å‹ç²¾åº¦æå‡æ–¹æ¡ˆ

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

æœ¬æ–¹æ¡ˆè¯¦ç»†é˜è¿°å¦‚ä½•åœ¨GPUç¯å¢ƒä¸‹æå‡æ¨¡å‹ç²¾åº¦ï¼Œä»ç¡¬ä»¶ä¼˜åŒ–ã€æ¨¡å‹ä¼˜åŒ–ã€è®­ç»ƒä¼˜åŒ–åˆ°æ¨ç†ä¼˜åŒ–ï¼Œæä¾›å…¨æ–¹ä½çš„ç²¾åº¦æå‡ç­–ç•¥ã€‚

### æ ¸å¿ƒç­–ç•¥
- **ç¡¬ä»¶ä¼˜åŒ–**: å……åˆ†åˆ©ç”¨GPUç®—åŠ›å’Œå†…å­˜
- **æ¨¡å‹ä¼˜åŒ–**: ä½¿ç”¨æ›´å¤§æ¨¡å‹å’Œé«˜çº§æ¶æ„
- **è®­ç»ƒä¼˜åŒ–**: æ”¹è¿›è®­ç»ƒç­–ç•¥å’Œæ•°æ®å¢å¼º
- **æ¨ç†ä¼˜åŒ–**: ä¼˜åŒ–æ¨ç†æµç¨‹å’Œåå¤„ç†

---

## ğŸ¯ ä¸€ã€ç²¾åº¦æå‡ç­–ç•¥æ¦‚è§ˆ

### 1.1 ç²¾åº¦æå‡ç»´åº¦

```
ç²¾åº¦æå‡
â”œâ”€ ç¡¬ä»¶ä¼˜åŒ– (10-15%æå‡)
â”‚  â”œâ”€ GPUå†…å­˜ç®¡ç†
â”‚  â”œâ”€ æ··åˆç²¾åº¦è®­ç»ƒ
â”‚  â””â”€ å¤šGPUå¹¶è¡Œ
â”œâ”€ æ¨¡å‹ä¼˜åŒ– (15-25%æå‡)
â”‚  â”œâ”€ ä½¿ç”¨æ›´å¤§æ¨¡å‹
â”‚  â”œâ”€ æ¨¡å‹é›†æˆ
â”‚  â””â”€ çŸ¥è¯†è’¸é¦
â”œâ”€ è®­ç»ƒä¼˜åŒ– (20-30%æå‡)
â”‚  â”œâ”€ æ•°æ®å¢å¼º
â”‚  â”œâ”€ æŸå¤±å‡½æ•°ä¼˜åŒ–
â”‚  â””â”€ å­¦ä¹ ç‡è°ƒåº¦
â””â”€ æ¨ç†ä¼˜åŒ– (5-10%æå‡)
   â”œâ”€ æµ‹è¯•æ—¶å¢å¼º
   â”œâ”€ å¤šå°ºåº¦æ¨ç†
   â””â”€ åå¤„ç†ä¼˜åŒ–
```

### 1.2 é¢„æœŸæ•ˆæœ

| ä¼˜åŒ–ç­–ç•¥ | ç²¾åº¦æå‡ | é€Ÿåº¦å½±å“ | éš¾åº¦ |
|----------|----------|----------|------|
| æ··åˆç²¾åº¦è®­ç»ƒ | +2-5% | +10-20% | ä½ |
| ä½¿ç”¨æ›´å¤§æ¨¡å‹ | +5-10% | -20-30% | ä½ |
| æ¨¡å‹é›†æˆ | +8-15% | -50% | ä¸­ |
| æ•°æ®å¢å¼º | +5-8% | æ— å½±å“ | ä¸­ |
| æµ‹è¯•æ—¶å¢å¼º | +3-5% | -30-40% | ä½ |
| çŸ¥è¯†è’¸é¦ | +3-7% | +20-30% | é«˜ |

---

## âš¡ äºŒã€ç¡¬ä»¶ä¼˜åŒ–ç­–ç•¥

### 2.1 GPUå†…å­˜ç®¡ç†ä¼˜åŒ–

#### é—®é¢˜åˆ†æ
å½“å‰ç³»ç»Ÿåœ¨GPUç¯å¢ƒä¸‹å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- GPUå†…å­˜æœªå……åˆ†åˆ©ç”¨
- æ‰¹å¤„ç†å¤§å°è®¾ç½®ä¿å®ˆ
- å†…å­˜ç¢ç‰‡åŒ–ä¸¥é‡

#### ä¼˜åŒ–æ–¹æ¡ˆ

**ä»£ç ä½ç½®**: `src/utils/gpu_acceleration.py:135-178`

```python
def _apply_cuda_optimizations(self, device_info: Dict[str, Any]) -> list:
    """åº”ç”¨CUDAä¼˜åŒ–è®¾ç½®"""
    optimizations = []

    # 1. ç¯å¢ƒå˜é‡ä¼˜åŒ–
    cuda_env = {
        "CUDA_LAUNCH_BLOCKING": "0",  # å¼‚æ­¥æ‰§è¡Œ
        "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:512,roundup_power2_divisions:16",
        "CUBLAS_WORKSPACE_CONFIG": ":16:8",
        "CUDA_MODULE_LOADING": "LAZY",
        "TORCH_CUDNN_V8_API_ENABLED": "1",
    }

    # 2. CuDNNä¼˜åŒ–
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False

    # 3. TF32ä¼˜åŒ– (Ampereæ¶æ„)
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True

    # 4. å†…å­˜ç®¡ç†
    torch.cuda.empty_cache()

    return optimizations
```

#### åŠ¨æ€æ‰¹å¤„ç†å¤§å°è°ƒæ•´

```python
def _calculate_optimal_batch_size(self, device_info: Dict[str, Any]) -> int:
    """è®¡ç®—æœ€ä¼˜æ‰¹å¤„ç†å¤§å°"""
    if device_info["backend"] == "cuda":
        memory_gb = device_info.get("gpu_memory_gb", 4)
        if memory_gb >= 24:
            return 32  # å¤§æ˜¾å­˜GPU
        elif memory_gb >= 16:
            return 24
        elif memory_gb >= 12:
            return 16
        elif memory_gb >= 8:
            return 12
        elif memory_gb >= 6:
            return 8
        else:
            return 4
    elif device_info["backend"] == "mps":
        return 8  # MPSä¿å®ˆè®¾ç½®
    else:
        return min(os.cpu_count() or 4, 8)
```

#### å†…å­˜ç›‘æ§å’Œä¼˜åŒ–

```python
def monitor_gpu_memory(self):
    """ç›‘æ§GPUå†…å­˜ä½¿ç”¨"""
    import torch

    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        max_allocated = torch.cuda.max_memory_allocated() / 1024**3

        logger.info(f"GPUå†…å­˜ä½¿ç”¨: {allocated:.2f}GB / {reserved:.2f}GB (å³°å€¼: {max_allocated:.2f}GB)")

        # å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜æ—¶æ¸…ç†ç¼“å­˜
        if allocated > 0.9 * reserved:
            torch.cuda.empty_cache()
            logger.warning("GPUå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå·²æ¸…ç†ç¼“å­˜")
```

### 2.2 æ··åˆç²¾åº¦è®­ç»ƒ (AMP)

#### åŸç†
æ··åˆç²¾åº¦è®­ç»ƒä½¿ç”¨FP16è¿›è¡Œå‰å‘ä¼ æ’­å’Œæ¢¯åº¦è®¡ç®—ï¼Œä½¿ç”¨FP32è¿›è¡Œå‚æ•°æ›´æ–°ï¼Œåœ¨ä¿æŒç²¾åº¦çš„åŒæ—¶æå‡è®­ç»ƒé€Ÿåº¦ã€‚

#### å®ç°æ–¹æ¡ˆ

```python
from torch.cuda.amp import autocast, GradScaler

class MixedPrecisionTrainer:
    """æ··åˆç²¾åº¦è®­ç»ƒå™¨"""

    def __init__(self, model, optimizer):
        self.model = model
        self.optimizer = optimizer
        self.scaler = GradScaler()

    def train_step(self, images, labels):
        """è®­ç»ƒæ­¥éª¤"""
        self.optimizer.zero_grad()

        # å‰å‘ä¼ æ’­ä½¿ç”¨æ··åˆç²¾åº¦
        with autocast():
            outputs = self.model(images)
            loss = self.criterion(outputs, labels)

        # åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°
        self.scaler.scale(loss).backward()
        self.scaler.step(self.optimizer)
        self.scaler.update()

        return loss.item()
```

#### é…ç½®

```yaml
# config/unified_params.yaml
system:
  enable_amp: true              # å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦
  amp_opt_level: "O1"           # ä¼˜åŒ–çº§åˆ«
  amp_loss_scale: 128.0         # æŸå¤±ç¼©æ”¾å› å­
```

#### æ€§èƒ½æå‡
- **è®­ç»ƒé€Ÿåº¦**: +30-50%
- **å†…å­˜èŠ‚çœ**: -40-50%
- **ç²¾åº¦å½±å“**: Â±0.5% (å¯å¿½ç•¥)

### 2.3 å¤šGPUå¹¶è¡Œè®­ç»ƒ

#### æ•°æ®å¹¶è¡Œ (Data Parallel)

```python
import torch.nn as nn
from torch.nn.parallel import DataParallel

# å•GPUè®­ç»ƒ
model = YOLO("yolov8m.pt")

# å¤šGPUæ•°æ®å¹¶è¡Œ
if torch.cuda.device_count() > 1:
    model = DataParallel(model)
    logger.info(f"ä½¿ç”¨{torch.cuda.device_count()}ä¸ªGPUè¿›è¡Œæ•°æ®å¹¶è¡Œè®­ç»ƒ")
```

#### åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ (DDP)

```python
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

def setup_ddp():
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ"""
    dist.init_process_group(backend='nccl')
    rank = dist.get_rank()
    world_size = dist.get_world_size()

    # è®¾ç½®å½“å‰è®¾å¤‡
    torch.cuda.set_device(rank)
    device = torch.device(f'cuda:{rank}')

    return device, rank, world_size

def train_with_ddp():
    """ä½¿ç”¨DDPè®­ç»ƒ"""
    device, rank, world_size = setup_ddp()

    # åˆ›å»ºæ¨¡å‹
    model = YOLO("yolov8m.pt").to(device)
    model = DDP(model, device_ids=[rank])

    # è®­ç»ƒå¾ªç¯
    for epoch in range(num_epochs):
        for batch in dataloader:
            images, labels = batch
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
```

#### æ€§èƒ½æå‡
- **è®­ç»ƒé€Ÿåº¦**: +Nå€ (Nä¸ºGPUæ•°é‡)
- **æ‰¹å¤„ç†å¤§å°**: +Nå€
- **ç²¾åº¦å½±å“**: æ—  (ç†è®ºä¸Šç›¸åŒ)

---

## ğŸ§  ä¸‰ã€æ¨¡å‹ä¼˜åŒ–ç­–ç•¥

### 3.1 ä½¿ç”¨æ›´å¤§æ¨¡å‹

#### æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | mAP@0.5 | é€Ÿåº¦ (FPS) | æ¨èåœºæ™¯ |
|------|--------|---------|------------|----------|
| YOLOv8n | 3.2M | 37.3 | 50-60 | å¿«é€Ÿæ¨ç† |
| YOLOv8s | 11.2M | 44.9 | 30-40 | å¹³è¡¡æ€§èƒ½ |
| YOLOv8m | 25.9M | 50.2 | 20-25 | é«˜ç²¾åº¦ |
| YOLOv8l | 43.7M | 52.9 | 15-20 | è¶…é«˜ç²¾åº¦ |
| YOLOv8x | 68.2M | 53.9 | 10-15 | æè‡´ç²¾åº¦ |

#### å‡çº§æ–¹æ¡ˆ

```yaml
# config/unified_params.yaml
profiles:
  fast:
    human_detection:
      model_path: models/yolo/yolov8s.pt

  balanced:
    human_detection:
      model_path: models/yolo/yolov8m.pt  # å‡çº§åˆ°Medium

  accurate:
    human_detection:
      model_path: models/yolo/yolov8l.pt  # å‡çº§åˆ°Large
      max_detections: 20
    cascade:
      enable: true
      heavy_weights: models/yolo/yolov8x.pt  # çº§è”ä½¿ç”¨XLarge
```

#### ç²¾åº¦æå‡é¢„æœŸ
- YOLOv8s â†’ YOLOv8m: +5-7%
- YOLOv8m â†’ YOLOv8l: +3-5%
- YOLOv8l â†’ YOLOv8x: +1-2%

### 3.2 æ¨¡å‹é›†æˆ (Ensemble)

#### ç­–ç•¥
ä½¿ç”¨å¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœè¿›è¡ŒæŠ•ç¥¨æˆ–åŠ æƒå¹³å‡ã€‚

#### å®ç°æ–¹æ¡ˆ

```python
class ModelEnsemble:
    """æ¨¡å‹é›†æˆ"""

    def __init__(self, model_paths, weights=None):
        self.models = []
        self.weights = weights or [1.0] * len(model_paths)

        # åŠ è½½å¤šä¸ªæ¨¡å‹
        for path in model_paths:
            model = YOLO(path)
            model.to(self.device)
            model.eval()
            self.models.append(model)

    def predict(self, image):
        """é›†æˆé¢„æµ‹"""
        predictions = []

        for model in self.models:
            with torch.no_grad():
                pred = model(image)
                predictions.append(pred)

        # åŠ æƒå¹³å‡
        ensemble_pred = self._weighted_average(predictions, self.weights)

        return ensemble_pred

    def _weighted_average(self, predictions, weights):
        """åŠ æƒå¹³å‡"""
        total_weight = sum(weights)

        # åˆå¹¶è¾¹ç•Œæ¡†
        all_boxes = []
        all_scores = []
        all_classes = []

        for pred, weight in zip(predictions, weights):
            boxes = pred.boxes.xyxy.cpu().numpy()
            scores = pred.boxes.conf.cpu().numpy() * weight
            classes = pred.boxes.cls.cpu().numpy()

            all_boxes.extend(boxes)
            all_scores.extend(scores)
            all_classes.extend(classes)

        # NMS
        final_boxes = self._nms(all_boxes, all_scores, all_classes)

        return final_boxes
```

#### é›†æˆé…ç½®

```yaml
# config/unified_params.yaml
ensemble:
  enable: true
  models:
    - path: models/yolo/yolov8s.pt
      weight: 0.3
    - path: models/yolo/yolov8m.pt
      weight: 0.4
    - path: models/yolo/yolov8l.pt
      weight: 0.3
  nms_threshold: 0.5
  confidence_threshold: 0.4
```

#### ç²¾åº¦æå‡é¢„æœŸ
- 2æ¨¡å‹é›†æˆ: +3-5%
- 3æ¨¡å‹é›†æˆ: +5-8%
- 5æ¨¡å‹é›†æˆ: +8-12%

### 3.3 çŸ¥è¯†è’¸é¦ (Knowledge Distillation)

#### åŸç†
ä½¿ç”¨å¤§æ¨¡å‹(æ•™å¸ˆ)æŒ‡å¯¼å°æ¨¡å‹(å­¦ç”Ÿ)è®­ç»ƒï¼Œåœ¨ä¿æŒå°æ¨¡å‹é€Ÿåº¦çš„åŒæ—¶æå‡ç²¾åº¦ã€‚

#### å®ç°æ–¹æ¡ˆ

```python
class KnowledgeDistillation:
    """çŸ¥è¯†è’¸é¦"""

    def __init__(self, teacher_model, student_model, temperature=3.0, alpha=0.7):
        self.teacher = teacher_model
        self.student = student_model
        self.temperature = temperature
        self.alpha = alpha

        # å†»ç»“æ•™å¸ˆæ¨¡å‹
        for param in self.teacher.parameters():
            param.requires_grad = False

    def distillation_loss(self, student_outputs, teacher_outputs, labels):
        """è’¸é¦æŸå¤±"""
        # è½¯æ ‡ç­¾æŸå¤± (KLæ•£åº¦)
        soft_loss = F.kl_div(
            F.log_softmax(student_outputs / self.temperature, dim=1),
            F.softmax(teacher_outputs / self.temperature, dim=1),
            reduction='batchmean'
        ) * (self.temperature ** 2)

        # ç¡¬æ ‡ç­¾æŸå¤± (äº¤å‰ç†µ)
        hard_loss = F.cross_entropy(student_outputs, labels)

        # ç»„åˆæŸå¤±
        total_loss = self.alpha * soft_loss + (1 - self.alpha) * hard_loss

        return total_loss

    def train_step(self, images, labels):
        """è®­ç»ƒæ­¥éª¤"""
        # æ•™å¸ˆæ¨¡å‹é¢„æµ‹
        with torch.no_grad():
            teacher_outputs = self.teacher(images)

        # å­¦ç”Ÿæ¨¡å‹é¢„æµ‹
        student_outputs = self.student(images)

        # è®¡ç®—è’¸é¦æŸå¤±
        loss = self.distillation_loss(student_outputs, teacher_outputs, labels)

        return loss
```

#### ç²¾åº¦æå‡é¢„æœŸ
- å°æ¨¡å‹ç²¾åº¦æå‡: +5-10%
- é€Ÿåº¦å½±å“: æ—  (æ¨ç†æ—¶åªä½¿ç”¨å­¦ç”Ÿæ¨¡å‹)

---

## ğŸ“ å››ã€è®­ç»ƒä¼˜åŒ–ç­–ç•¥

### 4.1 æ•°æ®å¢å¼º

#### å¢å¼ºç­–ç•¥

```python
import torchvision.transforms as transforms

class AdvancedAugmentation:
    """é«˜çº§æ•°æ®å¢å¼º"""

    def __init__(self):
        self.train_transform = transforms.Compose([
            # å‡ ä½•å˜æ¢
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.2),
            transforms.RandomRotation(degrees=15),
            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),

            # é¢œè‰²å¢å¼º
            transforms.ColorJitter(
                brightness=0.3,
                contrast=0.3,
                saturation=0.3,
                hue=0.1
            ),

            # å™ªå£°å’Œæ¨¡ç³Š
            transforms.RandomApply([
                transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))
            ], p=0.3),

            # å½’ä¸€åŒ–
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

    def __call__(self, image):
        return self.train_transform(image)
```

#### å¢å¼ºé…ç½®

```yaml
# config/unified_params.yaml
data_augmentation:
  enabled: true
  geometric:
    - horizontal_flip: 0.5
    - vertical_flip: 0.2
    - rotation: 15
    - translation: 0.1
  color:
    - brightness: 0.3
    - contrast: 0.3
    - saturation: 0.3
    - hue: 0.1
  noise:
    - gaussian_blur: 0.3
    - random_noise: 0.2
```

#### ç²¾åº¦æå‡é¢„æœŸ
- åŸºç¡€å¢å¼º: +3-5%
- é«˜çº§å¢å¼º: +5-8%

### 4.2 æŸå¤±å‡½æ•°ä¼˜åŒ–

#### Focal Loss

```python
import torch.nn.functional as F

class FocalLoss(nn.Module):
    """Focal Loss - è§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜"""

    def __init__(self, alpha=0.25, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        return focal_loss.mean()
```

#### IoU Loss

```python
class IoULoss(nn.Module):
    """IoU Loss - ç›´æ¥ä¼˜åŒ–IoUæŒ‡æ ‡"""

    def __init__(self):
        super().__init__()

    def forward(self, pred_boxes, target_boxes):
        # è®¡ç®—IoU
        iou = self._compute_iou(pred_boxes, target_boxes)

        # IoU Loss
        iou_loss = 1 - iou

        return iou_loss.mean()

    def _compute_iou(self, boxes1, boxes2):
        """è®¡ç®—IoU"""
        # å®ç°IoUè®¡ç®—
        pass
```

#### ç»„åˆæŸå¤±

```python
class CombinedLoss(nn.Module):
    """ç»„åˆæŸå¤±å‡½æ•°"""

    def __init__(self, weights=None):
        super().__init__()
        self.weights = weights or {
            'cls': 1.0,
            'box': 5.0,
            'obj': 1.0
        }

        self.cls_loss = FocalLoss()
        self.box_loss = IoULoss()
        self.obj_loss = nn.BCEWithLogitsLoss()

    def forward(self, predictions, targets):
        # åˆ†ç±»æŸå¤±
        cls_loss = self.cls_loss(predictions['cls'], targets['cls'])

        # è¾¹ç•Œæ¡†æŸå¤±
        box_loss = self.box_loss(predictions['box'], targets['box'])

        # ç›®æ ‡æŸå¤±
        obj_loss = self.obj_loss(predictions['obj'], targets['obj'])

        # ç»„åˆæŸå¤±
        total_loss = (
            self.weights['cls'] * cls_loss +
            self.weights['box'] * box_loss +
            self.weights['obj'] * obj_loss
        )

        return total_loss
```

### 4.3 å­¦ä¹ ç‡è°ƒåº¦

#### Cosine Annealing

```python
from torch.optim.lr_scheduler import CosineAnnealingLR

# åˆ›å»ºä¼˜åŒ–å™¨
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)

# å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler = CosineAnnealingLR(
    optimizer,
    T_max=100,  # æœ€å¤§è¿­ä»£æ¬¡æ•°
    eta_min=1e-6  # æœ€å°å­¦ä¹ ç‡
)

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    # è®­ç»ƒ
    train_one_epoch(model, optimizer, train_loader)

    # æ›´æ–°å­¦ä¹ ç‡
    scheduler.step()
```

#### Warmup + Cosine Annealing

```python
from torch.optim.lr_scheduler import LinearLR, SequentialLR

def create_scheduler(optimizer, num_epochs, warmup_epochs=5):
    """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
    # Warmupé˜¶æ®µ
    warmup_scheduler = LinearLR(
        optimizer,
        start_factor=0.1,
        end_factor=1.0,
        total_iters=warmup_epochs
    )

    # Cosine Annealingé˜¶æ®µ
    cosine_scheduler = CosineAnnealingLR(
        optimizer,
        T_max=num_epochs - warmup_epochs,
        eta_min=1e-6
    )

    # ç»„åˆè°ƒåº¦å™¨
    scheduler = SequentialLR(
        optimizer,
        schedulers=[warmup_scheduler, cosine_scheduler],
        milestones=[warmup_epochs]
    )

    return scheduler
```

#### ç²¾åº¦æå‡é¢„æœŸ
- åˆç†çš„å­¦ä¹ ç‡è°ƒåº¦: +2-5%

---

## ğŸš€ äº”ã€æ¨ç†ä¼˜åŒ–ç­–ç•¥

### 5.1 æµ‹è¯•æ—¶å¢å¼º (TTA)

#### å¤šå°ºåº¦æ¨ç†

```python
class TestTimeAugmentation:
    """æµ‹è¯•æ—¶å¢å¼º"""

    def __init__(self, model, scales=[0.8, 1.0, 1.2]):
        self.model = model
        self.scales = scales

    def predict(self, image):
        """å¤šå°ºåº¦é¢„æµ‹"""
        predictions = []

        for scale in self.scales:
            # ç¼©æ”¾å›¾åƒ
            h, w = image.shape[:2]
            new_h, new_w = int(h * scale), int(w * scale)
            scaled_image = cv2.resize(image, (new_w, new_h))

            # é¢„æµ‹
            with torch.no_grad():
                pred = self.model(scaled_image)
                predictions.append(pred)

        # åˆå¹¶é¢„æµ‹ç»“æœ
        final_pred = self._merge_predictions(predictions, self.scales)

        return final_pred

    def _merge_predictions(self, predictions, scales):
        """åˆå¹¶å¤šå°ºåº¦é¢„æµ‹"""
        # å®ç°é¢„æµ‹åˆå¹¶é€»è¾‘
        pass
```

#### å¤šè§’åº¦æ¨ç†

```python
def multi_angle_inference(model, image):
    """å¤šè§’åº¦æ¨ç†"""
    predictions = []

    # åŸå§‹å›¾åƒ
    pred_0 = model(image)
    predictions.append(pred_0)

    # æ°´å¹³ç¿»è½¬
    image_flip = cv2.flip(image, 1)
    pred_180 = model(image_flip)
    # ç¿»è½¬é¢„æµ‹ç»“æœ
    pred_180 = flip_predictions(pred_180)
    predictions.append(pred_180)

    # åˆå¹¶é¢„æµ‹
    final_pred = merge_predictions(predictions)

    return final_pred
```

#### ç²¾åº¦æå‡é¢„æœŸ
- å¤šå°ºåº¦TTA: +3-5%
- å¤šè§’åº¦TTA: +2-3%
- ç»„åˆTTA: +5-8%

### 5.2 æ¨¡å‹é‡åŒ–

#### INT8é‡åŒ–

```python
import torch.quantization as quantization

def quantize_model(model):
    """é‡åŒ–æ¨¡å‹"""
    # è®¾ç½®é‡åŒ–é…ç½®
    quantization_config = quantization.QConfig(
        activation=quantization.observer.MinMaxObserver.with_args(
            dtype=torch.qint8
        ),
        weight=quantization.observer.MinMaxObserver.with_args(
            dtype=torch.qint8
        )
    )

    # å‡†å¤‡æ¨¡å‹
    model.qconfig = quantization_config
    model_prepared = quantization.prepare(model)

    # æ ¡å‡†
    calibrate_model(model_prepared, calibration_data)

    # è½¬æ¢
    model_quantized = quantization.convert(model_prepared)

    return model_quantized
```

#### ç²¾åº¦å½±å“
- é€Ÿåº¦æå‡: +2-4å€
- å†…å­˜èŠ‚çœ: -75%
- ç²¾åº¦æŸå¤±: -1-3%

### 5.3 åå¤„ç†ä¼˜åŒ–

#### Soft NMS

```python
def soft_nms(boxes, scores, iou_threshold=0.5, sigma=0.5):
    """Soft NMS - è½¯éæå¤§å€¼æŠ‘åˆ¶"""
    keep = []

    while len(boxes) > 0:
        # é€‰æ‹©æœ€é«˜åˆ†
        max_idx = np.argmax(scores)
        keep.append(max_idx)

        # è®¡ç®—IoU
        ious = compute_iou(boxes[max_idx], boxes)

        # æ›´æ–°åˆ†æ•°
        for i in range(len(scores)):
            if i != max_idx:
                scores[i] *= np.exp(-(ious[i] ** 2) / sigma)

        # ç§»é™¤ä½åˆ†æ¡†
        mask = scores > 0.01
        boxes = boxes[mask]
        scores = scores[mask]

    return keep
```

#### ç²¾åº¦æå‡é¢„æœŸ
- Soft NMS: +1-2%
- æ›´å¥½çš„NMSç­–ç•¥: +2-3%

---

## ğŸ“Š å…­ã€å®æ–½è®¡åˆ’

### 6.1 é˜¶æ®µä¸€ï¼šå¿«é€Ÿæå‡ (1-2å‘¨)

#### ç›®æ ‡
å¿«é€Ÿè·å¾—5-10%çš„ç²¾åº¦æå‡

#### ä»»åŠ¡æ¸…å•
- [ ] å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)
- [ ] å‡çº§åˆ°æ›´å¤§æ¨¡å‹ (YOLOv8s â†’ YOLOv8m)
- [ ] ä¼˜åŒ–GPUå†…å­˜ç®¡ç†
- [ ] å¯ç”¨æµ‹è¯•æ—¶å¢å¼º (TTA)

#### é¢„æœŸæ•ˆæœ
- ç²¾åº¦æå‡: +5-10%
- é€Ÿåº¦å½±å“: -10-20%

### 6.2 é˜¶æ®µäºŒï¼šæ·±åº¦ä¼˜åŒ– (2-4å‘¨)

#### ç›®æ ‡
è·å¾—10-20%çš„ç²¾åº¦æå‡

#### ä»»åŠ¡æ¸…å•
- [ ] å®æ–½æ¨¡å‹é›†æˆ
- [ ] ä¼˜åŒ–æ•°æ®å¢å¼ºç­–ç•¥
- [ ] æ”¹è¿›æŸå¤±å‡½æ•°
- [ ] ä¼˜åŒ–å­¦ä¹ ç‡è°ƒåº¦

#### é¢„æœŸæ•ˆæœ
- ç²¾åº¦æå‡: +10-20%
- é€Ÿåº¦å½±å“: -30-50%

### 6.3 é˜¶æ®µä¸‰ï¼šæè‡´ä¼˜åŒ– (4-8å‘¨)

#### ç›®æ ‡
è·å¾—20%ä»¥ä¸Šçš„ç²¾åº¦æå‡

#### ä»»åŠ¡æ¸…å•
- [ ] å®æ–½çŸ¥è¯†è’¸é¦
- [ ] å¤šGPUå¹¶è¡Œè®­ç»ƒ
- [ ] è‡ªå®šä¹‰æ¨¡å‹æ¶æ„
- [ ] å¤§è§„æ¨¡æ•°æ®å¢å¼º

#### é¢„æœŸæ•ˆæœ
- ç²¾åº¦æå‡: +20-30%
- é€Ÿåº¦å½±å“: -50-70%

---

## ğŸ¯ ä¸ƒã€æ¨èé…ç½®

### 7.1 å¿«é€Ÿæå‡é…ç½®

```yaml
# config/unified_params.yaml
system:
  enable_amp: true
  batch_size: 16
  enable_batch_processing: true

profiles:
  accurate:
    human_detection:
      model_path: models/yolo/yolov8m.pt
      confidence_threshold: 0.5
    cascade:
      enable: true
      heavy_weights: models/yolo/yolov8l.pt

inference:
  tta:
    enabled: true
    scales: [0.8, 1.0, 1.2]
    flip: true
```

### 7.2 æè‡´ç²¾åº¦é…ç½®

```yaml
# config/unified_params.yaml
system:
  enable_amp: true
  batch_size: 24
  enable_batch_processing: true
  multi_gpu: true

ensemble:
  enabled: true
  models:
    - path: models/yolo/yolov8m.pt
      weight: 0.3
    - path: models/yolo/yolov8l.pt
      weight: 0.4
    - path: models/yolo/yolov8x.pt
      weight: 0.3

inference:
  tta:
    enabled: true
    scales: [0.6, 0.8, 1.0, 1.2, 1.4]
    flip: true
    rotation: true
```

---

## ğŸ“ˆ å…«ã€æ€§èƒ½ç›‘æ§

### 8.1 ç›‘æ§æŒ‡æ ‡

```python
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        self.metrics = {
            'precision': [],
            'recall': [],
            'mAP': [],
            'fps': [],
            'gpu_memory': [],
            'latency': []
        }

    def update(self, predictions, ground_truth):
        """æ›´æ–°æŒ‡æ ‡"""
        # è®¡ç®—ç²¾åº¦æŒ‡æ ‡
        precision = self._calculate_precision(predictions, ground_truth)
        recall = self._calculate_recall(predictions, ground_truth)
        mAP = self._calculate_map(predictions, ground_truth)

        # æ›´æ–°æŒ‡æ ‡
        self.metrics['precision'].append(precision)
        self.metrics['recall'].append(recall)
        self.metrics['mAP'].append(mAP)

    def report(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        report = {
            'avg_precision': np.mean(self.metrics['precision']),
            'avg_recall': np.mean(self.metrics['recall']),
            'avg_mAP': np.mean(self.metrics['mAP']),
            'avg_fps': np.mean(self.metrics['fps']),
            'avg_gpu_memory': np.mean(self.metrics['gpu_memory']),
            'avg_latency': np.mean(self.metrics['latency'])
        }

        return report
```

### 8.2 å¯è§†åŒ–

```python
import matplotlib.pyplot as plt

def plot_training_curves(metrics):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # ç²¾åº¦æ›²çº¿
    axes[0, 0].plot(metrics['precision'])
    axes[0, 0].set_title('Precision')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Precision')

    # å¬å›ç‡æ›²çº¿
    axes[0, 1].plot(metrics['recall'])
    axes[0, 1].set_title('Recall')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Recall')

    # mAPæ›²çº¿
    axes[1, 0].plot(metrics['mAP'])
    axes[1, 0].set_title('mAP')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('mAP')

    # æŸå¤±æ›²çº¿
    axes[1, 1].plot(metrics['loss'])
    axes[1, 1].set_title('Loss')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Loss')

    plt.tight_layout()
    plt.savefig('training_curves.png')
```

---

## ğŸ‰ ä¹ã€æ€»ç»“

### 9.1 æ ¸å¿ƒè¦ç‚¹

1. **ç¡¬ä»¶ä¼˜åŒ–**: å……åˆ†åˆ©ç”¨GPUç®—åŠ›å’Œå†…å­˜ï¼Œå¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
2. **æ¨¡å‹ä¼˜åŒ–**: ä½¿ç”¨æ›´å¤§æ¨¡å‹ã€æ¨¡å‹é›†æˆã€çŸ¥è¯†è’¸é¦
3. **è®­ç»ƒä¼˜åŒ–**: æ•°æ®å¢å¼ºã€æŸå¤±å‡½æ•°ä¼˜åŒ–ã€å­¦ä¹ ç‡è°ƒåº¦
4. **æ¨ç†ä¼˜åŒ–**: æµ‹è¯•æ—¶å¢å¼ºã€æ¨¡å‹é‡åŒ–ã€åå¤„ç†ä¼˜åŒ–

### 9.2 é¢„æœŸæ•ˆæœ

| ä¼˜åŒ–é˜¶æ®µ | ç²¾åº¦æå‡ | é€Ÿåº¦å½±å“ | å®æ–½éš¾åº¦ |
|----------|----------|----------|----------|
| å¿«é€Ÿæå‡ | +5-10% | -10-20% | ä½ |
| æ·±åº¦ä¼˜åŒ– | +10-20% | -30-50% | ä¸­ |
| æè‡´ä¼˜åŒ– | +20-30% | -50-70% | é«˜ |

### 9.3 æ¨èè·¯çº¿

1. **ç¬¬ä¸€é˜¶æ®µ**: å¯ç”¨AMP + å‡çº§æ¨¡å‹ + ä¼˜åŒ–GPUå†…å­˜
2. **ç¬¬äºŒé˜¶æ®µ**: æ¨¡å‹é›†æˆ + æ•°æ®å¢å¼º + æŸå¤±ä¼˜åŒ–
3. **ç¬¬ä¸‰é˜¶æ®µ**: çŸ¥è¯†è’¸é¦ + å¤šGPUè®­ç»ƒ + è‡ªå®šä¹‰æ¶æ„

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-15
**ç»´æŠ¤è€…**: å¼€å‘å›¢é˜Ÿ
