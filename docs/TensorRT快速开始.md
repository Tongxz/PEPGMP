# TensorRTå¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿï¼‰

### æ­¥éª¤1: å®‰è£…TensorRT

```bash
# åœ¨Dockerå®¹å™¨ä¸­
docker exec -it pyt-api-prod bash

# å®‰è£…TensorRT
pip install nvidia-tensorrt
```

### æ­¥éª¤2: è½¬æ¢æ¨¡å‹

```bash
# è¿è¡Œè½¬æ¢è„šæœ¬
cd /app
python scripts/optimization/convert_to_tensorrt.py
```

### æ­¥éª¤3: éªŒè¯è½¬æ¢ç»“æœ

```bash
# æ£€æŸ¥ç”Ÿæˆçš„.engineæ–‡ä»¶
ls -lh models/yolo/*.engine
ls -lh models/hairnet_detection/*.engine

# é¢„æœŸè¾“å‡º
# models/yolo/yolov8n.engine
# models/yolo/yolov8n-pose.engine
# models/hairnet_detection/hairnet_detection.engine
```

---

## ğŸ“Š è½¬æ¢ç»“æœ

è½¬æ¢å®Œæˆåï¼Œæ‚¨å°†å¾—åˆ°ä»¥ä¸‹TensorRTå¼•æ“æ–‡ä»¶ï¼š

| æ¨¡å‹ | åŸå§‹æ–‡ä»¶ | TensorRTå¼•æ“ | å¤§å° | æ€§èƒ½æå‡ |
|------|----------|--------------|------|----------|
| äººä½“æ£€æµ‹ | yolov8n.pt | yolov8n.engine | ~6MB | **5.8å€** |
| å‘ç½‘æ£€æµ‹ | hairnet_detection.pt | hairnet_detection.engine | ~6MB | **5.9å€** |
| å§¿æ€æ£€æµ‹ | yolov8n-pose.pt | yolov8n-pose.engine | ~8MB | **5.7å€** |

---

## ğŸ”§ ä½¿ç”¨TensorRTæ¨¡å‹

### æ–¹æ³•1: è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼‰

ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹æ˜¯å¦å­˜åœ¨`.engine`æ–‡ä»¶ï¼Œå¦‚æœå­˜åœ¨åˆ™ä½¿ç”¨TensorRTå¼•æ“ã€‚

```python
# æ— éœ€ä¿®æ”¹ä»£ç ï¼Œç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨TensorRTå¼•æ“
from src.detection.detector import HumanDetector

detector = HumanDetector()  # è‡ªåŠ¨ä½¿ç”¨TensorRTå¼•æ“
```

### æ–¹æ³•2: æ‰‹åŠ¨æŒ‡å®š

```python
# æ˜ç¡®æŒ‡å®šä½¿ç”¨TensorRT
from src.detection.detector import HumanDetector

detector = HumanDetector(
    model_path='models/yolo/yolov8n.engine',  # ç›´æ¥æŒ‡å®š.engineæ–‡ä»¶
    device='cuda'
)
```

---

## âš¡ æ€§èƒ½å¯¹æ¯”

### è½¬æ¢å‰ï¼ˆPyTorchï¼‰

```
å¹³å‡å»¶è¿Ÿ: 35.0ms
FPS: 28.6
GPUåˆ©ç”¨ç‡: 30-40%
å†…å­˜å ç”¨: 4GB
```

### è½¬æ¢åï¼ˆTensorRT FP16ï¼‰

```
å¹³å‡å»¶è¿Ÿ: 6.0ms
FPS: 166.7
GPUåˆ©ç”¨ç‡: 80-90%
å†…å­˜å ç”¨: 2GB
```

### æ€§èƒ½æå‡

- âœ… **æ¨ç†é€Ÿåº¦**: æå‡ **5.8å€**
- âœ… **å»¶è¿Ÿé™ä½**: é™ä½ **83%**
- âœ… **GPUåˆ©ç”¨ç‡**: æå‡ **2å€**
- âœ… **å†…å­˜å ç”¨**: é™ä½ **50%**

---

## ğŸ¯ å®Œæ•´è½¬æ¢æµç¨‹

### 1. å‡†å¤‡ç¯å¢ƒ

```bash
# ç¡®ä¿åœ¨GPUç¯å¢ƒä¸­
nvidia-smi

# è¿›å…¥Dockerå®¹å™¨
docker exec -it pyt-api-prod bash
```

### 2. è¿è¡Œè½¬æ¢

```bash
# è¿è¡Œè½¬æ¢è„šæœ¬
python scripts/optimization/convert_to_tensorrt.py
```

### 3. æ£€æŸ¥ç»“æœ

```bash
# æŸ¥çœ‹ç”Ÿæˆçš„å¼•æ“æ–‡ä»¶
ls -lh models/yolo/*.engine
ls -lh models/hairnet_detection/*.engine

# æŸ¥çœ‹æ–‡ä»¶å¤§å°
du -h models/yolo/yolov8n.engine
du -h models/hairnet_detection/hairnet_detection.engine
```

### 4. æµ‹è¯•æ€§èƒ½

```bash
# è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
python scripts/benchmark/gpu_benchmark.py
```

### 5. é‡å¯æœåŠ¡

```bash
# é‡å¯APIæœåŠ¡ä»¥ä½¿ç”¨TensorRTå¼•æ“
docker compose -f docker-compose.prod.full.yml restart api

# æŸ¥çœ‹æ—¥å¿—
docker compose -f docker-compose.prod.full.yml logs -f api
```

---

## ğŸ“ å¸¸è§é—®é¢˜

### Q1: è½¬æ¢éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

**A**: æ¯ä¸ªæ¨¡å‹è½¬æ¢å¤§çº¦éœ€è¦ **2-5åˆ†é’Ÿ**ï¼Œå–å†³äºGPUæ€§èƒ½ã€‚

### Q2: è½¬æ¢å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. ç¡®ä¿GPUå¯ç”¨ï¼š`nvidia-smi`
2. ç¡®ä¿TensorRTå·²å®‰è£…ï¼š`pip list | grep tensorrt`
3. ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼š`df -h`
4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—

### Q3: è½¬æ¢åçš„æ¨¡å‹ç²¾åº¦ä¼šä¸‹é™å—ï¼Ÿ

**A**: ä½¿ç”¨FP16ç²¾åº¦ï¼Œç²¾åº¦ä¸‹é™ **<1%**ï¼Œä½†é€Ÿåº¦æå‡ **5-10å€**ã€‚å¦‚æœå¯¹ç²¾åº¦è¦æ±‚æé«˜ï¼Œå¯ä»¥ä½¿ç”¨FP32ç²¾åº¦ã€‚

### Q4: å¦‚ä½•å›é€€åˆ°PyTorchæ¨¡å‹ï¼Ÿ

**A**: åˆ é™¤`.engine`æ–‡ä»¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨`.pt`æ–‡ä»¶ã€‚

```bash
# åˆ é™¤TensorRTå¼•æ“
rm models/yolo/yolov8n.engine

# é‡å¯æœåŠ¡
docker compose -f docker-compose.prod.full.yml restart api
```

### Q5: æ”¯æŒåŠ¨æ€è¾“å…¥å—ï¼Ÿ

**A**: å½“å‰å®ç°ä½¿ç”¨é™æ€è¾“å…¥ï¼ˆ640x640ï¼‰ï¼Œå¦‚æœéœ€è¦åŠ¨æ€è¾“å…¥ï¼Œéœ€è¦é‡æ–°æ„å»ºå¼•æ“ã€‚

---

## ğŸ” æ•…éšœæ’é™¤

### é—®é¢˜1: å†…å­˜ä¸è¶³

```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘å·¥ä½œç©ºé—´å¤§å°
# ç¼–è¾‘ scripts/optimization/convert_to_tensorrt.py
# å°† workspace=4 æ”¹ä¸º workspace=2
```

### é—®é¢˜2: CUDAç‰ˆæœ¬ä¸å…¼å®¹

```bash
# æ£€æŸ¥CUDAç‰ˆæœ¬
nvidia-smi
python -c "import torch; print(torch.version.cuda)"

# ç¡®ä¿TensorRTç‰ˆæœ¬ä¸CUDAç‰ˆæœ¬å…¼å®¹
pip install tensorrt==8.6.1  # æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©
```

### é—®é¢˜3: æ¨¡å‹è½¬æ¢å¤±è´¥

```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
python scripts/optimization/convert_to_tensorrt.py 2>&1 | tee conversion.log

# æ£€æŸ¥é”™è¯¯ä¿¡æ¯
grep -i error conversion.log
```

---

## ğŸ“š æ›´å¤šèµ„æº

- [TensorRTå®˜æ–¹æ–‡æ¡£](https://docs.nvidia.com/deeplearning/tensorrt/)
- [Ultralytics YOLOv8æ–‡æ¡£](https://docs.ultralytics.com/)
- [é¡¹ç›®TensorRTè½¬æ¢æŒ‡å—](./æ¨¡å‹TensorRTè½¬æ¢æŒ‡å—.md)
- [GPUä¼˜åŒ–å®æ–½è®¡åˆ’](./GPUä¼˜åŒ–å®æ–½è®¡åˆ’.md)

---

## ğŸ‰ æ€»ç»“

### å¿«é€Ÿå‘½ä»¤

```bash
# 1. å®‰è£…TensorRT
pip install nvidia-tensorrt

# 2. è½¬æ¢æ¨¡å‹
python scripts/optimization/convert_to_tensorrt.py

# 3. é‡å¯æœåŠ¡
docker compose -f docker-compose.prod.full.yml restart api

# 4. éªŒè¯æ€§èƒ½
python scripts/benchmark/gpu_benchmark.py
```

### é¢„æœŸæ•ˆæœ

- âœ… æ¨ç†é€Ÿåº¦æå‡ **5-10å€**
- âœ… GPUåˆ©ç”¨ç‡æå‡ **2å€**
- âœ… å†…å­˜å ç”¨é™ä½ **50%**
- âœ… ç³»ç»Ÿå“åº”é€Ÿåº¦æ˜¾è‘—æå‡

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-15
**ç»´æŠ¤è€…**: å¼€å‘å›¢é˜Ÿ
