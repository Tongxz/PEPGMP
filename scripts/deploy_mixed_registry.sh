#!/bin/bash
# æ··åˆéƒ¨ç½²è„šæœ¬ï¼ˆç½‘ç»œéš”ç¦»é€‚é…ç‰ˆï¼‰
# åŠŸèƒ½ï¼šæ„å»º -> (å¯é€‰æ¨é€) -> å¯¼å‡º -> æš‚åœæ¢ç½‘ -> ä¼ è¾“ -> éƒ¨ç½²
# é€‚ç”¨ï¼šå¼€å‘æœºæ— æ³•åŒæ—¶è¿æ¥Registryå’Œç”Ÿäº§ç½‘ç»œçš„æƒ…å†µ

set -e

# --- åŠ è½½ç»Ÿä¸€é…ç½® ---
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
if [ -f "$SCRIPT_DIR/lib/deploy_config.sh" ]; then
    source "$SCRIPT_DIR/lib/deploy_config.sh"
else
    echo "[ERROR] é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $SCRIPT_DIR/lib/deploy_config.sh"
    exit 1
fi

# --- é…ç½®éƒ¨åˆ† ---
REGISTRY="$REGISTRY_URL"
IMAGE_NAME_BACKEND="$BACKEND_IMAGE_NAME"
IMAGE_NAME_FRONTEND="$FRONTEND_IMAGE_NAME"
PRODUCTION_IP="${1}"
PRODUCTION_USER="${2:-ubuntu}"
DEPLOY_DIR="${3:-/home/ubuntu/projects/PEPGMP}"

# ==================== ç‰ˆæœ¬å·é…ç½® ====================
# ç‰ˆæœ¬å·ä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼ï¼ˆå½“å‰æ—¶é—´ï¼‰
# æ”¯æŒæ ¼å¼ï¼š
#   - æ—¥æœŸæ—¶é—´æ ¼å¼: 20251224-1430ï¼ˆé»˜è®¤ï¼‰
#   - è¯­ä¹‰åŒ–ç‰ˆæœ¬: v1.0.0, 1.0.0
#   - æ—¥æœŸæ ¼å¼: 20251224
# ä½¿ç”¨ç¤ºä¾‹:
#   bash scripts/deploy_mixed_registry.sh 192.168.1.100 ubuntu /path v1.0.0
#   æˆ–: VERSION_TAG=v1.0.0 bash scripts/deploy_mixed_registry.sh 192.168.1.100
TAG="${4:-${VERSION_TAG:-$(date +%Y%m%d-%H%M)}}"
FULL_BACKEND_IMAGE="$REGISTRY/$IMAGE_NAME_BACKEND:$TAG"
FULL_FRONTEND_IMAGE="$REGISTRY/$IMAGE_NAME_FRONTEND:$TAG"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

# SSH è¿æ¥å¤ç”¨é…ç½®ï¼ˆControlMasterï¼‰
SSH_CONTROL_PATH="$HOME/.ssh/control-%r@%h:%p"
setup_ssh_control() {
    # åˆ›å»º SSH æ§åˆ¶ç›®å½•
    mkdir -p "$HOME/.ssh"

    # å»ºç«‹ SSH ControlMaster è¿æ¥ï¼ˆå¦‚æœå°šæœªå»ºç«‹ï¼‰
    if ! ssh -O check -o ControlPath="$SSH_CONTROL_PATH" "$PRODUCTION_USER@$PRODUCTION_IP" > /dev/null 2>&1; then
        log_info "å»ºç«‹ SSH è¿æ¥å¤ç”¨ï¼ˆControlMasterï¼‰..."
        ssh -fN -o ControlMaster=yes \
            -o ControlPath="$SSH_CONTROL_PATH" \
            -o ControlPersist=300 \
            -o ServerAliveInterval=60 \
            -o ServerAliveCountMax=3 \
            "$PRODUCTION_USER@$PRODUCTION_IP" 2>/dev/null || {
            log_warning "SSH ControlMaster å»ºç«‹å¤±è´¥ï¼Œå°†ä½¿ç”¨æ™®é€š SSH è¿æ¥"
            log_info "æç¤ºï¼šé…ç½® SSH Key å¯é¿å…å¤šæ¬¡è¾“å…¥å¯†ç "
        }
    else
        log_info "SSH è¿æ¥å¤ç”¨å·²å­˜åœ¨"
    fi
}

cleanup_ssh_control() {
    # å…³é—­ SSH ControlMaster è¿æ¥
    if ssh -O check -o ControlPath="$SSH_CONTROL_PATH" "$PRODUCTION_USER@$PRODUCTION_IP" > /dev/null 2>&1; then
        ssh -O exit -o ControlPath="$SSH_CONTROL_PATH" "$PRODUCTION_USER@$PRODUCTION_IP" > /dev/null 2>&1 || true
    fi
}

# ä½¿ç”¨ rsync ä¼ è¾“æ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
transfer_file_rsync() {
    local src_file="$1"
    local dest_path="$2"
    local max_retries="${3:-3}"
    local retry_count=0

    # æ£€æŸ¥ rsync æ˜¯å¦å¯ç”¨
    if ! command -v rsync > /dev/null 2>&1; then
        log_warning "rsync ä¸å¯ç”¨ï¼Œå›é€€åˆ° scp"
        return 1
    fi

    while [ $retry_count -lt $max_retries ]; do
        if rsync -avP --progress \
            -e "ssh -o ControlPath=$SSH_CONTROL_PATH" \
            "$src_file" "$PRODUCTION_USER@$PRODUCTION_IP:$dest_path" 2>&1; then
            return 0
        else
            retry_count=$((retry_count + 1))
            if [ $retry_count -lt $max_retries ]; then
                log_warning "ä¼ è¾“å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ($retry_count/$max_retries)..."
                sleep 2
            fi
        fi
    done

    return 1
}

# æ¸…ç†è¿œç¨‹æ—§é•œåƒï¼ˆä¿ç•™æœ€è¿‘ N ä¸ªç‰ˆæœ¬ï¼‰
cleanup_old_images() {
    local keep_versions="${1:-3}"  # é»˜è®¤ä¿ç•™æœ€è¿‘ 3 ä¸ªç‰ˆæœ¬
    local image_name="$2"

    log_info "æ¸…ç†æ—§é•œåƒï¼ˆä¿ç•™æœ€è¿‘ $keep_versions ä¸ªç‰ˆæœ¬ï¼‰..."

    ssh -o ControlPath="$SSH_CONTROL_PATH" "$PRODUCTION_USER@$PRODUCTION_IP" << EOF
        set -e
        # è·å–æ‰€æœ‰æ ‡ç­¾ï¼ˆæŒ‰æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
        OLD_IMAGES=\$(docker images --format "{{.Repository}}:{{.Tag}}" --filter "reference=$image_name:*" | \
            grep -v "latest" | \
            sort -r | \
            tail -n +$((keep_versions + 1)))

        if [ -n "\$OLD_IMAGES" ]; then
            echo "åˆ é™¤æ—§é•œåƒ:"
            echo "\$OLD_IMAGES" | while read img; do
                if [ -n "\$img" ]; then
                    echo "  - \$img"
                    docker rmi "\$img" 2>/dev/null || true
                fi
            done
        else
            echo "æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ—§é•œåƒ"
        fi

        # æ¸…ç† dangling images
        docker image prune -f > /dev/null 2>&1 || true
EOF
}

# äº¤äº’å¼ç¡®è®¤å‡½æ•°
wait_for_network_switch() {
    echo ""
    echo -e "${YELLOW}======================================================${NC}"
    echo -e "${YELLOW}   ğŸš§ æš‚åœï¼šè¯·åˆ‡æ¢ç½‘ç»œï¼ ğŸš§${NC}"
    echo -e "${YELLOW}======================================================${NC}"
    echo "å½“å‰é˜¶æ®µå®Œæˆã€‚è¯·æ–­å¼€ Registry ç½‘ç»œï¼Œè¿æ¥åˆ°ç”Ÿäº§ç¯å¢ƒç½‘ç»œã€‚"
    echo "ç›®æ ‡æœåŠ¡å™¨: $PRODUCTION_IP"
    echo ""
    read -p "ç½‘ç»œåˆ‡æ¢å®Œæˆåï¼Œè¯·æŒ‰ [Enter] é”®ç»§ç»­..."
    echo ""
}

# æ£€æŸ¥å‚æ•°
if [ -z "$PRODUCTION_IP" ]; then
    log_error "è¯·æä¾›ç”Ÿäº§æœåŠ¡å™¨IP"
    exit 1
fi

# è®¾ç½® SSH è¿æ¥å¤ç”¨ï¼ˆåœ¨è„šæœ¬å¼€å§‹æ—¶ï¼‰
trap cleanup_ssh_control EXIT INT TERM
setup_ssh_control

echo "========================================================================="
echo "               æ··åˆéƒ¨ç½²æ–¹æ¡ˆï¼ˆç½‘ç»œéš”ç¦»é€‚é…ç‰ˆï¼‰"
echo "========================================================================="
log_info "Registry: $REGISTRY"
log_info "ç‰ˆæœ¬æ ‡ç­¾: $TAG"
log_info "æç¤º: å¯é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æˆ– VERSION_TAG ç¯å¢ƒå˜é‡è‡ªå®šä¹‰ç‰ˆæœ¬å·"
echo ""

# æ£€æŸ¥taræ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ”¯æŒä»ä¸­é—´æ­¥éª¤ç»§ç»­ï¼‰
TAR_FILE_BACKEND="/tmp/pepgmp-backend-$TAG.tar.gz"
TAR_FILE_FRONTEND="/tmp/pepgmp-frontend-$TAG.tar.gz"
SKIP_BUILD=false
if [ -f "$TAR_FILE_BACKEND" ] && [ -f "$TAR_FILE_FRONTEND" ]; then
    log_warning "æ£€æµ‹åˆ°å·²å­˜åœ¨çš„taræ–‡ä»¶:"
    echo "  - $TAR_FILE_BACKEND"
    echo "  - $TAR_FILE_FRONTEND"
    read -p "æ˜¯å¦ä½¿ç”¨ç°æœ‰æ–‡ä»¶è·³è¿‡æ„å»ºæ­¥éª¤? (Y/n): " -n 1 -r
    echo ""
    if [[ ! $REPLY =~ ^[Nn]$ ]]; then
        SKIP_BUILD=true
        log_info "å°†ä½¿ç”¨ç°æœ‰taræ–‡ä»¶ï¼Œè·³è¿‡æ„å»ºå’Œå¯¼å‡ºæ­¥éª¤"
    else
        log_info "å°†é‡æ–°æ„å»ºé•œåƒ"
        rm -f "$TAR_FILE_BACKEND" "$TAR_FILE_FRONTEND"
    fi
fi

# ==================== æ­¥éª¤1: æ„å»ºé•œåƒ (æœ¬åœ°æ‰§è¡Œï¼Œæ— éœ€ç½‘ç»œ) ====================
if [ "$SKIP_BUILD" = "false" ]; then
    log_info "[1/7] æ„å»ºé•œåƒ..."

    # æ¶æ„æ£€æµ‹ä¸æ„å»º
    ARCH=$(uname -m)
    if [ ! -f "Dockerfile.prod" ]; then
        log_error "Dockerfile.prod ä¸å­˜åœ¨"
        exit 1
    fi

    # æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰åŸºç¡€é•œåƒ
    BASE_IMAGE="nvidia/cuda:12.8.0-runtime-ubuntu22.04"
    if ! docker images $BASE_IMAGE --format "{{.Repository}}:{{.Tag}}" | grep -q "$BASE_IMAGE"; then
        log_error "æœ¬åœ°æ²¡æœ‰åŸºç¡€é•œåƒ: $BASE_IMAGE"
        log_info "è¯·å…ˆæ‹‰å–é•œåƒ: docker pull $BASE_IMAGE"
        exit 1
    fi

    log_info "æœ¬åœ°åŸºç¡€é•œåƒå·²æ‰¾åˆ°: $BASE_IMAGE"

# ç”Ÿäº§æ„å»ºä¾èµ–éœ€è¦å¤–ç½‘ä¸‹è½½ï¼ˆPyTorch CUDA wheel / PyPI ä¾èµ–ï¼‰ã€‚
# ç”±äºä½ å½“å‰æ²¡æœ‰å†…éƒ¨é•œåƒæºã€ç§æœ‰ Registry ä¹Ÿä¸å¯ç”¨ï¼Œè¿™é‡Œå¿…é¡»åœ¨â€œå¯ä¸Šç½‘â€çš„ç½‘ç»œç¯å¢ƒä¸‹å®Œæˆæ„å»ºï¼Œ
# æ„å»ºå®Œæˆåå†åˆ‡æ¢åˆ°ç”Ÿäº§ç½‘ç»œè¿›è¡Œ scp ä¼ è¾“ï¼ˆæ··åˆéƒ¨ç½²çš„è®¾è®¡å°±æ˜¯ä¸ºæ­¤æœåŠ¡ï¼‰ã€‚
# ä½¿ç”¨ PyTorch 2.9.1 ç¨³å®šç‰ˆï¼ˆæ”¯æŒ CUDA 12.8 å’Œ sm_120ï¼‰ï¼Œå›ºå®šç‰ˆæœ¬å·ä»¥å……åˆ†åˆ©ç”¨ Docker ç¼“å­˜
TORCH_INSTALL_MODE_DEFAULT="stable"
TORCH_INDEX_URL_DEFAULT="https://download.pytorch.org/whl/cu128"
PIP_MIRROR_DEFAULT="https://pypi.tuna.tsinghua.edu.cn/simple/"
log_info "æ£€æŸ¥æ„å»ºä¾èµ–ä¸‹è½½æºè¿é€šæ€§..."
if ! curl -sf --connect-timeout 5 "$TORCH_INDEX_URL_DEFAULT" > /dev/null 2>&1; then
    log_error "æ— æ³•è®¿é—® PyTorch ä¸‹è½½æº: $TORCH_INDEX_URL_DEFAULT"
    log_error "å½“å‰ç½‘ç»œæ— æ³•å®Œæˆç”Ÿäº§é•œåƒæ„å»ºï¼ˆæ²¡æœ‰å†…éƒ¨é•œåƒæº/Registry ä¹Ÿä¸å¯ç”¨ï¼‰ã€‚"
    log_info "è¯·åˆ‡æ¢åˆ°å¯ä¸Šç½‘ç½‘ç»œï¼ˆä¾‹å¦‚æ‰‹æœºçƒ­ç‚¹/åŠå…¬ç½‘ç»œï¼‰åé‡æ–°æ‰§è¡Œæœ¬è„šæœ¬å®Œæˆæ„å»ºï¼›"
    log_info "æ„å»ºå®Œæˆå¯¼å‡º tar åï¼Œå†æŒ‰æç¤ºåˆ‡å›ç”Ÿäº§ç½‘ç»œæ‰§è¡Œ scp ä¼ è¾“ã€‚"
    exit 1
fi
if ! curl -sf --connect-timeout 5 "$PIP_MIRROR_DEFAULT" > /dev/null 2>&1; then
    log_error "æ— æ³•è®¿é—® PyPI é•œåƒæº: $PIP_MIRROR_DEFAULT"
    log_error "å½“å‰ç½‘ç»œæ— æ³•å®Œæˆç”Ÿäº§é•œåƒæ„å»ºï¼ˆä¾èµ–æ— æ³•ä¸‹è½½ï¼‰ã€‚"
    log_info "è¯·åˆ‡æ¢åˆ°å¯ä¸Šç½‘ç½‘ç»œåé‡æ–°æ‰§è¡Œæœ¬è„šæœ¬ã€‚"
    exit 1
fi
log_success "ä¾èµ–ä¸‹è½½æºå¯è¾¾ï¼Œç»§ç»­æ„å»ºã€‚"

    # æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆDocker Hubï¼‰
    log_info "æ£€æŸ¥ç½‘ç»œè¿æ¥..."
    if ! curl -sf --connect-timeout 3 "https://auth.docker.io" > /dev/null 2>&1; then
        log_warning "æ— æ³•è¿æ¥åˆ° Docker Hubï¼Œå°†ä½¿ç”¨æœ¬åœ°é•œåƒæ„å»º"
        USE_OFFLINE_BUILD=true
    else
        USE_OFFLINE_BUILD=false
    fi

    # å¼€å§‹æ„å»º
    export DOCKER_BUILDKIT=1
    if [ "$ARCH" = "arm64" ] || [ "$ARCH" = "aarch64" ]; then
        log_info "æ£€æµ‹åˆ°ARMæ¶æ„ï¼Œä½¿ç”¨buildxæ„å»ºlinux/amd64..."

        # å…³é”®ï¼šDocker Desktop ä¸­ buildx builder ä¼šç”¨ â€œ*â€ æ ‡è®°å½“å‰ builderï¼ˆä¾‹å¦‚ desktop-linux*ï¼‰ã€‚
        # å¦å¤– builder ä¸ docker context ç»‘å®šï¼šå½“å‰ context=desktop-linux æ—¶ï¼Œä½¿ç”¨ default builder ä¼šæŠ¥é”™ã€‚
        CURRENT_CTX="$(docker context show 2>/dev/null || echo "")"
        BUILDER_NAME="$CURRENT_CTX"
        if ! docker buildx ls | awk '{print $1}' | sed 's/\*$//' | grep -qx "${BUILDER_NAME}"; then
            # fallbackï¼šä¼˜å…ˆ desktop-linuxï¼Œå…¶æ¬¡ default
            if docker buildx ls | awk '{print $1}' | sed 's/\*$//' | grep -qx 'desktop-linux'; then
                BUILDER_NAME="desktop-linux"
            else
                BUILDER_NAME="default"
            fi
        fi
        docker buildx use "${BUILDER_NAME}" > /dev/null 2>&1 || true

        # æ‰§è¡Œæ„å»ºï¼š
        # - Dockerfile.prod ä½¿ç”¨ BASE_IMAGE build-argï¼ˆé»˜è®¤ nvidia/cuda:...ï¼‰
        # - è¿™é‡Œæ˜¾å¼ä¼ å…¥ BASE_IMAGEï¼Œç¡®ä¿ä¸æœ¬åœ°æ£€æŸ¥ä¸€è‡´
        docker buildx build \
          --builder "${BUILDER_NAME}" \
          --platform linux/amd64 \
          --pull=false \
          -f Dockerfile.prod \
          --build-arg BASE_IMAGE="nvidia/cuda:12.8.0-runtime-ubuntu22.04" \
          --build-arg TORCH_INSTALL_MODE="$TORCH_INSTALL_MODE_DEFAULT" \
          --build-arg TORCH_INDEX_URL="$TORCH_INDEX_URL_DEFAULT" \
          -t $FULL_BACKEND_IMAGE \
          --load .

        # æ„å»ºå‰ç«¯é•œåƒï¼ˆåŒæ ·ä½¿ç”¨ buildx è¾“å‡º linux/amd64ï¼‰
        if [ ! -f "Dockerfile.frontend" ]; then
            log_error "Dockerfile.frontend ä¸å­˜åœ¨ï¼Œä½†ç”Ÿäº§éœ€è¦ pepgmp-frontend é•œåƒ"
            exit 1
        fi
        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰å‰ç«¯åŸºç¡€é•œåƒ
        log_info "æ£€æŸ¥å‰ç«¯åŸºç¡€é•œåƒ..."
        if ! docker images | grep -qE "node.*20.*alpine|^node "; then
            log_warning "æœ¬åœ°æœªæ‰¾åˆ° node:20-alpine é•œåƒ"
            log_info "buildx åœ¨ç¦»çº¿ç¯å¢ƒå¯èƒ½æ— æ³•æ„å»ºï¼Œå°è¯•ç»§ç»­..."
        fi

        docker buildx build \
          --builder "${BUILDER_NAME}" \
          --platform linux/amd64 \
          --pull=false \
          -f Dockerfile.frontend \
          --build-arg NODE_IMAGE="node:20-alpine" \
          --build-arg NGINX_IMAGE="nginx:1.27-alpine" \
          --build-arg VITE_API_BASE=/api/v1 \
          --build-arg BASE_URL=/ \
          --build-arg SKIP_TYPE_CHECK=true \
          -t $FULL_FRONTEND_IMAGE \
          --load . || {
            log_error "å‰ç«¯é•œåƒæ„å»ºå¤±è´¥"
            log_info "åŸå› : buildx éœ€è¦åŸºç¡€é•œåƒçš„å…ƒæ•°æ®ï¼Œä½†åœ¨ç¦»çº¿ç¯å¢ƒä¸‹æ— æ³•è·å–"
            log_info "è§£å†³æ–¹æ¡ˆ:"
            log_info "  1. åœ¨å¯è”ç½‘ç¯å¢ƒå…ˆæ‹‰å–: docker pull node:20-alpine nginx:1.27-alpine"
            log_info "  2. æˆ–ä½¿ç”¨ç§æœ‰ Registry çš„é•œåƒ: --build-arg NODE_IMAGE=\$REGISTRY/node:20-alpine"
            log_info "  3. æˆ–æš‚æ—¶è·³è¿‡å‰ç«¯æ„å»ºï¼ˆå¦‚æœå‰ç«¯ä»£ç æœªå˜åŒ–ï¼‰"
            exit 1
          }
    else
        docker build -f Dockerfile.prod -t $FULL_BACKEND_IMAGE .
        if [ ! -f "Dockerfile.frontend" ]; then
            log_error "Dockerfile.frontend ä¸å­˜åœ¨ï¼Œä½†ç”Ÿäº§éœ€è¦ pepgmp-frontend é•œåƒ"
            exit 1
        fi
        docker build -f Dockerfile.frontend \
          --build-arg NODE_IMAGE="node:20-alpine" \
          --build-arg NGINX_IMAGE="nginx:1.27-alpine" \
          --build-arg VITE_API_BASE=/api/v1 \
          --build-arg BASE_URL=/ \
          --build-arg SKIP_TYPE_CHECK=true \
          -t $FULL_FRONTEND_IMAGE .
    fi

    if [ $? -eq 0 ]; then
        log_success "é•œåƒæ„å»ºå®Œæˆ"
    else
        log_error "æ„å»ºå¤±è´¥"
        log_info "æç¤º: å¦‚æœæ˜¯å› ä¸ºç½‘ç»œé—®é¢˜æ— æ³•æ‹‰å–åŸºç¡€é•œåƒï¼Œè¯·ï¼š"
        echo "  1. ç¡®ä¿æœ¬åœ°æœ‰é•œåƒ: docker images | grep nvidia/cuda"
        echo "  2. æˆ–æ‰‹åŠ¨æ‹‰å–: docker pull $BASE_IMAGE"
        exit 1
    fi
    echo ""

    # ==================== æ­¥éª¤2: å°è¯•æ¨é€åˆ° Registry ====================
    log_info "[2/7] æ£€æŸ¥ Registry è¿æ¥å¹¶æ¨é€..."

    # éé˜»å¡æ£€æµ‹ï¼šå¦‚æœèƒ½è¿ä¸Šå°±æ¨ï¼Œè¿ä¸ä¸Šå°±è·³è¿‡
    if curl -sf --connect-timeout 3 "http://$REGISTRY/v2/_catalog" > /dev/null 2>&1; then
        log_info "æ£€æµ‹åˆ° Registry åœ¨çº¿ï¼Œæ­£åœ¨æ¨é€..."
        if docker push $FULL_BACKEND_IMAGE && docker push $FULL_FRONTEND_IMAGE; then
            log_success "é•œåƒå·²å¤‡ä»½åˆ° Registry"
        else
            log_warning "æ¨é€å¤±è´¥ï¼Œä½†è¿™ä¸å½±å“åç»­éƒ¨ç½²"
        fi
    else
        log_warning "âš ï¸  æ— æ³•è¿æ¥ Registry ($REGISTRY)"
        log_warning "   è·³è¿‡æ¨é€æ­¥éª¤ï¼Œä»…ä½¿ç”¨æœ¬åœ° tar åŒ…éƒ¨ç½²"
        log_info "   (è¿™æ˜¯æ­£å¸¸çš„ï¼Œå¦‚æœä½ å½“å‰è¿æ¥çš„æ˜¯ç”Ÿäº§ç½‘ç»œ)"
    fi
    echo ""

    # ==================== æ­¥éª¤3: å¯¼å‡ºé•œåƒ ====================
    log_info "[3/7] å¯¼å‡ºé•œåƒä¸º tar æ–‡ä»¶..."

    docker save $FULL_BACKEND_IMAGE | gzip > $TAR_FILE_BACKEND
    docker save $FULL_FRONTEND_IMAGE | gzip > $TAR_FILE_FRONTEND
    TAR_SIZE_BACKEND=$(ls -lh $TAR_FILE_BACKEND | awk '{print $5}')
    TAR_SIZE_FRONTEND=$(ls -lh $TAR_FILE_FRONTEND | awk '{print $5}')
    log_success "é•œåƒå·²å¯¼å‡º:"
    echo "  - $TAR_FILE_BACKEND ($TAR_SIZE_BACKEND)"
    echo "  - $TAR_FILE_FRONTEND ($TAR_SIZE_FRONTEND)"
    echo ""
else
    log_info "[1-3/7] è·³è¿‡æ„å»ºã€æ¨é€ã€å¯¼å‡ºæ­¥éª¤ï¼ˆä½¿ç”¨ç°æœ‰taræ–‡ä»¶ï¼‰"
    TAR_SIZE_BACKEND=$(ls -lh $TAR_FILE_BACKEND | awk '{print $5}')
    TAR_SIZE_FRONTEND=$(ls -lh $TAR_FILE_FRONTEND | awk '{print $5}')
    log_info "ä½¿ç”¨ç°æœ‰æ–‡ä»¶:"
    echo "  - $TAR_FILE_BACKEND ($TAR_SIZE_BACKEND)"
    echo "  - $TAR_FILE_FRONTEND ($TAR_SIZE_FRONTEND)"
    echo ""
fi

# ==================== æ­¥éª¤4: å…³é”®ç‚¹ - æš‚åœåˆ‡æ¢ç½‘ç»œ ====================

# å…ˆæ£€æµ‹ä¸€ä¸‹ç”Ÿäº§ç½‘ç»œé€šä¸é€šï¼Œå¦‚æœä¸é€šï¼Œè¯´æ˜éœ€è¦åˆ‡æ¢
if ! ping -c 1 -W 2 $PRODUCTION_IP > /dev/null 2>&1; then
    wait_for_network_switch

    # å†æ¬¡æ£€æµ‹
    log_info "æ­£åœ¨æ£€æµ‹ç”Ÿäº§ç½‘ç»œè¿æ¥..."
    while ! ping -c 1 -W 2 $PRODUCTION_IP > /dev/null 2>&1; do
        log_warning "æ— æ³• ping é€š $PRODUCTION_IPï¼Œè¯·æ£€æŸ¥ç½‘ç»œ..."
        read -p "é‡è¯•è¯·æŒ‰ [Enter]ï¼Œé€€å‡ºè¯·æŒ‰ [Ctrl+C]..."
    done
    log_success "ç½‘ç»œå·²è¿é€šï¼"
else
    log_info "ç”Ÿäº§ç½‘ç»œå·²è¿é€šï¼Œæ— éœ€åˆ‡æ¢ã€‚"
fi
echo ""

# ==================== æ­¥éª¤5: ä¼ è¾“æ–‡ä»¶ ====================
log_info "[5/7] ä¼ è¾“æ–‡ä»¶åˆ°ç”Ÿäº§æœåŠ¡å™¨..."

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "$TAR_FILE_BACKEND" ] || [ ! -f "$TAR_FILE_FRONTEND" ]; then
    log_error "taræ–‡ä»¶ä¸å­˜åœ¨ï¼ˆéœ€è¦åŒæ—¶å­˜åœ¨ backend+frontendï¼‰"
    exit 1
fi

# åŒæ­¥å…³é”®éƒ¨ç½²é…ç½®ï¼ˆé¿å…æœ¬åœ°æ›´æ–°äº† compose/nginxï¼Œä½†ç”Ÿäº§æœºä»ç„¶ä½¿ç”¨æ—§é…ç½®ï¼‰
if [ ! -f "docker-compose.prod.yml" ]; then
    log_error "docker-compose.prod.yml ä¸å­˜åœ¨ï¼Œæ— æ³•åŒæ­¥ç”Ÿäº§é…ç½®"
    exit 1
fi
if [ ! -f "nginx/nginx.conf" ]; then
    log_error "nginx/nginx.conf ä¸å­˜åœ¨ï¼Œæ— æ³•åŒæ­¥ Nginx é…ç½®"
    exit 1
fi
if [ ! -f "scripts/init_db.sql" ]; then
    log_warning "scripts/init_db.sql ä¸å­˜åœ¨ï¼ˆè‹¥ç”Ÿäº§ä¸ä¾èµ–è¯¥æ–‡ä»¶å¯å¿½ç•¥ï¼‰"
fi

# é¢„å…ˆç¡®ä¿è¿œç«¯ç›®å½•å­˜åœ¨ï¼ˆå¦åˆ™ scp æ— æ³•è½åˆ°ç›®æ ‡è·¯å¾„ï¼‰
log_info "å‡†å¤‡è¿œç«¯ç›®å½•ï¼ˆç”¨äºåŒæ­¥ compose/nginx é…ç½®ï¼‰..."
ssh -t -o ControlPath="$SSH_CONTROL_PATH" $PRODUCTION_USER@$PRODUCTION_IP << EOF
    set -e
    if [ ! -d "$DEPLOY_DIR" ]; then
        sudo mkdir -p $DEPLOY_DIR
        sudo chown $PRODUCTION_USER:$PRODUCTION_USER $DEPLOY_DIR
    fi
    mkdir -p $DEPLOY_DIR/nginx $DEPLOY_DIR/scripts
EOF

# ä½¿ç”¨ rsync ä¼ è¾“æ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
log_info "ä½¿ç”¨ rsync ä¼ è¾“æ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰..."

# æ£€æŸ¥ rsync æ˜¯å¦å¯ç”¨
if ! command -v rsync > /dev/null 2>&1; then
    log_warning "rsync ä¸å¯ç”¨ï¼Œå›é€€åˆ° scp"
    USE_RSYNC=false
else
    USE_RSYNC=true
    log_info "rsync å¯ç”¨ï¼Œå°†ä½¿ç”¨æ–­ç‚¹ç»­ä¼ åŠŸèƒ½"
fi

# ä¼ è¾“åç«¯é•œåƒ
if [ "$USE_RSYNC" = "true" ]; then
    if ! transfer_file_rsync "$TAR_FILE_BACKEND" "/tmp/" 3; then
        log_error "åç«¯é•œåƒä¼ è¾“å¤±è´¥"
        exit 1
    fi
    log_success "åç«¯é•œåƒä¼ è¾“å®Œæˆ"

    # ä¼ è¾“å‰ç«¯é•œåƒ
    if ! transfer_file_rsync "$TAR_FILE_FRONTEND" "/tmp/" 3; then
        log_error "å‰ç«¯é•œåƒä¼ è¾“å¤±è´¥"
        exit 1
    fi
    log_success "å‰ç«¯é•œåƒä¼ è¾“å®Œæˆ"

    # ä¼ è¾“é…ç½®æ–‡ä»¶
    if ! transfer_file_rsync "docker-compose.prod.yml" "$DEPLOY_DIR/docker-compose.prod.yml" 3; then
        log_error "docker-compose.prod.yml ä¼ è¾“å¤±è´¥"
        exit 1
    fi

    if ! transfer_file_rsync "nginx/nginx.conf" "$DEPLOY_DIR/nginx/nginx.conf" 3; then
        log_error "nginx.conf ä¼ è¾“å¤±è´¥"
        exit 1
    fi

    if [ -f "scripts/init_db.sql" ]; then
        transfer_file_rsync "scripts/init_db.sql" "$DEPLOY_DIR/scripts/init_db.sql" 3 || true
    fi
else
    # å›é€€åˆ° scpï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    RETRY_COUNT=0
    MAX_RETRIES=3
    while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
        if scp -o ControlPath="$SSH_CONTROL_PATH" $TAR_FILE_BACKEND $PRODUCTION_USER@$PRODUCTION_IP:/tmp/ \
            && scp -o ControlPath="$SSH_CONTROL_PATH" $TAR_FILE_FRONTEND $PRODUCTION_USER@$PRODUCTION_IP:/tmp/ \
            && scp -o ControlPath="$SSH_CONTROL_PATH" docker-compose.prod.yml $PRODUCTION_USER@$PRODUCTION_IP:$DEPLOY_DIR/docker-compose.prod.yml \
            && scp -o ControlPath="$SSH_CONTROL_PATH" nginx/nginx.conf $PRODUCTION_USER@$PRODUCTION_IP:$DEPLOY_DIR/nginx/nginx.conf \
            && ( [ -f "scripts/init_db.sql" ] && scp -o ControlPath="$SSH_CONTROL_PATH" scripts/init_db.sql $PRODUCTION_USER@$PRODUCTION_IP:$DEPLOY_DIR/scripts/init_db.sql || true ); then
            log_success "ä¼ è¾“æˆåŠŸ"
            break
        else
            RETRY_COUNT=$((RETRY_COUNT + 1))
            if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                log_warning "ä¼ è¾“å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ($RETRY_COUNT/$MAX_RETRIES)..."
                sleep 2
            else
                log_error "ä¼ è¾“å¤±è´¥ï¼ˆå·²é‡è¯• $MAX_RETRIES æ¬¡ï¼‰ï¼Œè¯·æ£€æŸ¥ SSH è¿æ¥"
                log_info "æç¤ºï¼š"
                echo "  1. æ£€æŸ¥SSHè¿æ¥: ssh $PRODUCTION_USER@$PRODUCTION_IP"
                echo "  2. æ£€æŸ¥ç½‘ç»œè¿æ¥: ping $PRODUCTION_IP"
                echo "  3. å¯ä»¥æ‰‹åŠ¨ä¼ è¾“: scp $TAR_FILE_BACKEND $PRODUCTION_USER@$PRODUCTION_IP:/tmp/"
                exit 1
            fi
        fi
    done
fi
echo ""

# ==================== æ­¥éª¤6: è¿œç¨‹éƒ¨ç½² ====================
log_info "[6/7] è¿œç¨‹æ‰§è¡Œéƒ¨ç½²..."

ssh -t -o ControlPath="$SSH_CONTROL_PATH" $PRODUCTION_USER@$PRODUCTION_IP << EOF
    set -e

    # æ£€æŸ¥å¹¶åˆ›å»ºéƒ¨ç½²ç›®å½•
    if [ ! -d "$DEPLOY_DIR" ]; then
        echo "âš ï¸  éƒ¨ç½²ç›®å½•ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º: $DEPLOY_DIR"
        sudo mkdir -p $DEPLOY_DIR
        sudo chown $PRODUCTION_USER:$PRODUCTION_USER $DEPLOY_DIR
        echo "âœ“ ç›®å½•å·²åˆ›å»º"
    fi

    cd $DEPLOY_DIR

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if [ ! -f .env.production ]; then
        echo "âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦é¦–æ¬¡éƒ¨ç½²"
        echo "è¯·å…ˆæ‰§è¡Œé¦–æ¬¡éƒ¨ç½²æ­¥éª¤ï¼Œæˆ–æ‰‹åŠ¨åˆ›å»º .env.production"
        exit 1
    fi

    echo "1. å¯¼å…¥é•œåƒ (è§£å‹ä¸­)..."
    docker load < /tmp/pepgmp-backend-$TAG.tar.gz
    docker load < /tmp/pepgmp-frontend-$TAG.tar.gz

    # é‡æ–°æ‰“æ ‡ç­¾
    docker tag $FULL_BACKEND_IMAGE pepgmp-backend:$TAG
    docker tag $FULL_BACKEND_IMAGE pepgmp-backend:latest
    docker tag $FULL_FRONTEND_IMAGE pepgmp-frontend:$TAG
    docker tag $FULL_FRONTEND_IMAGE pepgmp-frontend:latest

    echo "2. æ›´æ–°ç‰ˆæœ¬é…ç½®..."
    # æ™ºèƒ½æ›´æ–°/è¿½åŠ  TAG
    if grep -q "^IMAGE_TAG=" .env.production; then
        sed -i "s|^IMAGE_TAG=.*|IMAGE_TAG=$TAG|" .env.production
    else
        echo "" >> .env.production
        echo "IMAGE_TAG=$TAG" >> .env.production
    fi

    # ç¡®ä¿ä¸ä½¿ç”¨è¿œç¨‹ Registry å‰ç¼€
    if grep -q "^IMAGE_REGISTRY=" .env.production; then
        sed -i 's|^IMAGE_REGISTRY=.*|IMAGE_REGISTRY=|' .env.production
    fi

    echo "3. é‡å¯æœåŠ¡..."
    docker compose -f docker-compose.prod.yml --env-file .env.production up -d --no-deps api
    # è¿è¡Œ frontend-init ä»¥æå–é™æ€æ–‡ä»¶ï¼ˆä¸€æ¬¡æ€§ä»»åŠ¡ï¼‰
    docker compose -f docker-compose.prod.yml --env-file .env.production up --abort-on-container-exit frontend-init
    docker compose -f docker-compose.prod.yml --env-file .env.production up -d --no-deps nginx

    echo "4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
    rm -f /tmp/pepgmp-backend-$TAG.tar.gz /tmp/pepgmp-frontend-$TAG.tar.gz

    echo "5. æ¸…ç†æ—§é•œåƒï¼ˆä¿ç•™æœ€è¿‘ 3 ä¸ªç‰ˆæœ¬ï¼‰..."
    # æ¸…ç†åç«¯æ—§é•œåƒ
    OLD_BACKEND_IMAGES=\$(docker images --format "{{.Repository}}:{{.Tag}}" --filter "reference=pepgmp-backend:*" | \
        grep -v "latest" | grep -v "$TAG" | \
        sort -r | tail -n +4)
    if [ -n "\$OLD_BACKEND_IMAGES" ]; then
        echo "åˆ é™¤æ—§åç«¯é•œåƒ:"
        echo "\$OLD_BACKEND_IMAGES" | while read img; do
            if [ -n "\$img" ]; then
                echo "  - \$img"
                docker rmi "\$img" 2>/dev/null || true
            fi
        done
    fi

    # æ¸…ç†å‰ç«¯æ—§é•œåƒ
    OLD_FRONTEND_IMAGES=\$(docker images --format "{{.Repository}}:{{.Tag}}" --filter "reference=pepgmp-frontend:*" | \
        grep -v "latest" | grep -v "$TAG" | \
        sort -r | tail -n +4)
    if [ -n "\$OLD_FRONTEND_IMAGES" ]; then
        echo "åˆ é™¤æ—§å‰ç«¯é•œåƒ:"
        echo "\$OLD_FRONTEND_IMAGES" | while read img; do
            if [ -n "\$img" ]; then
                echo "  - \$img"
                docker rmi "\$img" 2>/dev/null || true
            fi
        done
    fi

    # æ¸…ç† dangling images
    docker image prune -f > /dev/null 2>&1 || true
    echo "æ¸…ç†å®Œæˆ"
EOF

if [ $? -eq 0 ]; then
    log_success "éƒ¨ç½²è„šæœ¬æ‰§è¡Œå®Œæˆ"
else
    log_error "è¿œç¨‹éƒ¨ç½²æ‰§è¡Œå¤±è´¥"
    exit 1
fi

# ==================== æ­¥éª¤7: å¥åº·æ£€æŸ¥ ====================
log_info "[7/7] ç­‰å¾…æœåŠ¡å¯åŠ¨å¹¶æ£€æŸ¥..."
sleep 5

# è¯´æ˜ï¼š
# - è¿™é‡Œä¼šè§¦å‘ SSH è®¤è¯ï¼ˆå¦‚æœæœªé…ç½®å…å¯†ï¼‰ï¼Œå»ºè®®ç”Ÿäº§ç¯å¢ƒé…ç½® SSH Key ä»¥ä¾¿è„šæœ¬å…¨è‡ªåŠ¨è¿è¡Œã€‚
# - ä¼˜å…ˆæ£€æŸ¥ api å®¹å™¨è‡ªèº«çš„å¥åº·ç«¯ç‚¹ï¼ˆé¿å… nginx å°šæœªå°±ç»ªå¯¼è‡´è¯¯åˆ¤ï¼‰ã€‚
MAX_HEALTH_RETRIES=15
HEALTH_OK=false
for i in $(seq 1 $MAX_HEALTH_RETRIES); do
    if ssh -o ControlPath="$SSH_CONTROL_PATH" $PRODUCTION_USER@$PRODUCTION_IP \
        "docker exec pepgmp-api-prod curl -sf --max-time 5 http://localhost:8000/api/v1/monitoring/health > /dev/null" \
        > /dev/null 2>&1; then
        HEALTH_OK=true
        break
    fi
    log_info "å¥åº·æ£€æŸ¥æœªå°±ç»ªï¼Œé‡è¯• $i/$MAX_HEALTH_RETRIESï¼ˆç­‰å¾…å¯åŠ¨ä¸­ï¼‰..."
    sleep 4
done

if [ "$HEALTH_OK" = "true" ]; then
    log_success "âœ… å¥åº·æ£€æŸ¥é€šè¿‡ï¼API æœåŠ¡å·²å°±ç»ªã€‚"
else
    log_warning "âš ï¸  å¥åº·æ£€æŸ¥æœªé€šè¿‡ï¼ˆå¯èƒ½å¯åŠ¨å¤±è´¥æˆ–å¯åŠ¨æ—¶é—´è¾ƒé•¿ï¼‰"
    log_info "   å»ºè®®åœ¨ç”Ÿäº§æœºæ‰§è¡Œï¼š"
    echo "     ssh $PRODUCTION_USER@$PRODUCTION_IP 'cd $DEPLOY_DIR && docker compose -f docker-compose.prod.yml --env-file .env.production ps'"
    echo "     ssh $PRODUCTION_USER@$PRODUCTION_IP 'docker logs --tail 200 pepgmp-api-prod'"
fi

# æ¸…ç†æœ¬åœ°
rm -f $TAR_FILE_BACKEND $TAR_FILE_FRONTEND
echo ""
