#!/usr/bin/env python
"""
é€šè¿‡MLOps APIåˆ›å»ºå’Œè¿è¡Œå‘ç½‘æ£€æµ‹è®­ç»ƒå·¥ä½œæµ

ç”¨æ³•:
    python scripts/mlops/train_hairnet_workflow.py

æ³¨æ„: è¯·ç¡®ä¿åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ:
    python -m src.api.app
    æˆ–
    uvicorn src.api.app:app --reload
"""

import json
import sys
import time
from pathlib import Path

import requests

# APIåŸºç¡€URL
BASE_URL = "http://localhost:8000/api/v1/mlops"

# è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
REQUEST_TIMEOUT = 30


def create_training_workflow(dataset_path: str, data_yaml_path: str) -> dict:
    """åˆ›å»ºå·¥ä½œæµ"""
    url = f"{BASE_URL}/workflows"

    workflow = {
        "name": "å‘ç½‘æ£€æµ‹æ¨¡å‹è®­ç»ƒï¼ˆRoboflow v15ï¼‰",
        "type": "multi_behavior_training",
        "trigger": "manual",
        "description": "ä½¿ç”¨Roboflowå‘ç½‘æ£€æµ‹æ•°æ®é›†è®­ç»ƒYOLOv8æ¨¡å‹ï¼ˆv15ï¼Œ2ç±»åˆ«ï¼‰",
        "steps": [
            {
                "type": "multi_behavior_training",
                "name": "è®­ç»ƒå‘ç½‘æ£€æµ‹æ¨¡å‹",
                "config": {
                    "dataset_dir": dataset_path,
                    "data_config": data_yaml_path,
                    "training_params": {
                        "model": "yolov8s.pt",
                        "epochs": 150,
                        "batch_size": 16,
                        "image_size": 640,
                        "device": "cuda:0",
                        "patience": 50,
                        "lr0": 0.01,
                        "lrf": 0.01,
                        "momentum": 0.937,
                        "weight_decay": 0.0005,
                        "warmup_epochs": 3.0,
                    },
                },
            }
        ],
    }

    print("ğŸ“ åˆ›å»ºå·¥ä½œæµ...")
    print(f"æ•°æ®é›†è·¯å¾„: {dataset_path}")
    print(f"é…ç½®æ–‡ä»¶: {data_yaml_path}")

    try:
        response = requests.post(url, json=workflow, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        result = response.json()
    except requests.exceptions.ConnectionError:
        print("\nâŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨")
        print("   è¯·ç¡®ä¿åç«¯æœåŠ¡æ­£åœ¨è¿è¡Œ:")
        print("   python -m src.api.app")
        print("   æˆ–")
        print("   uvicorn src.api.app:app --reload")
        sys.exit(1)
    except requests.exceptions.Timeout:
        print("\nâŒ APIè¯·æ±‚è¶…æ—¶")
        print("   è¯·æ£€æŸ¥åç«¯æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        sys.exit(1)

    print(f"âœ… å·¥ä½œæµåˆ›å»ºæˆåŠŸ: {result['workflow_id']}")
    return result


def run_workflow(workflow_id: str) -> dict:
    """è¿è¡Œå·¥ä½œæµ"""
    url = f"{BASE_URL}/workflows/{workflow_id}/run"

    print(f"\nğŸš€ è¿è¡Œå·¥ä½œæµ: {workflow_id}...")

    try:
        response = requests.post(url, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        result = response.json()
    except requests.exceptions.ConnectionError:
        print("\nâŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨")
        sys.exit(1)
    except requests.exceptions.Timeout:
        print("\nâŒ APIè¯·æ±‚è¶…æ—¶")
        sys.exit(1)

    print(f"âœ… å·¥ä½œæµå·²å¯åŠ¨: {result['run_id']}")
    return result


def monitor_workflow(workflow_id: str, run_id: str = None) -> dict:
    """ç›‘æ§å·¥ä½œæµçŠ¶æ€"""
    url = f"{BASE_URL}/workflows/{workflow_id}"

    print("\nğŸ“Š ç›‘æ§å·¥ä½œæµçŠ¶æ€...")
    print("=" * 60)

    last_status = None
    while True:
        try:
            response = requests.get(url, timeout=REQUEST_TIMEOUT)
            response.raise_for_status()
            workflow = response.json()
        except requests.exceptions.ConnectionError:
            print("\nâŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨")
            sys.exit(1)
        except requests.exceptions.Timeout:
            print("\nâš ï¸  è¯·æ±‚è¶…æ—¶ï¼Œç»§ç»­ç›‘æ§...")
            time.sleep(5)
            continue

        status = workflow.get("status", "unknown")

        # åªåœ¨çŠ¶æ€å˜åŒ–æ—¶æ‰“å°
        if status != last_status:
            print(f"â±ï¸  {time.strftime('%Y-%m-%d %H:%M:%S')} - çŠ¶æ€: {status}")
            last_status = status

        if status in ["success", "failed", "error"]:
            print("=" * 60)
            break

        time.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡

    return workflow


def get_training_results(workflow_id: str) -> tuple:
    """è·å–è®­ç»ƒç»“æœ"""
    url = f"{BASE_URL}/workflows/{workflow_id}"

    print("\nğŸ“ˆ è·å–è®­ç»ƒç»“æœ...")

    try:
        response = requests.get(url, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        workflow = response.json()
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨")
        return None, None
    except requests.exceptions.Timeout:
        print("âŒ APIè¯·æ±‚è¶…æ—¶")
        return None, None

    # è·å–æœ€åä¸€æ¬¡è¿è¡Œ
    last_run = workflow.get("last_run")
    if not last_run:
        print("âš ï¸  æœªæ‰¾åˆ°è¿è¡Œè®°å½•")
        return None, None

    # è·å–è¿è¡Œè¯¦æƒ…
    run_url = f"{BASE_URL}/workflows/{workflow_id}/runs/{last_run}"
    try:
        response = requests.get(run_url, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        run_info = response.json()
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨")
        return None, None
    except requests.exceptions.Timeout:
        print("âŒ APIè¯·æ±‚è¶…æ—¶")
        return None, None

    # ä»è¾“å‡ºä¸­æå–è®­ç»ƒç»“æœ
    outputs = run_info.get("outputs", [])
    for output in outputs:
        if output.get("step_name") == "è®­ç»ƒå‘ç½‘æ£€æµ‹æ¨¡å‹":
            step_output = output.get("output", {})
            model_path = step_output.get("model_path")
            metrics = step_output.get("metrics", {})
            report_path = step_output.get("report_path")

            print("\nâœ… è®­ç»ƒå®Œæˆï¼")
            print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
            print(f"ğŸ“„ æŠ¥å‘Šè·¯å¾„: {report_path}")
            print("\nğŸ“Š è¯„ä¼°æŒ‡æ ‡:")
            print(
                f"  mAP@0.5:        {metrics.get('mAP50', 'N/A'):.4f}"
                if isinstance(metrics.get("mAP50"), (int, float))
                else f"  mAP@0.5:        {metrics.get('mAP50', 'N/A')}"
            )
            print(
                f"  mAP@0.5:0.95:   {metrics.get('mAP50_95', 'N/A'):.4f}"
                if isinstance(metrics.get("mAP50_95"), (int, float))
                else f"  mAP@0.5:0.95:   {metrics.get('mAP50_95', 'N/A')}"
            )
            print(
                f"  Precision:      {metrics.get('precision', 'N/A'):.4f}"
                if isinstance(metrics.get("precision"), (int, float))
                else f"  Precision:      {metrics.get('precision', 'N/A')}"
            )
            print(
                f"  Recall:         {metrics.get('recall', 'N/A'):.4f}"
                if isinstance(metrics.get("recall"), (int, float))
                else f"  Recall:         {metrics.get('recall', 'N/A')}"
            )

            # è®¡ç®—F1åˆ†æ•°
            precision = metrics.get("precision", 0)
            recall = metrics.get("recall", 0)
            if isinstance(precision, (int, float)) and isinstance(recall, (int, float)):
                if precision + recall > 0:
                    f1_score = 2 * (precision * recall) / (precision + recall)
                    print(f"  F1-Score:       {f1_score:.4f}")

            # è¯„ä¼°æ¨¡å‹æ€§èƒ½
            mAP50 = metrics.get("mAP50", 0)
            if isinstance(mAP50, (int, float)):
                if mAP50 >= 0.90:
                    print("\nğŸ‰ æ¨¡å‹æ€§èƒ½ä¼˜ç§€ï¼å¯ä»¥éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒã€‚")
                elif mAP50 >= 0.80:
                    print("\nâœ… æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ä¼˜åŒ–ã€‚")
                else:
                    print("\nâš ï¸  æ¨¡å‹æ€§èƒ½éœ€è¦æ”¹è¿›ï¼Œå»ºè®®:")
                    print("  1. å¢åŠ è®­ç»ƒæ•°æ®")
                    print("  2. è°ƒæ•´è¶…å‚æ•°")
                    print("  3. å¢å¼ºæ•°æ®å¢å¼º")

            return model_path, metrics

    print("âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒç»“æœ")
    return None, None


def main():
    """ä¸»å‡½æ•°"""
    # æ•°æ®é›†è·¯å¾„
    dataset_path = "/Users/zhou/Code/PEPGMP/data/datasets/hairnet.v15i.yolov8"
    data_yaml_path = (
        "/Users/zhou/Code/PEPGMP/data/datasets/hairnet.v15i.yolov8/data.yaml"
    )

    # éªŒè¯æ•°æ®é›†å­˜åœ¨
    dataset_dir = Path(dataset_path)
    data_yaml = Path(data_yaml_path)

    if not dataset_dir.exists():
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_path}")
        return 1

    if not data_yaml.exists():
        print(f"âŒ data.yaml æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml_path}")
        return 1

    print("âœ… æ•°æ®é›†éªŒè¯é€šè¿‡")
    print(f"   æ•°æ®é›†ç›®å½•: {dataset_path}")
    print(f"   é…ç½®æ–‡ä»¶: {data_yaml_path}")

    try:
        # 1. åˆ›å»ºå·¥ä½œæµ
        workflow_result = create_training_workflow(dataset_path, data_yaml_path)
        workflow_id = workflow_result["workflow_id"]

        # 2. è¿è¡Œå·¥ä½œæµ
        run_result = run_workflow(workflow_id)
        run_id = run_result.get("run_id")

        # 3. ç›‘æ§å·¥ä½œæµ
        monitor_workflow(workflow_id, run_id)

        # 4. è·å–è®­ç»ƒç»“æœ
        model_path, metrics = get_training_results(workflow_id)

        if model_path:
            print("\nğŸ“‹ è®­ç»ƒç»“æœæ‘˜è¦:")
            print(f"   å·¥ä½œæµID: {workflow_id}")
            print(f"   è¿è¡ŒID: {run_id}")
            print(f"   æ¨¡å‹è·¯å¾„: {model_path}")
            print(f"   è¯„ä¼°æŒ‡æ ‡: {json.dumps(metrics, indent=2, ensure_ascii=False)}")
            return 0
        else:
            print("\nâŒ æœªèƒ½è·å–è®­ç»ƒç»“æœ")
            return 1

    except requests.exceptions.RequestException as e:
        print(f"\nâŒ APIè¯·æ±‚å¤±è´¥: {e}")
        if hasattr(e, "response") and e.response is not None:
            print(f"   å“åº”å†…å®¹: {e.response.text}")
        return 1
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
