#!/usr/bin/env python3
"""
äººä½“è¡Œä¸ºæ£€æµ‹ç³»ç»Ÿä¸»å…¥å£æ–‡ä»¶
Human Behavior Detection System Main Entry Point

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 1.0.0
åˆ›å»ºæ—¶é—´: 2024
"""

import argparse
import os
import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

import json
import time

import cv2

from config import Settings
from utils.logger import setup_project_logger

# GPUåŠ é€Ÿä¼˜åŒ–ï¼ˆåœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰ï¼‰
try:
    from utils.gpu_acceleration import initialize_gpu_acceleration

    gpu_status = initialize_gpu_acceleration()
except ImportError:
    gpu_status = {"device": "cpu", "gpu_available": False}


def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(
        description="äººä½“è¡Œä¸ºæ£€æµ‹ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python main.py --mode detection --source 0                    # ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œæ£€æµ‹
  python main.py --mode detection --source video.mp4           # ä½¿ç”¨è§†é¢‘æ–‡ä»¶è¿›è¡Œæ£€æµ‹
  python main.py --mode api --port 8000                        # å¯åŠ¨APIæœåŠ¡
  python main.py --mode training --config config/train.yaml    # è®­ç»ƒæ¨¡å‹
        """,
    )

    parser.add_argument(
        "--mode",
        choices=["detection", "api", "training", "demo", "supervisor"],
        default="detection",
        help="è¿è¡Œæ¨¡å¼ (é»˜è®¤: detection)",
    )

    parser.add_argument(
        "--gpu-optimize",
        action="store_true",
        help="å¯ç”¨GPUåŠ é€Ÿä¼˜åŒ–",
    )

    parser.add_argument(
        "--batch-size",
        type=int,
        help="æ‰¹å¤„ç†å¤§å°ï¼ˆè‡ªåŠ¨æ£€æµ‹æœ€ä¼˜å€¼ï¼‰",
    )

    parser.add_argument(
        "--source", type=str, default="0", help="è¾“å…¥æº: æ‘„åƒå¤´ç´¢å¼•(0,1...) æˆ– è§†é¢‘æ–‡ä»¶è·¯å¾„ (é»˜è®¤: 0)"
    )

    parser.add_argument(
        "--regions-file",
        type=str,
        default="config/regions.json",
        help="åŒºåŸŸé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/regions.json)",
    )

    parser.add_argument(
        "--config",
        type=str,
        default="config/default.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/default.yaml)",
    )

    parser.add_argument("--output", type=str, help="è¾“å‡ºç›®å½•è·¯å¾„")

    parser.add_argument("--port", type=int, default=8000, help="APIæœåŠ¡ç«¯å£ (é»˜è®¤: 8000)")

    parser.add_argument(
        "--host", type=str, default="0.0.0.0", help="APIæœåŠ¡ä¸»æœº (é»˜è®¤: 0.0.0.0)"
    )

    parser.add_argument("--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ¨¡å¼")

    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)",
    )

    # è‡ªé€‚åº”ç›¸å…³ CLI
    parser.add_argument(
        "--profile",
        type=str,
        default=None,
        help="fast|balanced|accurateï¼ˆä¼˜å…ˆçº§: CLI>ENV>YAML)",
    )
    parser.add_argument(
        "--device", type=str, default=None, help="cpu|cuda|mpsï¼ˆä¼˜å…ˆçº§: CLI>ENV>auto)"
    )
    parser.add_argument("--imgsz", type=int, default=None, help="YOLO è¾“å…¥å°ºå¯¸ï¼ˆè¦†ç›–é…ç½®ï¼‰")
    parser.add_argument(
        "--human-weights", type=str, default=None, help="YOLO äººä½“æ£€æµ‹æƒé‡è·¯å¾„ï¼ˆè¦†ç›–é…ç½®ï¼‰"
    )

    # æ€§èƒ½ä¼˜åŒ–ç›¸å…³ CLI
    parser.add_argument(
        "--no-window", action="store_true", help="ç¦ç”¨å¯è§†åŒ–çª—å£ï¼Œä»…è¾“å‡ºç»Ÿè®¡ä¿¡æ¯ï¼ˆæé«˜æ€§èƒ½ï¼‰"
    )
    parser.add_argument("--osd-minimal", action="store_true", help="æœ€å°åŒ–OSDç»˜åˆ¶ï¼Œå‡å°‘å¯è§†åŒ–å¼€é”€")
    parser.add_argument("--frame-skip", type=int, default=0, help="è·³å¸§æ•°é‡ï¼Œ0è¡¨ç¤ºä¸è·³å¸§ï¼ˆé»˜è®¤: 0ï¼‰")
    parser.add_argument("--cascade-enable", action="store_true", help="å¯ç”¨çº§è”äºŒæ¬¡æ£€æµ‹")
    parser.add_argument("--log-interval", type=int, default=None, help="æ—¥å¿—é™æµé—´éš”ï¼ˆå¸§ï¼‰")
    parser.add_argument(
        "--osd-regions", action="store_true", help="åœ¨çª—å£å åŠ æ˜¾ç¤ºå·²åŠ è½½çš„åŒºåŸŸå¤šè¾¹å½¢ä¸åç§°"
    )
    parser.add_argument(
        "--camera-id", type=str, default=None, help="å½“å‰æ£€æµ‹è¿›ç¨‹çš„æ‘„åƒå¤´æ ‡è¯†ï¼ˆç”¨äºäº‹ä»¶/æŒ‡æ ‡æ‰“æ ‡ï¼‰"
    )

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—
    logger = setup_project_logger()
    if args.debug:
        logger.setLevel("DEBUG")
    else:
        logger.setLevel(args.log_level)
    # æå‡æ ¹æ—¥å¿—çº§åˆ«ï¼Œç¡®ä¿å­æ¨¡å—æ—¥å¿—å¯è§
    try:
        import logging as _logging

        _logging.getLogger().setLevel(logger.level)
    except Exception:
        pass

    logger.info("=" * 50)
    logger.info("äººä½“è¡Œä¸ºæ£€æµ‹ç³»ç»Ÿå¯åŠ¨")
    logger.info(f"è¿è¡Œæ¨¡å¼: {args.mode}")

    # æ˜¾ç¤ºGPUçŠ¶æ€
    if gpu_status["gpu_available"]:
        logger.info(f"ğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨: {gpu_status['device']}")
        if args.gpu_optimize:
            logger.info("âš™ï¸  GPUä¼˜åŒ–æ¨¡å¼å·²å¯ç”¨")
    else:
        logger.info("âš ï¸  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
        if args.gpu_optimize:
            logger.warning("âš ï¸  GPUä¼˜åŒ–å‚æ•°å·²å¿½ç•¥ï¼ˆGPUä¸å¯ç”¨ï¼‰")

    logger.info("=" * 50)

    try:
        if args.mode == "detection":
            run_detection(args, logger)
        elif args.mode == "api":
            run_api_server(args, logger)
        elif args.mode == "training":
            run_training(args, logger)
        elif args.mode == "demo":
            run_demo(args, logger)
        elif args.mode == "supervisor":
            try:
                run_supervisor(args, logger)
            except NameError:
                logger.error("supervisor æ¨¡å¼æš‚æœªå®ç°ï¼Œè¯·ç¨åå†è¯•")
        else:
            logger.error(f"æœªçŸ¥çš„è¿è¡Œæ¨¡å¼: {args.mode}")
            sys.exit(1)

    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        if args.debug:
            import traceback

            traceback.print_exc()
        sys.exit(1)
    finally:
        logger.info("ç¨‹åºç»“æŸ")


def run_detection(args, logger):
    """
    è¿è¡Œæ£€æµ‹æ¨¡å¼
    """
    logger.info(f"å¼€å§‹æ£€æµ‹ï¼Œè¾“å…¥æº: {args.source}")

    # 1) åŠ è½½ç»Ÿä¸€å‚æ•°å¹¶åº”ç”¨ profiles/CLI è¦†ç›–
    try:
        from config.unified_params import get_unified_params

        params = get_unified_params()
        cli_overrides = {"runtime": {}, "human_detection": {}, "cascade": {}}
        if args.imgsz:
            cli_overrides["human_detection"]["imgsz"] = int(args.imgsz)
        if args.human_weights:
            cli_overrides["human_detection"]["model_path"] = str(args.human_weights)
        if args.cascade_enable:
            cli_overrides["cascade"]["enable"] = True
        if args.log_interval is not None:
            cli_overrides["runtime"]["log_interval"] = int(args.log_interval)
        effective = params.build_effective_config(
            profile=args.profile, cli_overrides=cli_overrides
        )
    except Exception as e:
        logger.error(f"åŠ è½½/åˆå¹¶é…ç½®å¤±è´¥: {e}")
        return

    # 2) ç»Ÿä¸€è®¾å¤‡é€‰æ‹©ï¼ˆç»“åˆç¡¬ä»¶è‡ªé€‚åº”ï¼‰
    try:
        # æ–°å¢ï¼šè‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–
        try:
            from src.utils.adaptive_optimizer import apply_adaptive_optimizations

            adaptive_config = apply_adaptive_optimizations()

            # åº”ç”¨è‡ªé€‚åº”é…ç½®ï¼ˆå¦‚æœç”¨æˆ·æœªæ‰‹åŠ¨æŒ‡å®šï¼‰
            auto_device = (args.device is None) or (str(args.device).lower() == "auto")
            auto_imgsz = (args.imgsz is None) or (str(args.imgsz).lower() == "auto")
            auto_weights = args.human_weights is None

            if auto_device:
                args.device = "cuda" if adaptive_config.get("enable_amp") else "cpu"
            if auto_imgsz:
                args.imgsz = adaptive_config.get("imgsz", 416)
            if auto_weights:
                recommended_model = adaptive_config.get(
                    "model_recommendations", {}
                ).get("human_model", "yolov8s.pt")
                args.human_weights = f"models/yolo/{recommended_model}"

            logger.info(f"è‡ªé€‚åº”ä¼˜åŒ–å·²å¯ç”¨: {adaptive_config['description']}")
            logger.info(
                f"æ¨èé…ç½® - è®¾å¤‡: {args.device}, å›¾åƒå°ºå¯¸: {args.imgsz}, æ¨¡å‹: {args.human_weights}"
            )

        except Exception as e:
            logger.debug(f"è‡ªé€‚åº”ä¼˜åŒ–è·³è¿‡: {e}")
            # å›é€€åˆ°åŸæœ‰çš„ç¡¬ä»¶æ¢æµ‹é€»è¾‘
            auto_device = (args.device is None) or (str(args.device).lower() == "auto")
            auto_imgsz = (args.imgsz is None) or (str(args.imgsz).lower() == "auto")
            auto_weights = args.human_weights is None
            if auto_device or auto_imgsz or auto_weights:
                try:
                    from src.utils.hardware_probe import decide_policy

                    pol = decide_policy(
                        preferred_profile=args.profile,
                        user_device=args.device,
                        user_imgsz=args.imgsz,
                    )
                    if auto_device:
                        args.device = pol.get("device")
                    if auto_imgsz:
                        args.imgsz = pol.get("imgsz")
                    if auto_weights and pol.get("human_weights"):
                        args.human_weights = pol.get("human_weights")
                    # ç¯å¢ƒå˜é‡æ³¨å…¥ï¼ˆçº¿ç¨‹æ•°ç­‰ï¼‰
                    for k, v in (pol.get("env") or {}).items():
                        os.environ[str(k)] = str(v)
                    logger.info(f"Auto policy applied: {pol}")
                except Exception as _e:
                    logger.debug(f"hardware_probe skipped: {_e}")
        from config.model_config import ModelConfig

        mc = ModelConfig()
        dev_req = args.device or None
        device = mc.select_device(requested=dev_req)
        logger.info(f"Device selected: {device}")
    except Exception as e:
        logger.error(f"é€‰æ‹©è®¾å¤‡å¤±è´¥: {e}")
        device = "cpu"

    # 3) è¾“å‡ºé…ç½®æ‘˜è¦
    hd = effective.get("human_detection", {})
    imgsz = hd.get("imgsz", None)
    weights = hd.get("model_path", None)
    prof = effective.get("inference", {}).get("profile", "fast")
    logger.info(
        f"é…ç½®æ‘˜è¦: device={device}, profile={prof}, imgsz={imgsz}, weights={weights}"
    )

    # 4) æ„å»ºâ€œä¼˜åŒ–ç»¼åˆç®¡çº¿â€å¹¶è¿è¡Œï¼ˆå¯ç”¨ YOLO äººä½“ä¸å¯é€‰çº§è”ï¼‰
    try:
        # å°†åˆå¹¶åçš„å…³é”®äººæ£€å‚æ•°å›å¡«åˆ°å…¨å±€é…ç½®ï¼Œç¡®ä¿ HumanDetector è¯»å–åˆ°
        from config.unified_params import update_global_param

        for k in [
            "model_path",
            "confidence_threshold",
            "iou_threshold",
            "min_box_area",
            "max_box_ratio",
            "min_width",
            "min_height",
            "nms_threshold",
            "max_detections",
            "device",
        ]:
            if k in hd:
                update_global_param("human_detection", k, hd[k])

        from src.core.behavior import BehaviorRecognizer
        from src.core.optimized_detection_pipeline import OptimizedDetectionPipeline
        from src.core.region import RegionManager
        from src.core.tracker import MultiObjectTracker
        from src.detection.detector import HumanDetector
        from src.detection.pose_detector import PoseDetectorFactory
        from src.detection.yolo_hairnet_detector import YOLOHairnetDetector
        from src.services.capture_service import CaptureService
        from src.services.process_engine import (  # è®°å½•ç”¨ï¼ˆé»˜è®¤å…³é—­ï¼‰
            Event,
            ProcessConfig,
            ProcessEngine,
        )
        from src.services.region_service import initialize_region_service

        # æƒé‡æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥ä¸å›é€€
        wpath = Path(weights) if weights else None
        if not (wpath and wpath.exists()):
            alt = Path("models/yolo/yolov8n.pt")
            logger.warning(f"æŒ‡å®šæƒé‡ä¸å­˜åœ¨: {weights}ï¼Œå›é€€åˆ° {alt}")
            weights = str(alt)
            update_global_param("human_detection", "model_path", weights)

        human_detector = HumanDetector(model_path=weights, device=device)

        # æ ¹æ®é…ç½®å’Œè®¾å¤‡é€‰æ‹©å§¿æ€æ£€æµ‹åç«¯
        from config.unified_params import get_unified_params

        params = get_unified_params()

        # ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„åç«¯è®¾ç½®ï¼Œå¦‚æœé…ç½®ä¸ºautoåˆ™æ ¹æ®è®¾å¤‡é€‰æ‹©
        pose_backend = params.pose_detection.backend
        if pose_backend == "auto":
            # è‡ªåŠ¨é€‰æ‹©ï¼šCUDAè®¾å¤‡ä¼˜å…ˆä½¿ç”¨YOLOv8ï¼ŒCPUè®¾å¤‡ä½¿ç”¨MediaPipe
            pose_backend = "yolov8" if str(device).lower() == "cuda" else "mediapipe"

        pose_detector = PoseDetectorFactory.create(
            backend=pose_backend,
            device=params.pose_detection.device
            if params.pose_detection.device != "auto"
            else device,
        )
        logger.info(f"å§¿æ€æ£€æµ‹å™¨åç«¯: {pose_backend}, è®¾å¤‡: {device}")

        behavior_recognizer = BehaviorRecognizer()
        hairnet_detector = YOLOHairnetDetector(device=device)
        cascade_cfg = effective.get("cascade", {})

        pipeline = OptimizedDetectionPipeline(
            human_detector=human_detector,
            hairnet_detector=hairnet_detector,
            behavior_recognizer=behavior_recognizer,
            pose_detector=pose_detector,
            enable_cache=True,
            cache_size=50,
            cache_ttl=20.0,
            cascade_config=cascade_cfg,
        )

        # åˆå§‹åŒ–æµç¨‹å¼•æ“ï¼ˆrecord-onlyï¼‰ï¼Œé»˜è®¤å…³é—­ï¼Œç”±é…ç½® process.enable æ§åˆ¶
        proc_cfg_src = effective.get("process", {}) or {}
        proc_cfg = ProcessConfig(
            enable=bool(proc_cfg_src.get("enable", False)),
            min_dwell_seconds_stand=float(
                (proc_cfg_src.get("min_dwell_seconds", {}) or {}).get("stand", 3)
            ),
            min_dwell_seconds_sink=float(
                (proc_cfg_src.get("min_dwell_seconds", {}) or {}).get("sink", 3)
            ),
            min_dwell_seconds_dryer=float(
                (proc_cfg_src.get("min_dwell_seconds", {}) or {}).get("dryer", 3)
            ),
            cooldown_seconds=float(proc_cfg_src.get("cooldown_seconds", 10)),
            region_entrance=str(
                (proc_cfg_src.get("region_names", {}) or {}).get("entrance", "å…¥å£çº¿")
            ),
            region_stand=str(
                (proc_cfg_src.get("region_names", {}) or {}).get("stand", "æ´—æ‰‹ç«™ç«‹åŒºåŸŸ")
            ),
            region_sink=str(
                (proc_cfg_src.get("region_names", {}) or {}).get("sink", "æ´—æ‰‹æ± åŒºåŸŸ")
            ),
            region_dryer=str(
                (proc_cfg_src.get("region_names", {}) or {}).get("dryer", "çƒ˜å¹²åŒºåŸŸ")
            ),
            region_work=str(
                (proc_cfg_src.get("region_names", {}) or {}).get("work", "å·¥ä½œåŒºåŒºåŸŸ")
            ),
            handwash_min_consecutive=int(
                proc_cfg_src.get("handwash_min_consecutive", 3)
            ),
        )
        process_engine = ProcessEngine(proc_cfg)
        events_path = Path("logs/events_record.jsonl")
        events_path.parent.mkdir(parents=True, exist_ok=True)

        # æŠ“æ‹æœåŠ¡ä¸å¸§ç¯å½¢ç¼“å†²
        cap_cfg = effective.get("capture", {}) or {}
        capture = CaptureService(
            output_dir="output/captures",
            pre_seconds=2.0,
            post_seconds=0.0,
            clip_fps=25.0,
            anonymize_head=bool(cap_cfg.get("anonymize_head", False)),
            anonymize_ratio=float(cap_cfg.get("anonymize_ratio", 0.4)),
            blur_kernel=int(cap_cfg.get("blur_kernel", 31)),
        )
        frame_buffer_maxlen = 200  # çº¦ç­‰äº 8s@25fpsï¼›pre_seconds=2 å¤Ÿç”¨
        frame_buffer: list = []  # é€€åŒ–å®ç°ï¼›ä¿æŒç®€å•

        # åˆå§‹åŒ–åŒºåŸŸæœåŠ¡ï¼ˆæ£€æµ‹æ¨¡å¼ï¼‰
        try:
            # ç»Ÿä¸€æ¥æºï¼šä¼˜å…ˆ CLI --regions-fileï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ HBD_REGIONS_FILEï¼Œæœ€åä¸¥æ ¼æ¨¡å¼ä½¿ç”¨é»˜è®¤ config/regions.json
            regions_file = args.regions_file or str(
                os.environ.get("HBD_REGIONS_FILE") or ""
            )
            if not regions_file:
                regions_file = "config/regions.json"
            if not Path(regions_file).exists():
                logger.error(f"åŒºåŸŸæ–‡ä»¶ä¸å­˜åœ¨: {regions_file}")
                return
            initialize_region_service(regions_file)
            logger.info(f"Regions config initialized: {regions_file}")
        except Exception as e:
            logger.warning(f"Initialize regions failed: {e}")

        # æ‰“å¼€è¾“å…¥æº
        src_str = str(args.source)
        if src_str.isdigit():
            cam_index = int(src_str)
            cap = cv2.VideoCapture(cam_index, cv2.CAP_AVFOUNDATION)
            if not cap or not cap.isOpened():
                cap = cv2.VideoCapture(cam_index)
            if not cap or not cap.isOpened():
                logger.error("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                return
        else:
            if not Path(src_str).exists():
                # å…è®¸ RTSP/ç½‘ç»œæµï¼ˆéæœ¬åœ°æ–‡ä»¶ï¼‰
                if not src_str.lower().startswith("rtsp://"):
                    logger.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {src_str}")
                    return
            cap = cv2.VideoCapture(src_str)
            if not cap or not cap.isOpened():
                if src_str.lower().startswith("rtsp://"):
                    logger.warning(f"RTSP æ‰“å¼€å¤±è´¥ï¼Œç¨åé‡è¯•: {src_str}")
                else:
                    logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {src_str}")
                    return

        # RTSP é‡è¿é…ç½®
        is_rtsp_source = (not src_str.isdigit()) and src_str.lower().startswith(
            "rtsp://"
        )
        backoff_seconds = 1.0
        backoff_max = 30.0

        def _reconnect_rtsp() -> bool:
            nonlocal cap, backoff_seconds
            try:
                if cap:
                    try:
                        cap.release()
                    except Exception:
                        pass
                logger.warning(f"å°è¯•é‡è¿ RTSP æºï¼ˆç­‰å¾… {backoff_seconds:.1f}sï¼‰: {src_str}")
            except Exception:
                pass
            try:
                time.sleep(backoff_seconds)
                backoff_seconds = min(backoff_seconds * 2.0, backoff_max)
                cap = cv2.VideoCapture(src_str)
                if cap and cap.isOpened():
                    logger.info("RTSP é‡è¿æˆåŠŸ")
                    backoff_seconds = 1.0
                    return True
                return False
            except Exception:
                return False

        # ä¿å­˜æºå¸§ç‡ï¼ˆè‹¥å¯è·å–ï¼‰
        try:
            src_fps = cap.get(cv2.CAP_PROP_FPS)
            Path("logs").mkdir(parents=True, exist_ok=True)
            with open("logs/source_fps.txt", "w", encoding="utf-8") as _f:
                _f.write(str(src_fps))
            logger.info(f"Source FPS saved: {src_fps}")
        except Exception:
            pass

        # è¿è¡Œå¾ªç¯ï¼ˆç®€å•å¯è§†åŒ–ï¼‰
        frame_idx = 0
        # æ—¥å¿—é—´éš”æ§åˆ¶ - CLIå‚æ•°ä¼˜å…ˆçº§æœ€é«˜
        log_iv = (
            args.log_interval
            if args.log_interval is not None
            else int(effective.get("runtime", {}).get("log_interval", 120) or 0)
        )

        # æ€§èƒ½æ¨¡å¼ï¼šå‡å°‘æ—¥å¿—é¢‘ç‡
        if args.no_window and log_iv == 0:
            log_iv = 60  # æ— çª—å£æ¨¡å¼é»˜è®¤60å¸§é—´éš”æ—¥å¿—
        # å¤šç›®æ ‡è·Ÿè¸ªå™¨ï¼ˆæ›¿ä»£ç®€æ˜“æœ€è¿‘é‚»ï¼‰
        mot = MultiObjectTracker(
            max_disappeared=15,
            iou_threshold=0.3,
            dist_threshold=120.0,
            match_strategy="hungarian",
            iou_weight=0.6,
            recycle_ids=True,
            force_revival=True,
        )
        try:
            while True:
                ok, frame = cap.read()
                if not ok:
                    if is_rtsp_source:
                        # å°è¯•æŒ‡æ•°é€€é¿é‡è¿ï¼Œç›´åˆ°æˆåŠŸä¸ºæ­¢
                        while True:
                            if _reconnect_rtsp():
                                ok, frame = cap.read()
                                if ok:
                                    break
                            else:
                                # ç»§ç»­æŒ‡æ•°é€€é¿
                                continue
                    else:
                        # æœ¬åœ°æ–‡ä»¶/æ‘„åƒå¤´ï¼šè¯»å¸§å¤±è´¥åˆ™é€€å‡º
                        break
                frame_idx += 1

                # ä¿å­˜é¦–å¸§åŸå§‹å›¾åƒ
                try:
                    if frame_idx == 1:
                        Path("logs").mkdir(parents=True, exist_ok=True)
                        cv2.imwrite("logs/first_frame.jpg", frame)
                        logger.info("Saved first frame to logs/first_frame.jpg")
                except Exception:
                    pass

                now_ts = time.time()
                # ç»´æŠ¤ç®€æ˜“å¸§ç¼“å†²ï¼ˆæ—¶é—´æˆ³, frameï¼‰
                try:
                    frame_buffer.append((now_ts, frame.copy()))
                    if len(frame_buffer) > frame_buffer_maxlen:
                        frame_buffer = frame_buffer[-frame_buffer_maxlen:]
                except Exception:
                    pass

                # æ ¹æ®CLIå‚æ•°æ§åˆ¶æ£€æµ‹å’Œå¯è§†åŒ–è¡Œä¸º
                result = pipeline.detect_comprehensive(
                    frame,
                    enable_hairnet=True,
                    enable_handwash=True,
                    enable_sanitize=False,
                    # å¯è€ƒè™‘æœªæ¥æ·»åŠ : osd_minimal=args.osd_minimal
                )

                annotated = (
                    result.annotated_image
                    if result.annotated_image is not None
                    else frame
                )

                # å®æ—¶åŒºåŸŸå åŠ ä¸é¦–æ¬¡è¦†ç›–å›¾ä¿å­˜ï¼ˆä¸ä¾èµ–æµç¨‹å¼•æ“å¼€å…³ï¼‰
                try:
                    from src.services.region_service import get_region_manager_for_frame

                    fh, fw = frame.shape[:2]
                    _rm = get_region_manager_for_frame(fw, fh)
                    if _rm is not None:
                        # é¦–æ¬¡æ‰“å°åŒºåŸŸæ‘˜è¦
                        if not globals().get("_regions_logged_always", False):
                            _names = []
                            try:
                                for _rid, _r in _rm.regions.items():
                                    _names.append(_r.name or _rid)
                            except Exception:
                                pass
                            logger.info(
                                f"[OSD] Regions loaded: count={len(getattr(_rm,'regions',{}))} names={_names}"
                            )
                            globals()["_regions_logged_always"] = True
                        # é¦–å¸§è¦†ç›–å›¾ï¼ˆä½¿ç”¨åŸå§‹å¸§å°ºå¯¸åæ ‡ç³»ï¼‰
                        if frame_idx == 1 and not globals().get(
                            "_overlay_first_saved", False
                        ):
                            import cv2 as _cv2
                            import numpy as _np

                            _overlay = frame.copy()
                            for _rid, _r in _rm.regions.items():
                                _pts = _np.array(
                                    [(int(px), int(py)) for (px, py) in _r.polygon],
                                    dtype=_np.int32,
                                )
                                _cv2.polylines(
                                    _overlay,
                                    [_pts],
                                    isClosed=True,
                                    color=(0, 255, 0),
                                    thickness=2,
                                )
                                if len(_pts) > 0:
                                    _cv2.putText(
                                        _overlay,
                                        (_r.name or _rid),
                                        (int(_pts[0][0]), int(_pts[0][1]) - 5),
                                        _cv2.FONT_HERSHEY_SIMPLEX,
                                        0.6,
                                        (0, 255, 0),
                                        2,
                                    )
                            Path("logs").mkdir(parents=True, exist_ok=True)
                            _cv2.imwrite("logs/overlay_first_frame.jpg", _overlay)
                            globals()["_overlay_first_saved"] = True
                            logger.info("Saved overlay_first_frame.jpg")
                        # åœ¨çª—å£å åŠ ï¼ˆè‹¥ annotated ä¸ frame å°ºå¯¸ä¸åŒï¼Œåˆ™æŒ‰æ¯”ä¾‹ç¼©æ”¾åæ ‡ï¼‰
                        if args.osd_regions:
                            import numpy as _np

                            ah, aw = annotated.shape[:2]
                            sx = (float(aw) / float(fw)) if fw > 0 else 1.0
                            sy = (float(ah) / float(fh)) if fh > 0 else 1.0
                            for _rid, _r in _rm.regions.items():
                                _pts = _np.array(
                                    [
                                        (int(px * sx), int(py * sy))
                                        for (px, py) in _r.polygon
                                    ],
                                    dtype=_np.int32,
                                )
                                cv2.polylines(
                                    annotated,
                                    [_pts],
                                    isClosed=True,
                                    color=(0, 255, 0),
                                    thickness=2,
                                )
                                if len(_pts) > 0:
                                    cv2.putText(
                                        annotated,
                                        (_r.name or _rid),
                                        (int(_pts[0][0]), int(_pts[0][1]) - 5),
                                        cv2.FONT_HERSHEY_SIMPLEX,
                                        0.6,
                                        (0, 255, 0),
                                        2,
                                    )
                    # å°†åŒºåŸŸç®¡ç†å™¨æŒ‚åˆ°å…¨å±€ä¾›åç»­ä½¿ç”¨
                    globals()["region_manager"] = _rm
                except Exception as _e:
                    logger.debug(f"OSD region overlay skip: {_e}")

                # record-onlyï¼šè‹¥å¯ç”¨ï¼Œåˆ™è®°å½•äº‹ä»¶åˆ° jsonlï¼Œä¸åšæŠ“æ‹
                if process_engine.cfg.enable:
                    # åŒºåŸŸç®¡ç†å™¨ï¼šæŒ‰éœ€åˆå§‹åŒ–ä¸€æ¬¡å¹¶ç¼©æ”¾åˆ°å½“å‰å¸§å°ºå¯¸
                    # ç»Ÿä¸€å…¥å£ï¼ˆå¸¦çƒ­æ›´æ–°/ç¼“å­˜ï¼‰ï¼šå–æ˜ å°„åçš„ RegionManager
                    # record-only åˆ†æ”¯å†…çš„åŒºåŸŸåŠ è½½é€»è¾‘å·²ä¸Šç§»ï¼Œæ­¤å¤„ä»…ä¾èµ–å…¨å±€ region_manager

                    # ä¿å­˜ä¸€æ¬¡åŒºåŸŸè¦†ç›–å åŠ å›¾ï¼ˆé¦–å¸§ï¼‰
                    try:
                        if not globals().get("_overlay_saved", False):
                            rm = globals().get("region_manager")
                            if rm is not None:
                                import cv2 as _cv2
                                import numpy as _np

                                overlay = annotated.copy()
                                for _rid, _r in rm.regions.items():
                                    pts = _np.array(
                                        [(int(px), int(py)) for (px, py) in _r.polygon],
                                        dtype=_np.int32,
                                    )
                                    color = (0, 255, 0)
                                    _cv2.polylines(
                                        overlay,
                                        [pts],
                                        isClosed=True,
                                        color=color,
                                        thickness=2,
                                    )
                                    if len(pts) > 0:
                                        _cv2.putText(
                                            overlay,
                                            (_r.name or _rid),
                                            (int(pts[0][0]), int(pts[0][1]) - 5),
                                            _cv2.FONT_HERSHEY_SIMPLEX,
                                            0.6,
                                            color,
                                            2,
                                        )
                                Path("logs").mkdir(parents=True, exist_ok=True)
                                _cv2.imwrite("logs/overlay_debug.jpg", overlay)
                                globals()["_overlay_saved"] = True
                                logger.info(
                                    "Saved region overlay to logs/overlay_debug.jpg"
                                )
                    except Exception:
                        pass

                    # æŒ‰éœ€åœ¨çª—å£å åŠ ç»˜åˆ¶åŒºåŸŸï¼ˆannotated éœ€è¦æŒ‰æ¯”ä¾‹ç¼©æ”¾æ˜¾ç¤ºï¼‰
                    try:
                        if args.osd_regions:
                            rm = globals().get("region_manager")
                            if rm is not None:
                                import numpy as _np

                                ah, aw = annotated.shape[:2]
                                fh2, fw2 = frame.shape[:2]
                                sx = (float(aw) / float(fw2)) if fw2 > 0 else 1.0
                                sy = (float(ah) / float(fh2)) if fh2 > 0 else 1.0
                                for _rid, _r in rm.regions.items():
                                    pts = _np.array(
                                        [
                                            (int(px * sx), int(py * sy))
                                            for (px, py) in _r.polygon
                                        ],
                                        dtype=_np.int32,
                                    )
                                    cv2.polylines(
                                        annotated,
                                        [pts],
                                        isClosed=True,
                                        color=(0, 255, 0),
                                        thickness=2,
                                    )
                                    if len(pts) > 0:
                                        cv2.putText(
                                            annotated,
                                            (_r.name or _rid),
                                            (int(pts[0][0]), int(pts[0][1]) - 5),
                                            cv2.FONT_HERSHEY_SIMPLEX,
                                            0.6,
                                            (0, 255, 0),
                                            2,
                                        )
                    except Exception:
                        pass

                    # æœ€å° UODï¼šé™„åŠ åŒºåŸŸåç§°
                    uod_persons = []

                    # ç®€å•BBoxé‡å 
                    def _bbox_overlap(b1, b2, thr: float = 0.1) -> bool:
                        if not b1 or not b2:
                            return False
                        x11, y11, x12, y12 = map(float, b1)
                        x21, y21, x22, y22 = map(float, b2)
                        ix1 = max(x11, x21)
                        iy1 = max(y11, y21)
                        ix2 = min(x12, x22)
                        iy2 = min(y12, y22)
                        if ix2 <= ix1 or iy2 <= iy1:
                            return False
                        inter = (ix2 - ix1) * (iy2 - iy1)
                        a1 = max(1.0, (x12 - x11) * (y12 - y11))
                        return inter / a1 >= float(thr)

                    try:
                        person_dets = getattr(result, "person_detections", []) or []
                        hairnet_results = getattr(result, "hairnet_results", []) or []
                        # æ„é€ ç”¨äºè·Ÿè¸ªå™¨çš„è¾“å…¥
                        dets_for_track = []
                        for det in person_dets:
                            bbox = det.get("bbox") or det.get("box") or det.get("xyxy")
                            conf = float(det.get("confidence", det.get("score", 0.0)))
                            if isinstance(bbox, (list, tuple)) and len(bbox) >= 4:
                                dets_for_track.append(
                                    {
                                        "bbox": [
                                            int(bbox[0]),
                                            int(bbox[1]),
                                            int(bbox[2]),
                                            int(bbox[3]),
                                        ],
                                        "confidence": conf,
                                    }
                                )
                        tracks = mot.update(dets_for_track)
                        # ç”Ÿæˆ UOD å¹¶é™„åŠ åŒºåŸŸä¸å‘ç½‘
                        # é¢„å–æ´—æ‰‹æ± åŒºåŸŸï¼ˆæŒ‰åç§°åŒ¹é…ï¼‰
                        sink_region_obj = None
                        try:
                            _rm_ref = globals().get("region_manager")
                            if _rm_ref is not None:
                                for _rid, _r in _rm_ref.regions.items():
                                    if (
                                        _r.name or _rid
                                    ) == process_engine.cfg.region_sink:
                                        sink_region_obj = _r
                                        break
                        except Exception:
                            sink_region_obj = None
                        from src.core.schemas import UODPerson

                        for tr in tracks:
                            tb = tr.get("bbox")
                            tid_assigned = int(tr.get("track_id", 0))
                            region_name = None
                            try:
                                rm = globals().get("region_manager")
                                if (
                                    rm is not None
                                    and isinstance(tb, (list, tuple))
                                    and len(tb) >= 4
                                ):
                                    cur_regions = rm.update_track_regions(
                                        tid_assigned,
                                        [
                                            int(tb[0]),
                                            int(tb[1]),
                                            int(tb[2]),
                                            int(tb[3]),
                                        ],
                                    )
                                    if cur_regions:
                                        rid = cur_regions[0]
                                        region_name = (
                                            rm.regions.get(rid).name
                                            if rid in rm.regions
                                            else rid
                                        )
                            except Exception:
                                region_name = None
                            # å‘ç½‘ç»“æœåŒ¹é…
                            has_hairnet = False
                            try:
                                for hr in hairnet_results:
                                    pb = hr.get("person_bbox") or hr.get("bbox")
                                    if _bbox_overlap(
                                        [
                                            int(tb[0]),
                                            int(tb[1]),
                                            int(tb[2]),
                                            int(tb[3]),
                                        ],
                                        pb,
                                        thr=0.1,
                                    ):
                                        has_hairnet = bool(hr.get("has_hairnet", False))
                                        break
                            except Exception:
                                has_hairnet = False
                            # æ‰‹éƒ¨å…³é”®ç‚¹è½å…¥â€œæ´—æ‰‹æ°´æ± â€åŒºåŸŸåˆ¤å®šï¼ˆä½¿ç”¨å…³é”®ç‚¹è€Œéæ‰‹æ¡†ä¸­å¿ƒï¼‰
                            hand_in_sink = False
                            try:
                                if sink_region_obj is not None:
                                    hand_regions = pipeline.get_hand_regions_for_person(
                                        frame,
                                        [
                                            int(tb[0]),
                                            int(tb[1]),
                                            int(tb[2]),
                                            int(tb[3]),
                                        ],
                                    )
                                    if hand_regions:
                                        h_img, w_img = frame.shape[:2]
                                        pts_inside = 0
                                        pts_total = 0
                                        for hres in hand_regions:
                                            lms = hres.get("landmarks")
                                            if not lms:
                                                continue
                                            for lm in lms:
                                                px = int(
                                                    float(lm.get("x", 0.0))
                                                    * float(w_img)
                                                )
                                                py = int(
                                                    float(lm.get("y", 0.0))
                                                    * float(h_img)
                                                )
                                                pts_total += 1
                                                try:
                                                    if sink_region_obj.point_in_region(
                                                        (px, py)
                                                    ):
                                                        pts_inside += 1
                                                except Exception:
                                                    pass
                                        if pts_total > 0:
                                            ratio = float(pts_inside) / float(pts_total)
                                            hand_in_sink = (pts_inside >= 3) and (
                                                ratio >= 0.2
                                            )
                            except Exception:
                                hand_in_sink = False
                            uod = UODPerson(
                                track_id=tid_assigned,
                                bbox=[int(tb[0]), int(tb[1]), int(tb[2]), int(tb[3])],
                                confidence=float(tr.get("confidence", 0.0)),
                                has_hairnet=has_hairnet,
                                region=region_name,
                                hand_in_sink=hand_in_sink,
                                ts=time.time(),
                            )
                            uod_persons.append(uod.to_dict())
                    except Exception:
                        uod_persons = []

                    # è°ƒè¯•ï¼šé€å¸§æ‰“å° track ä¸ regionï¼ˆå‰è‹¥å¹²å¸§ï¼‰ï¼Œä¾¿äºæ’æŸ¥åŒºåŸŸå‘½ä¸­
                    try:
                        if frame_idx <= 240:
                            for _p in uod_persons:
                                logger.info(
                                    f"track={_p['track_id']} region={_p.get('region')} bbox={_p.get('bbox')} hairnet={_p.get('has_hairnet')}"
                                )
                    except Exception:
                        pass
                    events = process_engine.step(uod_persons)
                    if events:
                        with events_path.open("a", encoding="utf-8") as f:
                            for ev in events:
                                f.write(
                                    json.dumps(
                                        {
                                            "type": ev.type,
                                            "track_id": ev.track_id,
                                            "ts": ev.ts,
                                            "evidence": ev.evidence,
                                            "camera_id": (args.camera_id or None),
                                        },
                                        ensure_ascii=False,
                                    )
                                    + "\n"
                                )
                                # æŠ“æ‹è¾“å‡º
                                try:
                                    # æŸ¥æ‰¾ç›¸åŒ track_id çš„ä¸Šä¸‹æ–‡
                                    ctx = {}
                                    for _p in uod_persons:
                                        if int(_p.get("track_id", -1)) == int(
                                            ev.track_id
                                        ):
                                            ctx = {
                                                "region": _p.get("region"),
                                                "has_hairnet": _p.get("has_hairnet"),
                                                "bbox": _p.get("bbox"),
                                                "type": ev.type,
                                                "track_id": ev.track_id,
                                                "ts": ev.ts,
                                                "evidence": ev.evidence,
                                                "camera_id": (args.camera_id or None),
                                            }
                                            break
                                    # ä½¿ç”¨ annotated ä»¥ä¾¿æœ‰å¯è§†å åŠ ï¼›è‹¥ä¸º None åˆ™ä½¿ç”¨åŸå¸§
                                    frame_for_save = (
                                        annotated if annotated is not None else frame
                                    )
                                    # ä¼ å…¥å¸§ç¼“å†²ï¼ˆè½¬æ¢ä¸º deque ä»¥ç¬¦åˆç±»å‹ï¼‰
                                    from collections import deque

                                    _buf = deque(
                                        frame_buffer, maxlen=frame_buffer_maxlen
                                    )
                                    capture.save_event(ev, frame_for_save, ctx, _buf)
                                except Exception:
                                    pass

                if log_iv and frame_idx % log_iv == 0:
                    cs = pipeline.cascade_stats
                    logger.info(
                        f"è¿›åº¦å¸§={frame_idx} çº§è”: è§¦å‘={cs.get('triggers',0)} ç»†åŒ–={cs.get('refined',0)} è€—æ—¶ç´¯è®¡={cs.get('time_total',0.0):.3f}s"
                    )
                    # æ‰“å°å½“å‰å¸§ track ä¸ region æ¦‚è¦
                    try:
                        # æŒ‰åŒºåŸŸåˆ†ç»„ç»Ÿè®¡ - é™åˆ°DEBUGçº§åˆ«å‡å°‘æ—¥å¿—å¼€é”€
                        if logger.isEnabledFor(_logging.DEBUG):
                            by_region = {}
                            for _p in uod_persons:
                                rn = _p.get("region") or "None"
                                by_region[rn] = by_region.get(rn, 0) + 1
                            logger.debug(f"æ´»è·ƒç›®æ ‡={len(uod_persons)} åˆ†å¸ƒ={by_region}")
                    except Exception:
                        pass

                # å±•ç¤ºçª—å£ï¼ˆæ”¾åœ¨ç»˜åˆ¶ä¹‹åï¼‰- å¯é€‰æ‹©ç¦ç”¨ä»¥æé«˜æ€§èƒ½
                if not args.no_window:
                    cv2.imshow("HBD - Main", annotated)

                    key = cv2.waitKey(1) & 0xFF
                    if key == ord("q") or key == 27:  # 'q' æˆ– ESC é”®é€€å‡º
                        break

                    # æ£€æŸ¥çª—å£æ˜¯å¦è¢«ç”¨æˆ·å…³é—­ï¼ˆç‚¹å‡»XæŒ‰é’®ï¼‰
                    try:
                        if (
                            cv2.getWindowProperty("HBD - Main", cv2.WND_PROP_VISIBLE)
                            < 1
                        ):
                            logger.info("æ£€æµ‹åˆ°çª—å£è¢«å…³é—­ï¼Œæ­£åœ¨é€€å‡º...")
                            break
                    except cv2.error:
                        # çª—å£å·²è¢«é”€æ¯
                        logger.info("çª—å£å·²è¢«é”€æ¯ï¼Œæ­£åœ¨é€€å‡º...")
                        break
                else:
                    # æ— çª—å£æ¨¡å¼ï¼Œæ£€æŸ¥é”®ç›˜ä¸­æ–­
                    import msvcrt

                    if msvcrt.kbhit():
                        key = msvcrt.getch()
                        if key == b"q":
                            break
        finally:
            cap.release()
            cv2.destroyAllWindows()
    except Exception as e:
        logger.error(f"ä¸»å…¥å£ç»¼åˆç®¡çº¿è¿è¡Œå¤±è´¥: {e}")
        return


def run_api_server(args, logger):
    """
    è¿è¡ŒAPIæœåŠ¡å™¨
    """
    logger.info(f"å¯åŠ¨APIæœåŠ¡å™¨: {args.host}:{args.port}")

    try:
        # é¢„å…ˆæ‰“å°ä¸€æ¬¡è®¾å¤‡é€‰æ‹©ç»“æœï¼ˆå®é™…æ¨¡å‹åœ¨åº”ç”¨ç”Ÿå‘½å‘¨æœŸå†…åˆå§‹åŒ–ï¼‰
        try:
            from config.model_config import ModelConfig as _MC

            dev_preview = _MC().select_device(requested=(args.device or None))
            logger.info(f"Device selected (preview): {dev_preview}")
        except Exception:
            pass

        import uvicorn

        # ç›´æ¥å¯¼å…¥ FastAPI app å®ä¾‹
        from api.app import app as fastapi_app

        uvicorn.run(
            fastapi_app,
            host=args.host,
            port=args.port,
            log_level=args.log_level.lower(),  # uvicorn æœŸæœ›å°å†™æ—¥å¿—çº§åˆ«
            reload=args.debug,  # åœ¨è°ƒè¯•æ¨¡å¼ä¸‹å¯ç”¨çƒ­é‡è½½
        )
    except ImportError as e:
        logger.error(f"æ— æ³•å¯¼å…¥APIæ¨¡å—æˆ–uvicorn: {e}")
        logger.info("è¯·ç¡®ä¿å·²å®‰è£…uvicorn: pip install uvicorn")


def run_supervisor(args, logger):
    """æ‰˜ç®¡ cameras.yaml ä¸­çš„æ‰€æœ‰æ‘„åƒå¤´æ£€æµ‹è¿›ç¨‹ã€‚"""
    try:
        from src.services.process_manager import get_process_manager
    except Exception as e:
        logger.error(f"æ— æ³•å¯¼å…¥è¿›ç¨‹ç®¡ç†å™¨: {e}")
        return
    pm = get_process_manager()
    res = pm.start_all()
    logger.info(f"Supervisor started cameras: {res}")
    try:
        while True:
            time.sleep(1.0)
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œå‡†å¤‡åœæ­¢æ‰€æœ‰æ‘„åƒå¤´...")
        pm.stop_all()
        logger.info("å·²åœæ­¢å…¨éƒ¨æ‘„åƒå¤´è¿›ç¨‹ã€‚")


def run_training(args, logger):
    """
    è¿è¡Œè®­ç»ƒæ¨¡å¼
    """
    logger.info(f"å¼€å§‹è®­ç»ƒï¼Œé…ç½®æ–‡ä»¶: {args.config}")

    # TODO: å®ç°è®­ç»ƒé€»è¾‘
    logger.info("è®­ç»ƒæ¨¡å¼æš‚æœªå®ç°ï¼Œè¯·ç­‰å¾…åç»­ç‰ˆæœ¬")


def run_demo(args, logger):
    """
    è¿è¡Œæ¼”ç¤ºæ¨¡å¼
    """
    logger.info("å¯åŠ¨æ¼”ç¤ºæ¨¡å¼")

    # TODO: å®ç°æ¼”ç¤ºé€»è¾‘
    logger.info("æ¼”ç¤ºæ¨¡å¼æš‚æœªå®ç°ï¼Œè¯·ç­‰å¾…åç»­ç‰ˆæœ¬")


if __name__ == "__main__":
    main()
