#!/usr/bin/env python3
"""
äººä½“è¡Œä¸ºæ£€æµ‹ç³»ç»Ÿä¸»å…¥å£æ–‡ä»¶
Human Behavior Detection System Main Entry Point

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 1.0.0
åˆ›å»ºæ—¶é—´: 2024
"""

import argparse
import os
import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

try:
    import time

    from utils.gpu_acceleration import initialize_gpu_acceleration
    from utils.logger import setup_project_logger
except ImportError:
    # This is a workaround for running scripts directly from the repository root.
    # It adds the 'src' directory to the Python path.
    src_path = Path(__file__).resolve().parent.parent / "src"
    sys.path.insert(0, str(src_path))
    import time

    from utils.gpu_acceleration import initialize_gpu_acceleration
    from utils.logger import setup_project_logger

# GPUåŠ é€Ÿä¼˜åŒ–ï¼ˆåœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰ï¼‰
try:
    gpu_status = initialize_gpu_acceleration()
except (ImportError, NameError):
    gpu_status = {"device": "cpu", "gpu_available": False}


def create_argument_parser():
    """åˆ›å»ºå¹¶é…ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="äººä½“è¡Œä¸ºæ£€æµ‹ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python main.py --mode detection --source 0                    # ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œæ£€æµ‹
  python main.py --mode detection --source video.mp4           # ä½¿ç”¨è§†é¢‘æ–‡ä»¶è¿›è¡Œæ£€æµ‹
  python main.py --mode api --port 8000                        # å¯åŠ¨APIæœåŠ¡
  python main.py --mode training --config config/train.yaml    # è®­ç»ƒæ¨¡å‹
        """,
    )

    # åŸºç¡€å‚æ•°
    parser.add_argument(
        "--mode",
        choices=["detection", "api", "training", "demo", "supervisor"],
        default="detection",
        help="è¿è¡Œæ¨¡å¼ (é»˜è®¤: detection)",
    )
    parser.add_argument("--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ¨¡å¼")
    parser.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)",
    )

    # è¾“å…¥è¾“å‡ºå‚æ•°
    parser.add_argument(
        "--source", type=str, default="0", help="è¾“å…¥æº: æ‘„åƒå¤´ç´¢å¼•(0,1...) æˆ– è§†é¢‘æ–‡ä»¶è·¯å¾„ (é»˜è®¤: 0)"
    )
    parser.add_argument("--output", type=str, help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument(
        "--config",
        type=str,
        default="config/default.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/default.yaml)",
    )
    parser.add_argument(
        "--regions-file",
        type=str,
        default="config/regions.json",
        help="åŒºåŸŸé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/regions.json)",
    )

    # APIæœåŠ¡å‚æ•°
    parser.add_argument("--port", type=int, default=8000, help="APIæœåŠ¡ç«¯å£ (é»˜è®¤: 8000)")
    parser.add_argument(
        "--host", type=str, default="0.0.0.0", help="APIæœåŠ¡ä¸»æœº (é»˜è®¤: 0.0.0.0)"
    )

    # GPUå’Œæ€§èƒ½å‚æ•°
    parser.add_argument("--gpu-optimize", action="store_true", help="å¯ç”¨GPUåŠ é€Ÿä¼˜åŒ–")
    parser.add_argument("--batch-size", type=int, help="æ‰¹å¤„ç†å¤§å°ï¼ˆè‡ªåŠ¨æ£€æµ‹æœ€ä¼˜å€¼ï¼‰")

    # è‡ªé€‚åº”ç›¸å…³å‚æ•°
    parser.add_argument(
        "--profile",
        type=str,
        default=None,
        help="fast|balanced|accurateï¼ˆä¼˜å…ˆçº§: CLI>ENV>YAML)",
    )
    parser.add_argument(
        "--device", type=str, default=None, help="cpu|cuda|mpsï¼ˆä¼˜å…ˆçº§: CLI>ENV>auto)"
    )
    parser.add_argument("--imgsz", type=int, default=None, help="YOLO è¾“å…¥å°ºå¯¸ï¼ˆè¦†ç›–é…ç½®ï¼‰")
    parser.add_argument(
        "--human-weights", type=str, default=None, help="YOLO äººä½“æ£€æµ‹æƒé‡è·¯å¾„ï¼ˆè¦†ç›–é…ç½®ï¼‰"
    )

    # æ€§èƒ½ä¼˜åŒ–å‚æ•°
    parser.add_argument(
        "--no-window", action="store_true", help="ç¦ç”¨å¯è§†åŒ–çª—å£ï¼Œä»…è¾“å‡ºç»Ÿè®¡ä¿¡æ¯ï¼ˆæé«˜æ€§èƒ½ï¼‰"
    )
    parser.add_argument("--osd-minimal", action="store_true", help="æœ€å°åŒ–OSDç»˜åˆ¶ï¼Œå‡å°‘å¯è§†åŒ–å¼€é”€")
    parser.add_argument("--frame-skip", type=int, default=0, help="è·³å¸§æ•°é‡ï¼Œ0è¡¨ç¤ºä¸è·³å¸§ï¼ˆé»˜è®¤: 0ï¼‰")
    parser.add_argument("--cascade-enable", action="store_true", help="å¯ç”¨çº§è”äºŒæ¬¡æ£€æµ‹")
    parser.add_argument("--log-interval", type=int, default=None, help="æ—¥å¿—é™æµé—´éš”ï¼ˆå¸§ï¼‰")
    parser.add_argument(
        "--osd-regions", action="store_true", help="åœ¨çª—å£å åŠ æ˜¾ç¤ºå·²åŠ è½½çš„åŒºåŸŸå¤šè¾¹å½¢ä¸åç§°"
    )
    parser.add_argument(
        "--camera-id", type=str, default=None, help="å½“å‰æ£€æµ‹è¿›ç¨‹çš„æ‘„åƒå¤´æ ‡è¯†ï¼ˆç”¨äºäº‹ä»¶/æŒ‡æ ‡æ‰“æ ‡ï¼‰"
    )

    return parser


def setup_logging_and_gpu(args):
    """è®¾ç½®æ—¥å¿—å’ŒGPUé…ç½®"""
    logger = setup_project_logger()
    if args.debug:
        logger.setLevel("DEBUG")
    else:
        logger.setLevel(args.log_level)

    # æå‡æ ¹æ—¥å¿—çº§åˆ«ï¼Œç¡®ä¿å­æ¨¡å—æ—¥å¿—å¯è§
    try:
        import logging as _logging

        _logging.getLogger().setLevel(logger.level)
    except Exception:
        pass

    logger.info("=" * 50)
    logger.info("äººä½“è¡Œä¸ºæ£€æµ‹ç³»ç»Ÿå¯åŠ¨")
    logger.info(f"è¿è¡Œæ¨¡å¼: {args.mode}")

    # æ˜¾ç¤ºGPUçŠ¶æ€
    if gpu_status["gpu_available"]:
        logger.info(f"ğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨: {gpu_status['device']}")
        if args.gpu_optimize:
            logger.info("âš™ï¸  GPUä¼˜åŒ–æ¨¡å¼å·²å¯ç”¨")
    else:
        logger.info("âš ï¸  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
        if args.gpu_optimize:
            logger.warning("âš ï¸  GPUä¼˜åŒ–å‚æ•°å·²å¿½ç•¥ï¼ˆGPUä¸å¯ç”¨ï¼‰")

    logger.info("=" * 50)
    return logger


def execute_mode(args, logger):
    """æ‰§è¡ŒæŒ‡å®šçš„è¿è¡Œæ¨¡å¼"""
    mode_handlers = {
        "detection": run_detection,
        "api": run_api_server,
        "training": run_training,
        "demo": run_demo,
        "supervisor": run_supervisor,
    }

    handler = mode_handlers.get(args.mode)
    if not handler:
        logger.error(f"æœªçŸ¥çš„è¿è¡Œæ¨¡å¼: {args.mode}")
        sys.exit(1)

    if args.mode == "supervisor":
        try:
            handler(args, logger)
        except NameError:
            logger.error("supervisor æ¨¡å¼æš‚æœªå®ç°ï¼Œè¯·ç¨åå†è¯•")
    else:
        handler(args, logger)


def main():
    """ä¸»å‡½æ•°"""
    parser = create_argument_parser()
    args = parser.parse_args()
    logger = setup_logging_and_gpu(args)

    try:
        execute_mode(args, logger)
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        if args.debug:
            import traceback

            traceback.print_exc()
        sys.exit(1)
    finally:
        logger.info("ç¨‹åºç»“æŸ")


def load_unified_params(args, logger):
    """åŠ è½½ç»Ÿä¸€å‚æ•°å¹¶åº”ç”¨CLIè¦†ç›–"""
    try:
        from config.unified_params import get_unified_params

        params = get_unified_params()
        cli_overrides = {"runtime": {}, "human_detection": {}, "cascade": {}}
        if args.imgsz:
            cli_overrides["human_detection"]["imgsz"] = int(args.imgsz)
        if args.human_weights:
            cli_overrides["human_detection"]["model_path"] = str(args.human_weights)
        if args.cascade_enable:
            cli_overrides["cascade"]["enable"] = True
        if args.log_interval is not None:
            cli_overrides["runtime"]["log_interval"] = int(args.log_interval)
        effective = params.build_effective_config(
            profile=args.profile, cli_overrides=cli_overrides
        )
        return effective
    except Exception as e:
        logger.error(f"åŠ è½½/åˆå¹¶é…ç½®å¤±è´¥: {e}")
        return None


def apply_adaptive_optimizations(args, logger):
    """åº”ç”¨è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–"""
    try:
        from src.utils.adaptive_optimizer import apply_adaptive_optimizations

        adaptive_config = apply_adaptive_optimizations()

        # åº”ç”¨è‡ªé€‚åº”é…ç½®ï¼ˆå¦‚æœç”¨æˆ·æœªæ‰‹åŠ¨æŒ‡å®šï¼‰
        auto_device = (args.device is None) or (str(args.device).lower() == "auto")
        auto_imgsz = (args.imgsz is None) or (str(args.imgsz).lower() == "auto")
        auto_weights = args.human_weights is None

        if auto_device:
            args.device = "cuda" if adaptive_config.get("enable_amp") else "cpu"
        if auto_imgsz:
            args.imgsz = adaptive_config.get("imgsz", 416)
        if auto_weights:
            recommended_model = adaptive_config.get("model_recommendations", {}).get(
                "human_model", "yolov8s.pt"
            )
            args.human_weights = f"models/yolo/{recommended_model}"

        logger.info(f"è‡ªé€‚åº”ä¼˜åŒ–å·²å¯ç”¨: {adaptive_config['description']}")
        logger.info(
            f"æ¨èé…ç½® - è®¾å¤‡: {args.device}, å›¾åƒå°ºå¯¸: {args.imgsz}, æ¨¡å‹: {args.human_weights}"
        )
        return True

    except Exception as e:
        logger.debug(f"è‡ªé€‚åº”ä¼˜åŒ–è·³è¿‡: {e}")
        return False


def apply_hardware_probe_fallback(args, logger):
    """åº”ç”¨ç¡¬ä»¶æ¢æµ‹å›é€€é€»è¾‘"""
    auto_device = (args.device is None) or (str(args.device).lower() == "auto")
    auto_imgsz = (args.imgsz is None) or (str(args.imgsz).lower() == "auto")
    auto_weights = args.human_weights is None

    if auto_device or auto_imgsz or auto_weights:
        try:
            from src.utils.hardware_probe import decide_policy

            pol = decide_policy(
                preferred_profile=args.profile,
                user_device=args.device,
                user_imgsz=args.imgsz,
            )
            if auto_device:
                args.device = pol.get("device")
            if auto_imgsz:
                args.imgsz = pol.get("imgsz")
            if auto_weights and pol.get("human_weights"):
                args.human_weights = pol.get("human_weights")
            # ç¯å¢ƒå˜é‡æ³¨å…¥ï¼ˆçº¿ç¨‹æ•°ç­‰ï¼‰
            for k, v in (pol.get("env") or {}).items():
                os.environ[str(k)] = str(v)
            logger.info(f"Auto policy applied: {pol}")
        except Exception as _e:
            logger.debug(f"hardware_probe skipped: {_e}")


def select_device(args, logger):
    """é€‰æ‹©è®¡ç®—è®¾å¤‡"""
    try:
        from config.model_config import ModelConfig

        mc = ModelConfig()
        dev_req = args.device or None
        device = mc.select_device(requested=dev_req)
        logger.info(f"Device selected: {device}")
        return device
    except Exception as e:
        logger.error(f"é€‰æ‹©è®¾å¤‡å¤±è´¥: {e}")
        return "cpu"


def _run_detection_loop(args, logger, pipeline, device):
    """
    æ‰§è¡Œè§†é¢‘æ£€æµ‹å¾ªç¯

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        logger: æ—¥å¿—è®°å½•å™¨
        pipeline: æ£€æµ‹ç®¡çº¿å®ä¾‹
        device: è®¾å¤‡ç±»å‹ (cpu/cuda/mps)
    """
    import asyncio
    import signal
    from collections import defaultdict
    from datetime import datetime

    import cv2

    # å¯¼å…¥æ•°æ®åº“æœåŠ¡
    try:
        from src.services.database_service import DatabaseService

        db_enabled = True
        logger.info("æ•°æ®åº“æœåŠ¡å·²å¯ç”¨")
    except ImportError as e:
        db_enabled = False
        logger.warning(f"æ•°æ®åº“æœåŠ¡æœªå¯ç”¨: {e}")

    # å…¨å±€æ ‡å¿—ç”¨äºä¼˜é›…é€€å‡º
    shutdown_requested = {"flag": False}

    def signal_handler(signum, frame):
        """å¤„ç†é€€å‡ºä¿¡å·"""
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡é€€å‡º...")
        shutdown_requested["flag"] = True

    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)

    # æ‰“å¼€è§†é¢‘æº
    source = args.source
    # å°è¯•å°†æºè½¬æ¢ä¸ºæ•´æ•°ï¼ˆæ‘„åƒå¤´ç´¢å¼•ï¼‰
    try:
        source = int(source)
    except (ValueError, TypeError):
        pass  # ä¿æŒä¸ºå­—ç¬¦ä¸²ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰

    cap = cv2.VideoCapture(source)
    if not cap.isOpened():
        logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æº: {args.source}")
        return

    # è·å–è§†é¢‘ä¿¡æ¯
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    logger.info(
        f"è§†é¢‘ä¿¡æ¯: {width}x{height} @ {fps}FPS, æ€»å¸§æ•°: {total_frames if total_frames > 0 else 'æœªçŸ¥(å®æ—¶æµ)'}"
    )

    # æ—¥å¿—é—´éš”è®¾ç½®ï¼ˆç”¨äºè·³å¸§ï¼‰
    log_interval = getattr(args, "log_interval", None) or 1
    if log_interval > 1:
        logger.info(f"å¯ç”¨å¸§è·³è¿‡: æ¯ {log_interval} å¸§å¤„ç† 1 å¸§")

    frame_count = 0
    process_count = 0
    start_time = time.time()
    last_log_time = start_time

    # æ•°æ®åº“ç›¸å…³åˆå§‹åŒ–
    db_service = None
    camera_id = getattr(args, "camera_id", "unknown")
    save_interval = int(os.getenv("DETECTION_SAVE_INTERVAL", "10"))  # æ¯10å¸§ä¿å­˜ä¸€æ¬¡
    
    # å°æ—¶ç»Ÿè®¡
    hour_stats = defaultdict(int)
    current_hour = datetime.now().replace(minute=0, second=0, microsecond=0)

    # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if db_enabled:
        try:
            db_service = DatabaseService()
            asyncio.run(db_service.init())
            logger.info(f"âœ… æ•°æ®åº“æœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼Œæ¯ {save_interval} å¸§ä¿å­˜ä¸€æ¬¡")
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            db_service = None

    try:
        logger.info("å¼€å§‹è§†é¢‘å¤„ç†å¾ªç¯...")

        while not shutdown_requested["flag"]:
            ret, frame = cap.read()
            if not ret:
                # å¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶ï¼Œå°è¯•å¾ªç¯æ’­æ”¾
                if total_frames > 0:
                    logger.info("è§†é¢‘æ–‡ä»¶æ’­æ”¾å®Œæˆï¼Œé‡æ–°å¼€å§‹å¾ªç¯æ’­æ”¾...")
                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # é‡ç½®åˆ°ç¬¬ä¸€å¸§
                    frame_count = 0  # é‡ç½®å¸§è®¡æ•°
                    continue
                else:
                    logger.warning("è§†é¢‘æµè¯»å–å¤±è´¥")
                    break

            frame_count += 1

            # æ ¹æ® log_interval å†³å®šæ˜¯å¦å¤„ç†è¿™ä¸€å¸§
            if log_interval > 1 and frame_count % log_interval != 0:
                continue

            process_count += 1
            detection_start = time.time()

            try:
                # ä½¿ç”¨ç®¡çº¿è¿›è¡Œæ£€æµ‹
                result = pipeline.detect_comprehensive(
                    frame,
                    enable_hairnet=True,
                    enable_handwash=True,
                    enable_sanitize=True,
                )

                detection_time = time.time() - detection_start

                # æå–æ£€æµ‹ç»“æœç»Ÿè®¡
                person_count = len(result.person_detections)
                hairnet_count = len(result.hairnet_results)
                handwash_count = len(result.handwash_results)
                sanitize_count = len(result.sanitize_results)

                # æ›´æ–°å°æ—¶ç»Ÿè®¡
                hour_stats["frames"] += 1
                hour_stats["persons"] += person_count
                hour_stats["handwash_events"] += handwash_count
                hour_stats["sanitize_events"] += sanitize_count
                
                # è®¡ç®—è¿è§„æ•°é‡
                hairnet_violations = sum(
                    1 for h in result.hairnet_results if not h.get("has_hairnet", True)
                )
                hour_stats["hairnet_violations"] += hairnet_violations

                # ä¿å­˜æ£€æµ‹è®°å½•åˆ°æ•°æ®åº“ï¼ˆæ¯Nå¸§ä¿å­˜ä¸€æ¬¡ï¼‰
                if db_service and process_count % save_interval == 0:
                    try:
                        elapsed = time.time() - start_time
                        avg_fps = process_count / elapsed if elapsed > 0 else 0

                        # å¼‚æ­¥ä¿å­˜æ£€æµ‹è®°å½•
                        record_id = asyncio.run(
                            db_service.save_detection_record(
                                camera_id=camera_id,
                                frame_number=frame_count,
                                result=result,
                                fps=avg_fps,
                            )
                        )

                        # ä¿å­˜è¿è§„äº‹ä»¶
                        for hairnet_result in result.hairnet_results:
                            if not hairnet_result.get("has_hairnet", True):
                                asyncio.run(
                                    db_service.save_violation_event(
                                        detection_id=record_id,
                                        camera_id=camera_id,
                                        violation_type="no_hairnet",
                                        track_id=hairnet_result.get("track_id"),
                                        confidence=hairnet_result.get("confidence", 0.0),
                                        bbox=hairnet_result.get("bbox"),
                                    )
                                )

                        logger.debug(f"å·²ä¿å­˜æ£€æµ‹è®°å½•: {record_id}")

                    except Exception as e:
                        logger.error(f"ä¿å­˜æ£€æµ‹è®°å½•å¤±è´¥: {e}")

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°å°æ—¶ç»Ÿè®¡
                now = datetime.now()
                new_hour = now.replace(minute=0, second=0, microsecond=0)
                if new_hour > current_hour and db_service:
                    try:
                        # ä¿å­˜ä¸Šä¸€å°æ—¶çš„ç»Ÿè®¡
                        asyncio.run(
                            db_service.update_hourly_statistics(
                                camera_id=camera_id,
                                hour_start=current_hour,
                                stats=dict(hour_stats),
                            )
                        )
                        logger.info(f"å·²ä¿å­˜å°æ—¶ç»Ÿè®¡: {current_hour}")

                        # é‡ç½®ç»Ÿè®¡
                        hour_stats.clear()
                        current_hour = new_hour

                    except Exception as e:
                        logger.error(f"ä¿å­˜å°æ—¶ç»Ÿè®¡å¤±è´¥: {e}")

                # å®šæœŸæ‰“å°ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ¯10å¸§æˆ–æ¯5ç§’ï¼‰
                current_time = time.time()
                should_log = (
                    process_count % 10 == 0 or (current_time - last_log_time) >= 5.0
                )

                if should_log:
                    elapsed = current_time - start_time
                    avg_fps = process_count / elapsed if elapsed > 0 else 0
                    progress = (
                        f"{frame_count}/{total_frames}"
                        if total_frames > 0
                        else str(frame_count)
                    )

                    logger.info(
                        f"å¸§ {progress} | "
                        f"æ£€æµ‹: äºº={person_count}, å‘ç½‘={hairnet_count}, æ´—æ‰‹={handwash_count}, æ¶ˆæ¯’={sanitize_count} | "
                        f"è€—æ—¶: {detection_time:.3f}s | "
                        f"å¤„ç†FPS: {avg_fps:.2f}"
                    )
                    last_log_time = current_time

                # å¯é€‰ï¼šä¿å­˜ç»“æœåˆ°è¾“å‡ºç›®å½•
                if args.output and result.annotated_image is not None:
                    output_dir = Path(args.output)
                    output_dir.mkdir(parents=True, exist_ok=True)
                    output_file = output_dir / f"frame_{frame_count:06d}.jpg"
                    cv2.imwrite(str(output_file), result.annotated_image)

            except Exception as e:
                logger.error(f"å¤„ç†ç¬¬ {frame_count} å¸§æ—¶å‡ºé”™: {e}")
                if args.debug:
                    import traceback

                    traceback.print_exc()
                continue

        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        logger.info("=" * 60)
        logger.info("æ£€æµ‹å®Œæˆç»Ÿè®¡:")
        logger.info(f"  æ€»å¸§æ•°: {frame_count}")
        logger.info(f"  å¤„ç†å¸§æ•°: {process_count}")
        logger.info(f"  æ€»è€—æ—¶: {total_time:.2f}s")
        logger.info(
            f"  å¹³å‡å¤„ç†FPS: {process_count / total_time:.2f}"
            if total_time > 0
            else "  å¹³å‡å¤„ç†FPS: N/A"
        )

        # æ‰“å°ç®¡çº¿ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            if hasattr(pipeline, "get_stats"):
                pipeline_stats = pipeline.get_stats()
                logger.info("  ç®¡çº¿ç»Ÿè®¡:")
                logger.info(f"    æ€»æ£€æµ‹æ¬¡æ•°: {pipeline_stats.get('total_detections', 0)}")
                logger.info(f"    ç¼“å­˜å‘½ä¸­: {pipeline_stats.get('cache_hits', 0)}")
                logger.info(f"    ç¼“å­˜æœªå‘½ä¸­: {pipeline_stats.get('cache_misses', 0)}")
                logger.info(
                    f"    å¹³å‡å¤„ç†æ—¶é—´: {pipeline_stats.get('avg_processing_time', 0):.3f}s"
                )
            elif hasattr(pipeline, "stats"):
                logger.info(f"  ç®¡çº¿ç»Ÿè®¡: {pipeline.stats}")
        except Exception as e:
            logger.debug(f"æ— æ³•è·å–ç®¡çº¿ç»Ÿè®¡: {e}")
        logger.info("=" * 60)

    except KeyboardInterrupt:
        logger.info("æ¥æ”¶åˆ°é”®ç›˜ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")

    except Exception as e:
        logger.error(f"æ£€æµ‹å¾ªç¯å‡ºç°å¼‚å¸¸: {e}")
        if args.debug:
            import traceback

            traceback.print_exc()

    finally:
        # ä¿å­˜æœ€åçš„å°æ—¶ç»Ÿè®¡
        if db_service and hour_stats:
            try:
                asyncio.run(
                    db_service.update_hourly_statistics(
                        camera_id=camera_id, hour_start=current_hour, stats=dict(hour_stats)
                    )
                )
                logger.info("å·²ä¿å­˜æœ€ç»ˆå°æ—¶ç»Ÿè®¡")
            except Exception as e:
                logger.error(f"ä¿å­˜æœ€ç»ˆç»Ÿè®¡å¤±è´¥: {e}")

        # å…³é—­æ•°æ®åº“è¿æ¥
        if db_service:
            try:
                asyncio.run(db_service.close())
                logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")
            except Exception as e:
                logger.error(f"å…³é—­æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")

        # èµ„æºæ¸…ç†
        logger.info("é‡Šæ”¾èµ„æº...")
        cap.release()
        cv2.destroyAllWindows()
        logger.info("èµ„æºé‡Šæ”¾å®Œæˆ")


def run_detection(args, logger):
    """è¿è¡Œæ£€æµ‹æ¨¡å¼"""
    logger.info(f"å¼€å§‹æ£€æµ‹ï¼Œè¾“å…¥æº: {args.source}")

    # 1) åŠ è½½ç»Ÿä¸€å‚æ•°å¹¶åº”ç”¨ profiles/CLI è¦†ç›–
    effective = load_unified_params(args, logger)
    if not effective:
        return

    # 2) ç»Ÿä¸€è®¾å¤‡é€‰æ‹©ï¼ˆç»“åˆç¡¬ä»¶è‡ªé€‚åº”ï¼‰
    # æ–°å¢ï¼šè‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–
    if not apply_adaptive_optimizations(args, logger):
        # å›é€€åˆ°åŸæœ‰çš„ç¡¬ä»¶æ¢æµ‹é€»è¾‘
        apply_hardware_probe_fallback(args, logger)

    device = select_device(args, logger)

    # 3) è¾“å‡ºé…ç½®æ‘˜è¦
    hd = effective.get("human_detection", {})
    imgsz = hd.get("imgsz", None)
    weights = hd.get("model_path", None)
    prof = effective.get("inference", {}).get("profile", "fast")
    logger.info(
        f"é…ç½®æ‘˜è¦: device={device}, profile={prof}, imgsz={imgsz}, weights={weights}"
    )

    # 4) æ„å»º"ä¼˜åŒ–ç»¼åˆç®¡çº¿"å¹¶è¿è¡Œï¼ˆå¯ç”¨ YOLO äººä½“ä¸å¯é€‰çº§è”ï¼‰
    try:
        # å°†åˆå¹¶åçš„å…³é”®äººæ£€å‚æ•°å›å¡«åˆ°å…¨å±€é…ç½®ï¼Œç¡®ä¿ HumanDetector è¯»å–åˆ°
        from config.unified_params import update_global_param

        for k in [
            "model_path",
            "confidence_threshold",
            "iou_threshold",
            "min_box_area",
            "max_box_ratio",
            "min_width",
            "min_height",
            "nms_threshold",
            "max_detections",
            "device",
        ]:
            if k in hd:
                update_global_param("human_detection", k, hd[k])

        # åˆå§‹åŒ–æ£€æµ‹å™¨å’Œç®¡çº¿
        from src.core.behavior import BehaviorRecognizer
        from src.core.optimized_detection_pipeline import OptimizedDetectionPipeline
        from src.detection.detector import HumanDetector
        from src.detection.pose_detector import PoseDetectorFactory
        from src.detection.yolo_hairnet_detector import YOLOHairnetDetector

        # æƒé‡æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥ä¸å›é€€
        wpath = Path(weights) if weights else None
        if not (wpath and wpath.exists()):
            alt = Path("models/yolo/yolov8n.pt")
            logger.warning(f"æŒ‡å®šæƒé‡ä¸å­˜åœ¨: {weights}ï¼Œå›é€€åˆ° {alt}")
            weights = str(alt)
            update_global_param("human_detection", "model_path", weights)

        human_detector = HumanDetector(model_path=weights, device=device)

        # æ ¹æ®é…ç½®å’Œè®¾å¤‡é€‰æ‹©å§¿æ€æ£€æµ‹åç«¯
        from config.unified_params import get_unified_params

        params = get_unified_params()

        # ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„åç«¯è®¾ç½®ï¼Œå¦‚æœé…ç½®ä¸ºautoåˆ™æ ¹æ®è®¾å¤‡é€‰æ‹©
        pose_backend = params.pose_detection.backend
        if pose_backend == "auto":
            # è‡ªåŠ¨é€‰æ‹©ï¼šCUDAè®¾å¤‡ä¼˜å…ˆä½¿ç”¨YOLOv8ï¼ŒCPUè®¾å¤‡ä½¿ç”¨MediaPipe
            pose_backend = "yolov8" if str(device).lower() == "cuda" else "mediapipe"

        pose_detector = PoseDetectorFactory.create(
            backend=pose_backend,
            device=params.pose_detection.device
            if params.pose_detection.device != "auto"
            else device,
        )
        logger.info(f"å§¿æ€æ£€æµ‹å™¨åç«¯: {pose_backend}, è®¾å¤‡: {device}")

        behavior_recognizer = BehaviorRecognizer()
        hairnet_detector = YOLOHairnetDetector(device=device)
        cascade_cfg = effective.get("cascade", {})

        pipeline = OptimizedDetectionPipeline(
            human_detector=human_detector,
            hairnet_detector=hairnet_detector,
            behavior_recognizer=behavior_recognizer,
            pose_detector=pose_detector,
            enable_cache=True,
            cache_size=50,
            cache_ttl=20.0,
            cascade_config=cascade_cfg,
        )

        logger.info("æ£€æµ‹ç®¡çº¿åˆå§‹åŒ–å®Œæˆï¼Œå¼€å§‹å¤„ç†...")

        # å®ç°è§†é¢‘å¤„ç†å¾ªç¯
        _run_detection_loop(args, logger, pipeline, device)

    except Exception as e:
        logger.error(f"æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        if args.debug:
            import traceback

            traceback.print_exc()


def run_api_server(args, logger):
    """
    è¿è¡ŒAPIæœåŠ¡å™¨
    """
    logger.info(f"å¯åŠ¨APIæœåŠ¡å™¨: {args.host}:{args.port}")

    try:
        # é¢„å…ˆæ‰“å°ä¸€æ¬¡è®¾å¤‡é€‰æ‹©ç»“æœï¼ˆå®é™…æ¨¡å‹åœ¨åº”ç”¨ç”Ÿå‘½å‘¨æœŸå†…åˆå§‹åŒ–ï¼‰
        try:
            from config.model_config import ModelConfig as _MC

            dev_preview = _MC().select_device(requested=(args.device or None))
            logger.info(f"Device selected (preview): {dev_preview}")
        except Exception:
            pass

        import uvicorn

        # ä½¿ç”¨å­—ç¬¦ä¸²è·¯å¾„å¯åŠ¨ FastAPI åº”ç”¨ï¼Œé¿å…ç›´æ¥å¯¼å…¥
        uvicorn.run(
            "src.api.app:app",
            host=args.host,
            port=args.port,
            log_level=args.log_level.lower(),  # uvicorn æœŸæœ›å°å†™æ—¥å¿—çº§åˆ«
            reload=args.debug,  # åœ¨è°ƒè¯•æ¨¡å¼ä¸‹å¯ç”¨çƒ­é‡è½½
        )
    except ImportError as e:
        logger.error(f"æ— æ³•å¯¼å…¥APIæ¨¡å—æˆ–uvicorn: {e}")
        logger.info("è¯·ç¡®ä¿å·²å®‰è£…uvicorn: pip install uvicorn")


def run_supervisor(args, logger):
    """æ‰˜ç®¡ cameras.yaml ä¸­çš„æ‰€æœ‰æ‘„åƒå¤´æ£€æµ‹è¿›ç¨‹ã€‚"""
    try:
        from src.services.process_manager import get_process_manager
    except Exception as e:
        logger.error(f"æ— æ³•å¯¼å…¥è¿›ç¨‹ç®¡ç†å™¨: {e}")
        return
    pm = get_process_manager()
    res = pm.start_all()
    logger.info(f"Supervisor started cameras: {res}")
    try:
        while True:
            time.sleep(1.0)
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œå‡†å¤‡åœæ­¢æ‰€æœ‰æ‘„åƒå¤´...")
        pm.stop_all()
        logger.info("å·²åœæ­¢å…¨éƒ¨æ‘„åƒå¤´è¿›ç¨‹ã€‚")


def run_training(args, logger):
    """
    è¿è¡Œè®­ç»ƒæ¨¡å¼
    """
    logger.info(f"å¼€å§‹è®­ç»ƒï¼Œé…ç½®æ–‡ä»¶: {args.config}")

    # TODO: å®ç°è®­ç»ƒé€»è¾‘
    logger.info("è®­ç»ƒæ¨¡å¼æš‚æœªå®ç°ï¼Œè¯·ç­‰å¾…åç»­ç‰ˆæœ¬")


def run_demo(args, logger):
    """
    è¿è¡Œæ¼”ç¤ºæ¨¡å¼
    """
    logger.info("å¯åŠ¨æ¼”ç¤ºæ¨¡å¼")

    # TODO: å®ç°æ¼”ç¤ºé€»è¾‘
    logger.info("æ¼”ç¤ºæ¨¡å¼æš‚æœªå®ç°ï¼Œè¯·ç­‰å¾…åç»­ç‰ˆæœ¬")


if __name__ == "__main__":
    main()
